{"version":3,"sources":["webpack://JSONFormula/./node_modules/antlr4/src/antlr4/BufferedTokenStream.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/CharStreams.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/CommonTokenFactory.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/CommonTokenStream.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/FileStream.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/InputStream.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/IntervalSet.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/LL1Analyzer.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/Lexer.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/Parser.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/ParserRuleContext.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/PredictionContext.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/Recognizer.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/RuleContext.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/Token.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/Utils.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATN.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNConfig.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNState.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ATNType.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/LexerATNSimulator.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/LexerAction.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/LexerActionExecutor.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/ParserATNSimulator.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/PredictionMode.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/SemanticContext.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/Transition.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/atn/index.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/dfa/DFA.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/dfa/DFAState.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/dfa/index.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/error/DiagnosticErrorListener.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/error/ErrorListener.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/error/Errors.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/error/index.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/index.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/polyfills/codepointat.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/tree/Tree.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/tree/Trees.js","webpack://JSONFormula/./node_modules/antlr4/src/antlr4/tree/index.js","webpack://JSONFormula/./node_modules/jmespath/jmespath.js","webpack://JSONFormula/ignored|/Users/johnbrinkman/dev/json-formula/node_modules/antlr4/src/antlr4|fs","webpack://JSONFormula/webpack/bootstrap","webpack://JSONFormula/webpack/runtime/make namespace object","webpack://JSONFormula/./src/antlr/JSONFormulaListener.js","webpack://JSONFormula/./src/antlr/JSONFormulaParser.js","webpack://JSONFormula/./src/antlr/JSONFormulaLexer.js","webpack://JSONFormula/./src/Listener.js","webpack://JSONFormula/./src/evaluate.js","webpack://JSONFormula/./src/index.js"],"names":["JSONFormulaListener","ctx","antlr4","serializedATN","join","atn","deserialize","decisionsToDFA","decisionToState","map","ds","index","sharedContextCache","JSONFormulaParser","input","_interp","ruleNames","literalNames","symbolicNames","localctx","ruleIndex","predIndex","expression_sempred","nonempty_expr_list_sempred","jmesPathExpression_sempred","precpred","_ctx","FormulaContext","state","enterRule","RULE_formula","enterOuterAlt","expression","match","EOF","re","exception","_errHandler","reportError","recover","exitRule","_p","undefined","_parentctx","_parentState","ExpressionContext","_prevctx","_startState","enterRecursionRule","RULE_expression","sync","la_","adaptivePredict","_input","TopLevelIntContext","SIGNED_INT","TopLevelNumberContext","NUMBER","TopLevelStringContext","RAW_STRING","UnaryExpressionContext","unary_op","BraceExpressionContext","T__0","T__1","FunctionCallContext","function_call","JmesPathContext","jmesPathExpression","stop","LT","_alt","_parseListeners","triggerExitRuleEvent","BinaryExpressionContext","pushNewRecursionContext","binary_op","PostfixContext","postfix_op","error","unrollRecursionContexts","Unary_opContext","RULE_unary_op","_la","LA","T__2","T__3","recoverInline","reportMatch","consume","Binary_opContext","RULE_binary_op","T__4","T__5","T__6","T__7","T__8","COMPARATOR","Postfix_opContext","RULE_postfix_op","T__9","Function_callContext","RULE_function_call","FUNCTIONS","expression_list","ParameterContext","RULE_parameter","Nonempty_expr_listContext","RULE_nonempty_expr_list","parameter","parm_separator","Expression_listContext","RULE_expression_list","T__14","T__16","T__18","T__21","T__22","T__23","JSON_CONSTANT","NAME","STRING","nonempty_expr_list","Parm_separatorContext","RULE_parm_separator","T__10","JmesPathExpressionContext","RULE_jmesPathExpression","BracketExpressionContext","bracketSpecifier","IdentifierExpressionContext","identifier","NotExpressionContext","ParenExpressionContext","WildcardExpressionContext","wildcard","MultiSelectListExpressionContext","multiSelectList","MultiSelectHashExpressionContext","multiSelectHash","LiteralExpressionContext","literal","FunctionCallExpressionContext","functionExpression","RawStringExpressionContext","CurrentNodeExpressionContext","currentNode","ComparisonExpressionContext","AndExpressionContext","T__12","OrExpressionContext","T__13","PipeExpressionContext","T__15","ChainExpressionContext","T__11","chainedExpression","BracketedExpressionContext","ChainedExpressionContext","RULE_chainedExpression","ChainedIdentifierContext","ChainedMultiSelectListContext","ChainedMultiSelectHashContext","ChainedFunctionExpressionContext","ChainedWildcardContext","WildcardContext","RULE_wildcard","MultiSelectListContext","RULE_multiSelectList","T__17","MultiSelectHashContext","RULE_multiSelectHash","keyvalExpr","T__19","KeyvalExprContext","RULE_keyvalExpr","T__20","BracketSpecifierContext","RULE_bracketSpecifier","BracketIndexContext","BracketStarContext","BracketSliceContext","slice","BracketFlattenContext","SelectContext","SliceContext","RULE_slice","start","step","FunctionExpressionContext","RULE_functionExpression","functionArg","FunctionArgContext","RULE_functionArg","expressionType","CurrentNodeContext","RULE_currentNode","ExpressionTypeContext","RULE_expressionType","LiteralContext","RULE_literal","jsonValue","IdentifierContext","RULE_identifier","JsonObjectContext","RULE_jsonObject","jsonObjectPair","JsonObjectPairContext","RULE_jsonObjectPair","JsonArrayContext","RULE_jsonArray","JsonValueContext","RULE_jsonValue","JsonStringValueContext","REAL_OR_EXPONENT_NUMBER","JsonNumberValueContext","JsonObjectValueContext","jsonObject","JsonArrayValueContext","jsonArray","JsonConstantValueContext","grammarFileName","WS","parser","parent","invokingState","getTypedRuleContext","getToken","listener","enterFormula","exitFormula","i","getTypedRuleContexts","enterBinaryExpression","exitBinaryExpression","enterJmesPath","exitJmesPath","enterTopLevelString","exitTopLevelString","enterTopLevelInt","exitTopLevelInt","enterFunctionCall","exitFunctionCall","enterBraceExpression","exitBraceExpression","enterPostfix","exitPostfix","enterUnaryExpression","exitUnaryExpression","enterTopLevelNumber","exitTopLevelNumber","enterUnary_op","exitUnary_op","enterBinary_op","exitBinary_op","enterPostfix_op","exitPostfix_op","enterFunction_call","exitFunction_call","enterParameter","exitParameter","enterNonempty_expr_list","exitNonempty_expr_list","enterExpression_list","exitExpression_list","enterParm_separator","exitParm_separator","enterPipeExpression","exitPipeExpression","enterIdentifierExpression","exitIdentifierExpression","enterNotExpression","exitNotExpression","enterRawStringExpression","exitRawStringExpression","enterComparisonExpression","exitComparisonExpression","enterParenExpression","exitParenExpression","enterBracketExpression","exitBracketExpression","enterOrExpression","exitOrExpression","enterCurrentNodeExpression","exitCurrentNodeExpression","enterChainExpression","exitChainExpression","enterAndExpression","exitAndExpression","enterMultiSelectHashExpression","exitMultiSelectHashExpression","enterWildcardExpression","exitWildcardExpression","enterFunctionCallExpression","exitFunctionCallExpression","enterMultiSelectListExpression","exitMultiSelectListExpression","enterBracketedExpression","exitBracketedExpression","enterLiteralExpression","exitLiteralExpression","enterChainedMultiSelectList","exitChainedMultiSelectList","enterChainedWildcard","exitChainedWildcard","enterChainedMultiSelectHash","exitChainedMultiSelectHash","enterChainedIdentifier","exitChainedIdentifier","enterChainedFunctionExpression","exitChainedFunctionExpression","enterWildcard","exitWildcard","enterMultiSelectList","exitMultiSelectList","enterMultiSelectHash","exitMultiSelectHash","enterKeyvalExpr","exitKeyvalExpr","enterSelect","exitSelect","enterBracketFlatten","exitBracketFlatten","enterBracketSlice","exitBracketSlice","enterBracketIndex","exitBracketIndex","enterBracketStar","exitBracketStar","getTokens","enterSlice","exitSlice","enterFunctionExpression","exitFunctionExpression","enterFunctionArg","exitFunctionArg","enterCurrentNode","exitCurrentNode","enterExpressionType","exitExpressionType","enterLiteral","exitLiteral","enterIdentifier","exitIdentifier","enterJsonObject","exitJsonObject","enterJsonObjectPair","exitJsonObjectPair","enterJsonArray","exitJsonArray","enterJsonArrayValue","exitJsonArrayValue","enterJsonStringValue","exitJsonStringValue","enterJsonObjectValue","exitJsonObjectValue","enterJsonConstantValue","exitJsonConstantValue","enterJsonNumberValue","exitJsonNumberValue","JSONFormulaLexer","channelNames","modeNames","Listener","data","traceOn","stack","msg","console","log","trace","getText","result","pop","op1","op","op2","push","toString","Math","pow","expr","x","jmespath","str","replace","func","text","toLowerCase","length","elem","Array","forEach","e","choice2","choice1","condition","Error","evaluate","json","chars","lexer","FELexer","debug","tokens","FEParser","buildParseTrees","parseError","ParseErrorListener","recognizer","offendingSymbol","line","column","parseErrHandler","removeErrorListeners","addErrorListener","tree","formula","extractor","document","getElementById","Field","name","val","value","readonly","required","createFields","childref","child","item","Object","keys","k","run","JSON","parse","checked","r","stringify","addEventListener","fetch","then","g4","innerHTML"],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;AACjC,cAAc,mBAAO,CAAC,GAAS;AAC/B,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAe;;AAE1C;AACA;;AAEA;AACA,2BAA2B,kBAAkB;AAC7C,IAAI,kBAAkB;AACtB;AACA;AACA;AACA,2CAA2C,wBAAwB;AACnE;AACA,qBAAqB,6BAA6B;AAClD,IAAI,4BAA4B;AAChC,IAAI,wBAAwB;AAC5B;AACA;AACA;;AAEA;AACA,UAAU,kBAAkB;AAC5B;AACA;AACA;AACA,mDAAmD,mBAAmB;AACtE,SAAS,WAAW;AACpB;AACA;;AAEA;AACA,qBAAqB,eAAe;AACpC,MAAM,gBAAgB,IAAI,gBAAgB,SAAS,WAAW,QAAQ;AACtE;AACA,MAAM,iBAAiB;AACvB;AACA;AACA,MAAM,uBAAuB;AAC7B;AACA,+BAA+B,gBAAgB;AAC/C;AACA;AACA;;AAEA;AACA,4BAA4B,iBAAiB;AAC7C,MAAM,oBAAoB,eAAe,eAAe;AACxD;AACA;AACA;AACA,UAAU,gBAAgB,0BAA0B,gBAAgB;AACpE;AACA;AACA,MAAM,mBAAmB,MAAM,UAAU,qBAAqB;AAC9D,UAAU;AACV,UAAU,cAAc;AACxB;AACA,MAAM,eAAe;AACrB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,QAAQ;AAC7B;AACA,aAAa,QAAQ,EAAE,WAAW,iCAAiC,QAAQ;AAC3E,KAAK,YAAY;AACjB;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS,QAAQ;AACjB;AACA,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA,iBAAiB,OAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,UAAU;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,0DAA0D,QAAQ;AAClE;AACA;AACA;AACA,qBAAqB,wBAAwB;AAC7C;AACA;AACA;AACA,YAAY,OAAO;AACnB,aAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,cAAc;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;;;;;;;ACjYA;AACA;AACA;AACA;;AAEA,oBAAoB,mBAAO,CAAC,GAAe;AAC3C,WAAW,mBAAO,CAAC,GAAI;;AAEvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;AC3EA;AACA;AACA;AACA;;AAEA,oBAAoB,oCAA8B;;AAElD;;AAEA;AACA,mCAAmC,mBAAmB;AACtD,IAAI,kBAAkB;AACtB;AACA;AACA;AACA;AACA;AACA,8BAA8B,2BAA2B;AACzD;AACA;AACA;AACA,8BAA8B,0BAA0B;AACxD,YAAY,2BAA2B;AACvC,YAAY,oCAAoC;AAChD,mBAAmB,qBAAqB;AACxC;AACA;AACA;AACA,iCAAiC,YAAY;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,gBAAgB,yBAAyB;AACzC;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;AC9DA;AACA;AACA;AACA;;;AAGA,cAAc,8BAAwB;AACtC,4BAA4B,mBAAO,CAAC,EAAuB;;AAE3D;AACA,uBAAuB,0BAA0B;AACjD;AACA,IAAI,wBAAwB;AAC5B;AACA;AACA;AACA,iBAAiB,gBAAgB;AACjC,+CAA+C,WAAW,GAAG,WAAW;AACxE,IAAI,WAAW;AACf;AACA;AACA;AACA,KAAK,6BAA6B;AAClC,IAAI,wBAAwB;AAC5B,SAAS,wBAAwB;AACjC;AACA;AACA;AACA,oCAAoC,aAAa;AACjD,IAAI,kBAAkB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,sBAAsB,uBAAuB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACnGA;AACA;AACA;AACA;;AAEA,oBAAoB,mBAAO,CAAC,GAAe;AAC3C,WAAW,mBAAO,CAAC,GAAI;;AAEvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACpBA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;AACjC,mBAAO,CAAC,GAAyB;AACjC,mBAAO,CAAC,GAA2B;;AAEnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA,GAAG;AACH,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY;AACZ;AACA;AACA,eAAe;AACf;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,2BAA2B;AAC3B;AACA;AACA;;AAEA;AACA;;AAEA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,uBAAuB,WAAW;AAClC;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;;;;;;;;ACjIA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;;AAEjC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,oBAAoB,6BAA6B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH,kBAAkB,2BAA2B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,eAAe,yBAAyB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,kBAAkB,2BAA2B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,2BAA2B;AAC5C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,YAAY,yBAAyB;AACrC,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,2BAA2B;AAC5C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,YAAY,yBAAyB;AACrC,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,2BAA2B;AAC5C;AACA,+BAA+B,mBAAmB;AAClD;AACA;AACA;AACA;AACA,YAAY,yBAAyB;AACrC,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;AChSA;AACA;AACA;AACA;;AAEA,OAAO,YAAY,GAAG,mBAAO,CAAC,GAAS;AACvC,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;AACjC,OAAO,UAAU,GAAG,mBAAO,CAAC,GAAiB;AAC7C,OAAO,YAAY,GAAG,mBAAO,CAAC,GAAe;AAC7C,OAAO,cAAc,GAAG,mBAAO,CAAC,GAAgB;AAChD,OAAO,kFAAkF,GAAG,mBAAO,CAAC,EAAkB;AACtH,OAAO,gFAAgF,GAAG,mBAAO,CAAC,GAAqB;;AAEvH;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAc,eAAe;AAC7B,+BAA+B,QAAQ;AACvC;AACA,0DAA0D,WAAW;AACrE;AACA;AACA,qEAAqE,QAAQ;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,YAAY;AAClC;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8CAA8C,QAAQ;AACtD,kBAAkB,UAAU;AAC5B;AACA,cAAc,UAAU,KAAK,WAAW;AACxC,QAAQ,QAAQ,cAAc,qBAAqB;AACnD,WAAW,UAAU,SAAS,WAAW;AACzC,iBAAiB,iBAAiB;AAClC;AACA;AACA;AACA,QAAQ,oBAAoB;AAC5B,mDAAmD,WAAW;AAC9D;AACA;AACA,kDAAkD,QAAQ;AAC1D,kBAAkB,UAAU;AAC5B;AACA;AACA;AACA,kCAAkC,iBAAiB;AACnD;AACA;AACA;AACA;AACA;;AAEA;AACA,8CAA8C,QAAQ;AACtD,kBAAkB,UAAU;AAC5B;AACA,cAAc,UAAU,KAAK,WAAW,MAAM,gBAAgB;AAC9D,wBAAwB,QAAQ,cAAc,qBAAqB;AACnE,2BAA2B,UAAU,SAAS,WAAW,MAAM,aAAa;AAC5E,QAAQ,WAAW,MAAM,gBAAgB;AACzC,iBAAiB,iBAAiB;AAClC;AACA;AACA;AACA,QAAQ,oBAAoB;AAC5B,yCAAyC,WAAW;AACpD;AACA;AACA;AACA;AACA,QAAQ,yBAAyB;AACjC;AACA;AACA,QAAQ,mBAAmB;AAC3B,4BAA4B,WAAW;AACvC,mBAAmB,WAAW,oCAAoC;AAClE,uDAAuD,iBAAiB;AACxE;AACA,0BAA0B,iBAAiB;AAC3C,sEAAsE;AACtE,WAAW,WAAW;AACtB;AACA;AACA,iCAAiC,6BAA6B;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gBAAgB;AACnD;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wBAAwB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mCAAmC,0BAA0B;AAC7D;AACA;;AAEA;;;;;;;;;AC5LA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;AACjC,mBAAmB,mBAAO,CAAC,GAAc;AACzC,2BAA2B,mBAAO,CAAC,EAAsB;AACzD,OAAO,qBAAqB,GAAG,mBAAO,CAAC,GAAgB;AACvD,OAAO,0BAA0B,GAAG,mBAAO,CAAC,GAAgB;;AAE5D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB;;AAEtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,6BAA6B;AAC7B;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,mCAAmC;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,+BAA+B;AAC/B;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,cAAc;AAC/B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;AAKA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;;AAGA;;;;;;;;ACrXA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;AACjC,OAAO,2CAA2C,GAAG,mBAAO,CAAC,GAAa;AAC1E,mBAAmB,mBAAO,CAAC,GAAc;AACzC,OAAO,qBAAqB,GAAG,mBAAO,CAAC,GAAuB;AAC9D,wBAAwB,mBAAO,CAAC,GAAuB;AACvD,kCAAkC,mBAAO,CAAC,GAAiC;AAC3E,cAAc,mBAAO,CAAC,GAAS;;AAE/B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,2BAA2B;AAC7C;AACA;AACA;AACA;AACA;AACA,UAAU,wBAAwB;AAClC;AACA;AACA;AACA;AACA;AACA,gDAAgD,WAAW;AAC3D;AACA;AACA;AACA,WAAW,kBAAkB,aAAa;AAC1C,MAAM,oBAAoB;AAC1B,oBAAoB,kBAAkB,cAAc;AACpD;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA;AACA;AACA;AACA,4BAA4B,6BAA6B;AACzD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,wCAAwC,YAAY;AACpD,cAAc,sCAAsC,MAAM,gBAAgB;AAC1E;AACA;AACA;AACA,KAAK,wCAAwC;AAC7C,sCAAsC,0BAA0B;AAChE,KAAK,WAAW;AAChB,KAAK,wCAAwC;AAC7C,+BAA+B,sCAAsC;AACrE;AACA;AACA;AACA;AACA,KAAK,YAAY;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,wCAAwC;AACxC,SAAS,gBAAgB;AACzB;AACA;AACA,KAAK,wCAAwC;AAC7C,sCAAsC,0BAA0B;AAChE,KAAK,WAAW;AAChB,KAAK,wCAAwC;AAC7C,+BAA+B,sCAAsC;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA,KAAK,+BAA+B;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,MAAM,cAAc;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY,eAAe;AAC3B;AACA,WAAW,eAAe,KAAK,WAAW;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,MAAM;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B,4CAA4C;AACxE;AACA,6CAA6C,QAAQ;AACrD,yDAAyD,QAAQ;AACjE,KAAK,QAAQ;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yCAAyC;AACtE,KAAK,uCAAuC;AAC5C;AACA;AACA,KAAK,6CAA6C;AAClD,KAAK,wCAAwC;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK,aAAa;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;;AAEA,UAAU,kBAAkB;AAC5B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA;;AAEA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,2BAA2B,aAAa;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,WAAW,KAAK,aAAa;AAC1C,wBAAwB,YAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,iBAAiB,MAAM,mBAAmB;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA,mBAAmB,UAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,uCAAuC;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B;AAC5B,mCAAmC,gDAAgD,EAAE;AACrF,iCAAiC,wCAAwC,EAAE;AAC3E,QAAQ;AACR;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,uEAAuE;AACvE,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACjrBA;AACA;AACA;AACA;;AAEA,oBAAoB,mBAAO,CAAC,GAAe;AAC3C,aAAa,mBAAO,CAAC,GAAa;AAClC;AACA;AACA;AACA;AACA,iBAAiB,iCAAiC;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,WAAW;AACpC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,eAAe,wBAAwB;AACvC;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,cAAc,wBAAwB;AACtC;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,eAAe,wBAAwB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,eAAe,wBAAwB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;;AAEA,qCAAqC,iEAAiB;AACtD;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;AChOA;AACA;AACA;AACA;;AAEA,oBAAoB,mBAAO,CAAC,GAAe;AAC3C,OAAO,uBAAuB,GAAG,mBAAO,CAAC,GAAS;;AAElD;;AAEA;AACA;AACA;;AAEA;AACA,2CAA2C,wBAAwB;AACnE;AACA;AACA;AACA;AACA,gBAAgB,mDAAmD,EAAE;AACrE,mBAAmB;AACnB;AACA,mBAAmB,OAAO,EAAE,gBAAgB;AAC5C,YAAY,2CAA2C,QAAQ;AAC/D,cAAc;AACd;AACA;AACA,mBAAmB,OAAO,EAAE,gBAAgB;AAC5C,YAAY,2CAA2C,QAAQ;AAC/D,oCAAoC;AACpC;AACA;AACA,YAAY,2CAA2C,YAAY;AACnE,aAAa;AACb;AACA;AACA;AACA,yBAAyB,cAAc;AACvC;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,eAAe,QAAQ;AACvB,IAAI,cAAc;AAClB;AACA;;AAEA;AACA,eAAe,QAAQ,yCAAyC;AAChE,2BAA2B,oBAAoB;AAC/C,IAAI,QAAQ,IAAI,2BAA2B;AAC3C;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH,gBAAgB;AAChB,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;;AAEA;;AAEA;AACA;AACA;AACA,WAAW,cAAc,0BAA0B,cAAc;AACjE;AACA,qBAAqB,2BAA2B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH,gBAAgB;AAChB,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,kBAAkB,8BAA8B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA,cAAc,kBAAkB,YAAY,wBAAwB;AACpE,WAAW,cAAc,KAAK,mBAAmB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,cAAc,iCAAiC;AAC/C;AACA,8CAA8C;AAC9C;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,wBAAwB;AACxB,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE,OAAO;AACT;AACA;AACA,yEAAyE;AACzE;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,sCAAsC,QAAQ,KAAK,QAAQ;AAC3D,IAAI,cAAc,yCAAyC,QAAQ;AACnE,iBAAiB,cAAc;AAC/B;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA,OAAO,cAAc,0BAA0B,SAAS,cAAc;AACtE;AACA;AACA,OAAO,cAAc,kBAAkB,cAAc;AACrD,IAAI,eAAe;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD;AACzD;AACA;AACA;AACA;AACA,6BAA6B,EAAE,cAAc;AAC7C;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,wBAAwB;AACxB,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA,kCAAkC;AAClC;AACA,EAAE;AACF;AACA,kCAAkC;AAClC,GAAG,0CAA0C;AAC7C;AACA;AACA;AACA;AACA,GAAG,0CAA0C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,cAAc,6BAA6B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,iCAAiC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,WAAW;AACX,WAAW;;AAEX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF;AACnF;AACA;AACA;AACA,gCAAgC;AAChC;AACA,IAAI,OAAO;AACX;AACA;AACA;AACA,UAAU;AACV,UAAU;AACV,GAAG,kDAAkD;AACrD;AACA;AACA;AACA,GAAG,OAAO;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,2BAA2B;AAC5C;AACA;AACA;AACA;AACA,EAAE;AACF,iBAAiB,2BAA2B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gCAAgC;AAChE,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,kCAAkC,eAAe,YAAY;AAC7D;AACA;AACA;AACA;;AAEA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA,mBAAmB,oBAAoB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA,iBAAiB,oBAAoB;AACrC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpuBA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAS;AACjC,OAAO,qBAAqB,GAAG,mBAAO,CAAC,GAAuB;AAC9D,OAAO,mBAAmB,GAAG,mBAAO,CAAC,GAAuB;;AAE5D;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,UAAU,EAAE;AACtE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD;AACA,yDAAyD,UAAU,EAAE;AACrE;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,yBAAyB;AACpD;AACA,QAAQ,iDAAiD;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;;;;;;;ACvIA;AACA;AACA;AACA;;AAEA,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAa;AACxC,OAAO,iBAAiB,GAAG,mBAAO,CAAC,GAAa;AAChD,cAAc,mBAAO,CAAC,EAAc;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;;AAE1B;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;AC/JA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB,sBAAsB;AACtB,oBAAoB,aAAa;AACjC,mBAAmB,aAAa;AAChC,yBAAyB;AACzB,mBAAmB;AACnB,qBAAqB;AACrB,oBAAoB;AACpB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA,sBAAsB,kBAAkB,uBAAuB,YAAY;AAC3E;AACA;AACA,QAAQ,eAAe,YAAY,kBAAkB;AACrD,qDAAqD,aAAa;AAClE,SAAS,WAAW,YAAY,eAAe,cAAc,aAAa;AAC1E,uCAAuC,gBAAgB,OAAO;AAC9D,4CAA4C,4BAA4B;AACxE,KAAK,4BAA4B;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,aAAa,WAAW;AACxB,IAAI,eAAe;AACnB;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;ACpJA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2BAA2B,mBAAmB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2BAA2B,mBAAmB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iBAAiB,iCAAiC;AAClD;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C;AACA,SAAS;AACT,mCAAmC,qBAAqB;AACxD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA,qBAAqB,sCAAsC;AAC3D,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClcA;AACA;AACA;AACA;;AAEA,oBAAoB,mBAAO,CAAC,GAAkB;AAC9C,OAAO,YAAY,GAAG,mBAAO,CAAC,GAAkB;AAChD,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;;AAEpC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB,gDAAgD,qBAAqB;AACrE;AACA;AACA;AACA,gDAAgD,kBAAkB;AAClE;AACA;AACA;AACA;AACA;;AAEA;AACA,yEAAyE,QAAQ;AACjF,WAAW,UAAU;AACrB,6BAA6B,QAAQ;AACrC,sDAAsD,QAAQ;AAC9D;AACA;AACA;AACA;AACA;;AAEA;AACA,mEAAmE,QAAQ;AAC3E,8BAA8B,qBAAqB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8CAA8C;AAC9C;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA,QAAQ,kBAAkB,wBAAwB,cAAc;AAChE;AACA;AACA;AACA,QAAQ,oBAAoB;AAC5B,iBAAiB,iBAAiB;AAClC;AACA,cAAc,cAAc,KAAK,WAAW;AAC5C,QAAQ,+BAA+B;AACvC;AACA;AACA;AACA;AACA,gBAAgB,YAAY;AAC5B;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;;;;;;;AC3JA;AACA;AACA;AACA;;AAEA,OAAO,cAAc,GAAG,mBAAO,CAAC,GAAY;AAC5C,OAAO,gBAAgB,GAAG,mBAAO,CAAC,GAAmB;AACrD,OAAO,KAAK,GAAG,mBAAO,CAAC,GAAU;;;AAGjC;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA,0CAA0C,+BAA+B;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA,wBAAwB;AACxB,6BAA6B;;;;;;;;AC3K7B;AACA;AACA;AACA;;AAEA,YAAY,mBAAO,CAAC,GAAO;AAC3B,cAAc,mBAAO,CAAC,GAAY;AAClC,OAAO,gBAAgB,GAAG,mBAAO,CAAC,GAAmB;AACrD,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAwB;;AAEhD;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE;AACF;AACA,EAAE;AACF;AACA;;AAEA;AACA,gBAAgB,WAAW,SAAS,iBAAiB,QAAQ;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,qBAAqB;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA,YAAY;AACZ;AACA;AACA;AACA,qDAAqD;AACrD;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK,oBAAoB,SAAS,QAAQ;AAC1C,KAAK,uBAAuB,GAAG,QAAQ,SAAS,qBAAqB;AACrE,KAAK,SAAS,SAAS,iCAAiC;AACxD,KAAK,eAAe;AACpB;AACA,4BAA4B,6BAA6B;AACzD,KAAK,2BAA2B;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oBAAoB;AAChD;AACA;;AAEA;AACA;AACA,iBAAiB,yBAAyB;AAC1C;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,yBAAyB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,yBAAyB;AAC1C;AACA;AACA;AACA;;AAEA;AACA,iBAAiB,iBAAiB;AAClC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;AC5PA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;;;;;;;ACxBA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,YAAY,mBAAO,CAAC,GAAO;AAC3B,gBAAgB,mBAAO,CAAC,GAAW;;AAEnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG,mBAAO,CAAC,GAAY;;AAExB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG,mBAAO,CAAC,EAAc;;AAE1B,OAAO,YAAY,GAAG,mBAAO,CAAC,GAAkB;AAChD,kCAAkC,mBAAO,CAAC,GAA6B;;AAEvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG,mBAAO,CAAC,GAAe;;AAE3B;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,6BAA6B,cAAc;AAC3C;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gDAAgD,WAAW;AAC3D;AACA;AACA,2BAA2B,WAAW;AACtC;AACA,8BAA8B,WAAW;AACzC;AACA,gBAAgB,WAAW,SAAS,iBAAiB;AACrD,6DAA6D,cAAc;AAC3E,kBAAkB,aAAa,YAAY;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,+BAA+B;AAChD;AACA;AACA;;AAEA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;;AAEA;AACA,iBAAiB,sBAAsB;AACvC;AACA;AACA;;AAEA;AACA,iBAAiB,uBAAuB;AACxC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,UAAU;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,qBAAqB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,UAAU;AAC/B;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,KAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,KAAK;AAC9B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,UAAU;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,qBAAqB;AACtC;AACA,qBAAqB,4BAA4B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,iBAAiB,qBAAqB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,4BAA4B;AACrD;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,yBAAyB,4BAA4B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,cAAc;AACnC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,oBAAoB,qBAAqB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA,gBAAgB,qBAAqB;AACrC;AACA,wBAAwB,4BAA4B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA,oBAAoB,yBAAyB;AAC7C,YAAY,+CAA+C;AAC3D;AACA;AACA;AACA;AACA,oBAAoB,qBAAqB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,oBAAoB,qBAAqB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,KAAK;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;;AAEA;;;AAGA;;;;;;;;AC1qBA;AACA;AACA;AACA;;AAEA,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAmB;AAC9C,OAAO,aAAa,GAAG,mBAAO,CAAC,EAAgB;AAC/C,OAAO,2BAA2B,GAAG,mBAAO,CAAC,GAAwB;AACrE,OAAO,IAAI,GAAG,mBAAO,CAAC,GAAY;;AAElC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;;;;;;;;ACnDA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,IAAI,4BAA4B;AAChC;AACA;AACA;AACA,0CAA0C;AAC1C,IAAI,wBAAwB;AAC5B;AACA;AACA,IAAI,iBAAiB;AACrB;AACA;AACA,IAAI,iBAAiB;AACrB;AACA;AACA,4DAA4D,UAAU;AACtE,gEAAgE,UAAU;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,aAAa;AACrC;AACA;AACA;AACA,iCAAiC,aAAa;AAC9C;AACA;AACA;AACA,yBAAyB,aAAa;AACtC;AACA;AACA;AACA;AACA;AACA,4BAA4B,cAAc;AAC1C;AACA;AACA;AACA,qCAAqC,cAAc;AACnD;AACA;AACA;AACA,6BAA6B,cAAc;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B,YAAY;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8BAA8B,cAAc;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,uBAAuB,SAAS,MAAM,aAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,aAAa,iBAAiB;AAC9B,oCAAoC;AACpC,yCAAyC,wBAAwB;AACjE,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1TA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACXA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,cAAc,mBAAO,CAAC,GAAY;AAClC,YAAY,mBAAO,CAAC,GAAO;AAC3B,qBAAqB,mBAAO,CAAC,GAAgB;AAC7C,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAmB;AAC9C,OAAO,oBAAoB,GAAG,mBAAO,CAAC,EAAgB;AACtD,OAAO,kBAAkB,GAAG,mBAAO,CAAC,GAAwB;AAC5D,OAAO,2BAA2B,GAAG,mBAAO,CAAC,GAAwB;AACrE,OAAO,cAAc,GAAG,mBAAO,CAAC,GAAY;AAC5C,OAAO,eAAe,GAAG,mBAAO,CAAC,GAAa;AAC9C,OAAO,WAAW,GAAG,mBAAO,CAAC,EAAc;AAC3C,4BAA4B,mBAAO,CAAC,GAAuB;AAC3D,OAAO,0BAA0B,GAAG,mBAAO,CAAC,GAAmB;;AAE/D;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS,sBAAsB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;;AAEd,gBAAgB;AAChB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,SAAS;AACvB;AACA;AACA;;AAEA;AACA;AACA;AACA,yBAAyB,WAAW;AACpC;AACA;AACA;AACA;AACA,KAAK,QAAQ,MAAM,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,QAAQ,MAAM,QAAQ;AAC3B,aAAa,cAAc;AAC3B;AACA;AACA;AACA;AACA;AACA;;AAEA,iCAAiC;AACjC;AACA,2DAA2D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,6BAA6B,QAAQ,aAAa,YAAY;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,kCAAkC;AACpD,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,sDAAsD;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,0BAA0B;AAC3C;AACA,mCAAmC,8CAA8C;AACjF;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA,aAAa,QAAQ,EAAE,WAAW;AAClC,KAAK,YAAY;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,qCAAqC,qDAAqD;AAC1F;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C;AACA,qDAAqD;AACrD;AACA,gCAAgC,wCAAwC;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,qCAAqC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,wCAAwC;AACtE,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,cAAc,GAAG,QAAQ,GAAG;;AAE5B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oBAAoB;AAClD;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,8DAA8D;AAC5F,IAAI;AACJ;AACA,+BAA+B,oBAAoB;AACnD;AACA,GAAG;AACH,6BAA6B,oBAAoB;AACjD,GAAG;AACH;AACA;AACA;AACA;AACA,gCAAgC,qBAAqB;AACrD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,kBAAkB,KAAK,WAAW;AAC7C,KAAK,gBAAgB;AACrB,KAAK,gBAAgB;AACrB,iCAAiC,qBAAqB,GAAG,qBAAqB;AAC9E,SAAS,uBAAuB;AAChC,6CAA6C,YAAY;AACzD;AACA,aAAa,gBAAgB;AAC7B;AACA;AACA;AACA;AACA,wBAAwB,WAAW,0BAA0B,YAAY;AACzE;AACA;AACA,aAAa,WAAW;AACxB,KAAK,WAAW;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD;;AAExD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,qCAAqC;;AAErC;;AAEA;;;;;;;;ACzoBA;AACA;AACA;AACA;;AAEA;AACA,sBAAsB,yBAAyB;AAC/C;AACA,sBAAsB,wBAAwB;AAC9C;AACA,sBAAsB,sBAAsB;AAC5C;AACA,qBAAqB,sBAAsB;AAC3C;AACA,qBAAqB,yBAAyB;AAC9C;AACA,qBAAqB,0BAA0B;AAC/C;AACA,qBAAqB,sBAAsB;AAC3C;AACA,qBAAqB,sBAAsB;AAC3C;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA,mBAAmB,WAAW,0BAA0B,kBAAkB;AAC1E;AACA,WAAW,WAAW;AACtB,mDAAmD,iBAAiB;AACpE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,mBAAmB,WAAW,0BAA0B;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA,mBAAmB,eAAe;AAClC,IAAI,sBAAsB;AAC1B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iDAAiD,sBAAsB;AACvE,0BAA0B,gBAAgB;AAC1C;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,mBAAmB,cAAc,0BAA0B,qBAAqB;AAChF;AACA,WAAW,cAAc;AACzB,mDAAmD,iBAAiB;AACpE;AACA;AACA;AACA;AACA;;AAEA;AACA,iDAAiD,qBAAqB;AACtE;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,mBAAmB,WAAW,0BAA0B,kBAAkB;AAC1E;AACA,WAAW,WAAW;AACtB,mDAAmD,iBAAiB;AACpE;AACA;AACA;AACA;AACA;;AAEA;AACA,iDAAiD,qBAAqB;AACtE;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;;AAGA;AACA,mBAAmB,WAAW,0BAA0B,kBAAkB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iDAAiD,kBAAkB;AACnE,0BAA0B,gBAAgB;AAC1C;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,8CAA8C,yBAAyB;AACvE;AACA;AACA,OAAO,yBAAyB;AAChC;AACA,wEAAwE,IAAI;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yBAAyB;AACjC;AACA,QAAQ,yBAAyB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,qDAAqD,oBAAoB;AACzE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA,mBAAmB,cAAc;AACjC,IAAI,wBAAwB;AAC5B,qBAAqB,cAAc;AACnC,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iDAAiD,wBAAwB;AACzE,0BAA0B,mBAAmB;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA,2BAA2B,kBAAkB;AAC7C,4CAA4C,0BAA0B;AACtE;AACA;AACA;AACA;AACA,uBAAuB,kCAAkC;AACzD,IAAI,gDAAgD;AACpD;AACA;AACA,WAAW,kBAAkB;AAC7B;AACA;AACA,IAAI,uCAAuC,UAAU,WAAW;AAChE;AACA,4CAA4C,iBAAiB;AAC7D;AACA;AACA;AACA,UAAU,iBAAiB;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6BAA6B,gBAAgB,mBAAmB;AAChE,2BAA2B,YAAY;AACvC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/XA;AACA;AACA;AACA;;AAEA,OAAO,UAAU,GAAG,mBAAO,CAAC,GAAU;AACtC,OAAO,yBAAyB,GAAG,mBAAO,CAAC,GAAe;;AAE1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,UAAU;AACzC;AACA;AACA;AACA;AACA,2BAA2B,iBAAiB;AAC5C,kCAAkC,+BAA+B;AACjE;AACA,gDAAgD;AAChD;AACA;AACA;;AAEA;AACA,eAAe,0BAA0B;AACzC;AACA;AACA;AACA,KAAK,uCAAuC,UAAU,WAAW;AACjE,KAAK,sBAAsB,eAAe,iBAAiB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,WAAW;AACrE;AACA;AACA;AACA;AACA,aAAa,oBAAoB,IAAI,0BAA0B;AAC/D;AACA;AACA;AACA;AACA,iBAAiB,8BAA8B;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,YAAY;AAC5B;AACA,0BAA0B,sBAAsB;AAChD,KAAK,YAAY,EAAE,iBAAiB;AACpC,KAAK,2BAA2B;AAChC;AACA;AACA;AACA;AACA;AACA,6CAA6C,uBAAuB;AACpE,KAAK,YAAY;AACjB;AACA;AACA,KAAK,sBAAsB,aAAa,YAAY;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,8BAA8B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,eAAe,0BAA0B;AACzC,eAAe,0BAA0B;AACzC,KAAK,kBAAkB;AACvB;AACA;AACA;AACA,KAAK,qBAAqB,cAAc,WAAW;AACnD;AACA;AACA,kBAAkB,0BAA0B;AAC5C;AACA,aAAa,oBAAoB,IAAI,0BAA0B;AAC/D,QAAQ,0BAA0B,MAAM,kBAAkB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;;;;;;;AC5KA;AACA;AACA;AACA;;AAEA,cAAc,mBAAO,CAAC,GAAY;AAClC,OAAO,wBAAwB;;AAE/B,YAAY,mBAAO,CAAC,GAAO;AAC3B,OAAO,wBAAwB,GAAG,mBAAO,CAAC,GAAY;;AAEtD,OAAO,UAAU,GAAG,mBAAO,CAAC,GAAa;AACzC,OAAO,aAAa,GAAG,mBAAO,CAAC,EAAgB;AAC/C,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,OAAO,yBAAyB,GAAG,mBAAO,CAAC,GAAmB;AAC9D,qBAAqB,mBAAO,CAAC,GAAgB;AAC7C,uBAAuB,mBAAO,CAAC,GAAkB;AACjD,oBAAoB,mBAAO,CAAC,GAAkB;AAC9C,0BAA0B,mBAAO,CAAC,GAAwB;AAC1D,OAAO,gBAAgB,GAAG,mBAAO,CAAC,GAAmB;AACrD,OAAO,kBAAkB,GAAG,mBAAO,CAAC,GAAwB;AAC5D,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAkB;AAC7C,OAAO,8EAA8E,GAAG,mBAAO,CAAC,EAAc;AAC9G,OAAO,qBAAqB,GAAG,mBAAO,CAAC,GAAmB;AAC1D,OAAO,6DAA6D,GAAG,mBAAO,CAAC,GAAwB;;;AAGvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,qBAAqB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E;AAC5E,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,sBAAsB;AAC/B,IAAI,6BAA6B;AACjC,IAAI,wBAAwB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yBAAyB,eAAe,sBAAsB;AACtE,4CAA4C;AAC5C;AACA,IAAI,sBAAsB,SAAS,oBAAoB;AACvD;AACA;AACA;AACA;AACA,IAAI,oBAAoB;AACxB;AACA,oBAAoB,wBAAwB;AAC5C;AACA;AACA,IAAI,gBAAgB,+BAA+B,eAAe;AAClE,IAAI,WAAW;AACf,IAAI,kBAAkB,sBAAsB,sBAAsB;AAClE,gDAAgD,sBAAsB;AACtE,IAAI,WAAW,aAAa,WAAW,MAAM,mBAAmB;AAChE,IAAI,mBAAmB;AACvB,IAAI,mBAAmB;AACvB,8CAA8C,KAAK,WAAW;AAC9D,iDAAiD,mBAAmB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,WAAW,gDAAgD,EAAE,6CAA6C,SAAS,2BAA2B;AAC9I,WAAW,8CAA8C,MAAM,wBAAwB;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,OAAO,SAAS;AAC5E,yDAAyD,OAAO,MAAM;AACtE;AACA,kBAAkB,OAAO,MAAM,KAAK,OAAO,MAAM;AACjD;AACA,0BAA0B,OAAO,GAAG,KAAK,OAAO,GAAG;AACnD,4BAA4B,OAAO,GAAG;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oEAAoE;AACpE,0EAA0E;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,mCAAmC;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,4BAA4B,WAAW;AACvC;AACA;AACA;AACA;AACA,QAAQ,QAAQ,MAAM,WAAW;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,QAAQ,MAAM,QAAQ;AAC9B,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD;AACzD,SAAS;AACT;AACA,wCAAwC,EAAE;AAC1C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB,KAAK,GAAG,KAAK,GAAG,EAAE,GAAG,KAAK;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,qBAAqB,wBAAwB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,6BAA6B;AACrD;AACA;AACA;AACA,+CAA+C,aAAa;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,6BAA6B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,4BAA4B;AACrD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA,QAAQ,cAAc,iBAAiB,oBAAoB;AAC3D,0BAA0B,cAAc;AACxC,8BAA8B,cAAc;AAC5C;AACA,gBAAgB,sBAAsB;AACtC,QAAQ,sBAAsB,4BAA4B,cAAc;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,cAAc;AACtB;AACA,gBAAgB,cAAc,2BAA2B,cAAc;AACvE;AACA,gCAAgC,cAAc;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wBAAwB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,qBAAqB;AACnE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA,qCAAqC,gDAAgD;AACrF;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ,0BAA0B;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sCAAsC;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,UAAU,KAAK,cAAc;AAC/C;AACA,QAAQ,gBAAgB;AACxB;AACA,6BAA6B,WAAW,uBAAuB;AAC/D;AACA;AACA;AACA;AACA,QAAQ,0BAA0B;AAClC;AACA;AACA,gBAAgB,4BAA4B;AAC5C;AACA;AACA;AACA;AACA;AACA,oBAAoB,wBAAwB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,+BAA+B;AAC5E,aAAa;AACb;AACA;AACA;AACA,oBAAoB,wBAAwB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,WAAW;AACjC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,oBAAoB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,QAAQ,2BAA2B;AACnC,QAAQ,cAAc;AACtB;AACA;AACA;AACA;AACA;AACA,QAAQ,wBAAwB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,8BAA8B;AAC5D;AACA;AACA;AACA;AACA,2CAA2C,+BAA+B;AAC1E;AACA;AACA;AACA,QAAQ,wBAAwB;AAChC,QAAQ,2BAA2B;AACnC,QAAQ,+BAA+B;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,cAAc;AAC1B;AACA;AACA;AACA,yCAAyC,wBAAwB;AACjE,QAAQ,8BAA8B;AACtC,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,yBAAyB;AACvD;AACA;AACA,uDAAuD,oDAAoD;AAC3G;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,uBAAuB;AAC7C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,WAAW,OAAO;AACtC;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,WAAW,OAAO;AACtC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,wCAAwC;AACxC;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,gBAAgB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8BAA8B,eAAe;AAC7C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,gBAAgB,UAAU;AACjE;AACA,aAAa;AACb;AACA,mCAAmC,2CAA2C;AAC9E;AACA,SAAS;AACT,+BAA+B,gBAAgB;AAC/C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,gBAAgB,UAAU;AACjE;AACA,aAAa;AACb;AACA,mCAAmC,2CAA2C;AAC9E;AACA,SAAS;AACT,+BAA+B,gBAAgB;AAC/C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,mCAAmC;AACjE;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ,oBAAoB,gBAAgB,SAAS;AACrD,gBAAgB,WAAW,KAAK,WAAW,SAAS,QAAQ;AAC5D;AACA;AACA;AACA,cAAc,SAAS,KAAK,WAAW,uBAAuB,WAAW;AACzE,2CAA2C,eAAe;AAC1D,QAAQ,oBAAoB,UAAU,SAAS;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,SAAS,KAAK,WAAW,uBAAuB;AACnE,4DAA4D;AAC5D,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,QAAQ;AAC1B,wEAAwE;AACxE;AACA,uBAAuB,QAAQ;AAC/B;AACA,cAAc,QAAQ,KAAK,cAAc,uBAAuB,cAAc;AAC9E;AACA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ,4BAA4B,QAAQ;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACprDA;AACA;AACA;AACA;;AAEA,OAAO,gCAAgC,GAAG,mBAAO,CAAC,GAAY;AAC9D,YAAY,mBAAO,CAAC,GAAO;AAC3B,OAAO,cAAc,GAAG,mBAAO,CAAC,GAAY;AAC5C,OAAO,aAAa,GAAG,mBAAO,CAAC,EAAgB;AAC/C,OAAO,UAAU,GAAG,mBAAO,CAAC,GAAa;AACzC,OAAO,gBAAgB,GAAG,mBAAO,CAAC,GAAmB;;AAErD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,WAAW;AACnB,mDAAmD,YAAY;AAC/D;AACA;AACA,iBAAiB,WAAW;AAC5B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,mDAAmD,WAAW;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,OAAO,KAAK,MAAM,OAAO,KAAK;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,sDAAsD,IAAI;AACrE;AACA,4DAA4D,QAAQ,EAAE;AACtE,mCAAmC,iCAAiC;AACpE,QAAQ,cAAc,MAAM,cAAc;AAC1C;AACA,YAAY,eAAe;AAC3B;AACA;AACA;AACA,WAAW,iDAAiD;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,mBAAmB;AACnD;AACA;AACA;AACA,WAAW,kBAAkB,eAAe,EAAE,EAAE;AAChD;AACA;AACA,QAAQ,QAAQ,MAAM,SAAS;AAC/B,6BAA6B,kBAAkB;AAC/C;AACA;AACA,WAAW,kBAAkB,eAAe,EAAE,iBAAiB,EAAE;AACjE;AACA;AACA,QAAQ,uCAAuC;AAC/C;AACA,QAAQ,mBAAmB;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD;AACA,uCAAuC,qCAAqC;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA,uCAAuC,cAAc;AACrD,QAAQ,oBAAoB;AAC5B;AACA;AACA;AACA;AACA,gBAAgB,WAAW,0BAA0B,cAAc;AACnE,QAAQ,oBAAoB,aAAa;AACzC;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA,wCAAwC,cAAc;AACtD,QAAQ,oBAAoB;AAC5B;AACA;AACA;AACA;AACA,gBAAgB,WAAW,2BAA2B,cAAc;AACpE,QAAQ,oBAAoB,aAAa;AACzC;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,QAAQ;AACxE,4BAA4B,qBAAqB;AACjD;AACA,kBAAkB,uBAAuB,MAAM,yBAAyB;AACxE,sBAAsB,qBAAqB,cAAc;AACzD,YAAY,qBAAqB,MAAM,WAAW;AAClD;AACA;AACA;AACA;AACA,WAAW,iBAAiB,oBAAoB;AAChD,QAAQ,QAAQ,UAAU,QAAQ,MAAM,UAAU;AAClD;AACA,qDAAqD,QAAQ,KAAK,QAAQ;AAC1E;AACA;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA,yBAAyB,UAAU,iBAAiB,cAAc;AAClE;AACA,cAAc,kBAAkB;AAChC,QAAQ,QAAQ,MAAM,UAAU;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,gBAAgB,MAAM,iBAAiB;AACrE,aAAa,WAAW,MAAM,WAAW;AACzC,QAAQ,gBAAgB;AACxB,aAAa,QAAQ,uCAAuC,QAAQ;AACpE,QAAQ,QAAQ;AAChB,4DAA4D,QAAQ;AACpE,QAAQ,SAAS;AACjB,iEAAiE,QAAQ;AACzE,QAAQ,SAAS,UAAU,QAAQ,qCAAqC;AACxE,8BAA8B,QAAQ;AACtC,0BAA0B,aAAa,uBAAuB,QAAQ;AACtE,wBAAwB,UAAU;AAClC,QAAQ,QAAQ,sCAAsC,QAAQ;AAC9D;AACA;AACA,8DAA8D,QAAQ;AACtE,QAAQ,SAAS;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,sBAAsB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA,aAAa,gBAAgB,GAAG,gBAAgB,GAAG,gBAAgB;AACnE,QAAQ,iBAAiB,GAAG,iBAAiB;AAC7C,QAAQ,OAAO,GAAG,qBAAqB,WAAW,IAAI,EAAE,IAAI,WAAW,IAAI,EAAE;AAC7E,QAAQ,OAAO,KAAK,MAAM;AAC1B;AACA;AACA,YAAY,gBAAgB,GAAG,gBAAgB,GAAG,iBAAiB;AACnE,QAAQ,iBAAiB,GAAG,kBAAkB;AAC9C,QAAQ,OAAO,GAAG,qBAAqB,WAAW,IAAI,EAAE,IAAI,WAAW,IAAI,EAAE;AAC7E,QAAQ,OAAO,GAAG,MAAM;AACxB;AACA,YAAY,gBAAgB,GAAG,gBAAgB,GAAG,iBAAiB;AACnE,QAAQ,iBAAiB,mCAAmC,OAAO,GAAG;AACtE,QAAQ,OAAO,GAAG,IAAI,OAAO,GAAG,MAAM;AACtC,kBAAkB,OAAO,KAAK;AAC9B;AACA,YAAY,gBAAgB,GAAG,gBAAgB,GAAG,iBAAiB;AACnE,QAAQ,iBAAiB,mCAAmC,OAAO,GAAG;AACtE,QAAQ,OAAO,GAAG,IAAI,OAAO,KAAK,MAAM;AACxC;AACA,YAAY,gBAAgB,GAAG,gBAAgB,GAAG,iBAAiB;AACnE,QAAQ,iBAAiB,mCAAmC,OAAO,GAAG;AACtE,QAAQ,OAAO,GAAG,IAAI,OAAO,KAAK,MAAM;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA,qEAAqE;AACrE,+CAA+C,UAAU;AACzD,QAAQ,UAAU,IAAI,GAAG,MAAM;AAC/B,oCAAoC,OAAO,GAAG;AAC9C;AACA;AACA;AACA,QAAQ,UAAU,MAAM,KAAK,QAAQ,IAAI,EAAE,MAAM;AACjD;AACA;AACA;AACA,KAAK;;AAEL;AACA,kDAAkD,cAAc;AAChE;AACA;AACA;AACA,gBAAgB,WAAW,WAAW,aAAa,KAAK,cAAc;AACtE,QAAQ,sCAAsC,KAAK,eAAe;AAClE;AACA;AACA;AACA,KAAK;AACL;AACA,uDAAuD,cAAc;AACrE;AACA;AACA;AACA,gBAAgB,WAAW,KAAK,cAAc,aAAa,aAAa;AACxE,QAAQ,sCAAsC,eAAe;AAC7D;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;;AAGL;AACA,uDAAuD,cAAc;AACrE;AACA;AACA;AACA,gBAAgB,WAAW,KAAK,cAAc,aAAa,aAAa;AACxE,QAAQ,sCAAsC,KAAK,eAAe;AAClE;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;;AAGL;AACA,kDAAkD,cAAc;AAChE;AACA;AACA,gBAAgB,WAAW,qBAAqB,cAAc;AAC9D,0BAA0B;AAC1B;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,KAAK;;;AAGL;AACA;AACA,QAAQ,cAAc;AACtB,QAAQ,8BAA8B;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;;AAEL;AACA;AACA,mEAAmE;AACnE,WAAW,cAAc;AACzB;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA,qCAAqC,cAAc,EAAE;AACrD;AACA,KAAK;;AAEL;AACA;AACA,+BAA+B,QAAQ,KAAK,cAAc;AAC1D;AACA;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA;AACA;AACA,mDAAmD,+CAA+C;AAClG,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;;AAEL;AACA;AACA,sBAAsB,QAAQ,KAAK,cAAc;AACjD;AACA;AACA,cAAc,6BAA6B,QAAQ;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;;AAEL;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA,aAAa,2BAA2B;AACxC;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACjjBA;AACA;AACA;AACA;;AAEA,OAAO,yBAAyB,GAAG,mBAAO,CAAC,GAAY;;AAEvD;AACA;AACA;AACA,kBAAkB,aAAa,wBAAwB,aAAa;AACpE;AACA,yBAAyB,UAAU,GAAG,SAAS,OAAO,gBAAgB;AACtE,IAAI,sBAAsB;AAC1B;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,aAAa,kCAAkC,WAAW;AACnE;AACA,SAAS,WAAW,kCAAkC,YAAY;AAClE;AACA,SAAS,WAAW;AACpB;AACA,eAAe,WAAW,EAAE,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;;AAGA;;AAEA;AACA;AACA;AACA;AACA,8EAA8E;AAC9E;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA,WAAW,8CAA8C;AACzD;AACA;;AAEA;AACA,gBAAgB,sBAAsB;AACtC,4BAA4B,OAAO,KAAK;AACxC;AACA;;;AAGA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA,WAAW,8BAA8B;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,uBAAuB;AACxC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,uBAAuB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,uBAAuB;AACxC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,uBAAuB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;ACzYA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,OAAO,YAAY,GAAG,mBAAO,CAAC,GAAkB;AAChD,OAAO,+BAA+B,GAAG,mBAAO,CAAC,GAAmB;;AAEpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,UAAU,oBAAoB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;AAEA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,kFAAkF;AAClF;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9SA;AACA;AACA;AACA;;AAEA,sCAA8B;AAC9B,kDAAsD;AACtD,oDAA0D;AAC1D,qDAA4D;AAC5D,8CAAoD;;;;;;;;ACTpD;AACA;AACA;AACA;;AAEA,OAAO,IAAI,GAAG,mBAAO,CAAC,GAAU;AAChC,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAY;AACvC,OAAO,mBAAmB,GAAG,mBAAO,CAAC,GAAiB;AACtD,OAAO,aAAa,GAAG,mBAAO,CAAC,EAAuB;AACtD,OAAO,cAAc,GAAG,mBAAO,CAAC,GAAiB;AACjD,OAAO,mBAAmB,GAAG,mBAAO,CAAC,GAAiB;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,UAAU;AAC7C,OAAO,UAAU;AACjB;AACA;AACA;AACA;AACA,MAAM,WAAW,0CAA0C;AAC3D,MAAM,YAAY,iCAAiC,wBAAwB;AAC3E,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK,WAAW;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,eAAe;AAC5B,YAAY,oBAAoB,KAAK,YAAY;AACjD,KAAK,WAAW,YAAY,YAAY;AACxC,KAAK,eAAe,yBAAyB,sBAAsB;AACnE;AACA,aAAa,sBAAsB;AACnC;AACA;AACA,0BAA0B,WAAW,6BAA6B;AAClE,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;;;;;;;;ACjKA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA,4BAA4B,IAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,kBAAkB;;;;;;;;;AC3ElB;AACA;AACA;AACA;;AAEA,OAAO,aAAa,GAAG,mBAAO,CAAC,EAAuB;AACtD,OAAO,UAAU,GAAG,mBAAO,CAAC,GAAY;;AAExC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,oBAAoB;AAC1B,MAAM,iBAAiB,UAAU,eAAe;AAChD;AACA;AACA;AACA;AACA;AACA,qBAAqB,8BAA8B,OAAO;AAC1D,MAAM,aAAa,KAAK,4BAA4B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,kCAAkC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,4BAA4B,KAAK,YAAY;AACnD;AACA,4CAA4C,mBAAmB;AAC/D,MAAM,8BAA8B;AACpC;AACA,mCAAmC,4BAA4B;AAC/D;AACA;AACA;AACA;AACA,kCAAkC;AAClC,2CAA2C;AAC3C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA,SAAS,eAAe;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,sCAAsC;AAC3C;AACA,KAAK,oBAAoB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB;;;;;;;;AC3JlB;AACA;AACA;AACA;;AAEA,sCAA8B;AAC9B,4DAAgE;AAChE,iEAA0E;AAC1E,6DAA6D;;;;;;;;ACR7D;AACA;AACA;AACA;;AAEA,OAAO,OAAO,GAAG,mBAAO,CAAC,GAAY;AACrC,OAAO,cAAc,GAAG,mBAAO,CAAC,GAAiB;AACjD,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAkB;;;AAG7C;AACA,2BAA2B,yBAAyB;AACpD;AACA,yBAAyB,mCAAmC;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,SAAS,IAAI,SAAS;AAClC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,mBAAmB,eAAe,WAAW;AAClE,oDAAoD,cAAc;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B;AAC3C;AACA;AACA,WAAW,EAAE,4BAA4B;AACzC;AACA;;AAEA;;;;;;;;ACxGA;AACA;AACA;AACA;;AAEA;AACA,gDAAgD,yBAAyB;AACzE;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA,2CAA2C,kBAAkB;AAC7D,cAAc,WAAW,GAAG,yBAAyB,OAAO,UAAU;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA,mCAAmC,2BAA2B;AAC9D;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,kBAAkB;;;;;;;;;AChFlB;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,OAAO,mGAAmG,GAAG,mBAAO,CAAC,GAAU;AAC/H,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAmB;AAC9C,OAAO,sBAAsB,GAAG,mBAAO,CAAC,GAAkB;;AAE1D;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA,0CAA0C,yBAAyB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,mDAAmD,0BAA0B;AAC7E;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,QAAQ;AACR,mDAAmD,0BAA0B;AAC7E;AACA;AACA;AACA;;AAEA;AACA,QAAQ;AACR;AACA;AACA,oDAAoD;AACpD,uEAAuE;AACvE;AACA;AACA;AACA,YAAY,2BAA2B;AACvC,QAAQ,kCAAkC;AAC1C,YAAY,6BAA6B;AACzC,QAAQ,4BAA4B;AACpC,YAAY,+BAA+B;AAC3C,QAAQ,8BAA8B;AACtC,mCAAmC,mCAAmC;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,sCAAsC,+BAA+B;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gCAAgC;AAC/C;AACA;AACA,+CAA+C,aAAa;AAC5D;AACA;AACA;AACA;AACA,wCAAwC,aAAa,GAAG,aAAa;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,YAAY;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,EAAE;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B,oBAAoB;AAC9C,QAAQ,2BAA2B;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B,oBAAoB;AAC9C,QAAQ,6BAA6B;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B,oBAAoB;AAC9C,QAAQ,+BAA+B;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,oCAAoC,YAAY;AAChD;AACA,QAAQ,iBAAiB;AACzB;AACA,sCAAsC,4BAA4B;AAClE;AACA;AACA;AACA;AACA,iDAAiD,4BAA4B;AAC7E;AACA,QAAQ,mCAAmC;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,wBAAwB,iBAAiB;AACzC;AACA,sCAAsC,6BAA6B;AACnE;AACA;AACA;AACA;AACA,iDAAiD,4BAA4B;AAC7E;AACA,QAAQ,mCAAmC;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ,6BAA6B;AACrC;AACA;AACA;AACA,WAAW,YAAY,qCAAqC,YAAY;AACxE,0CAA0C,YAAY;AACtD;AACA,YAAY,YAAY;AACxB;AACA,oDAAoD;AACpD,6BAA6B;AAC7B;AACA;AACA;AACA,gCAAgC,YAAY;AAC5C,2BAA2B,YAAY;AACvC,6BAA6B,mBAAmB;AAChD;AACA;AACA;AACA,oDAAoD;AACpD,8BAA8B;AAC9B;AACA;AACA;AACA,8BAA8B,YAAY,yBAAyB,UAAU;AAC7E,mDAAmD,WAAW;AAC9D;AACA;AACA;AACA,kBAAkB,YAAY;AAC9B;AACA;AACA,2CAA2C,UAAU;AACrD;AACA;AACA;AACA,YAAY,kCAAkC;AAC9C;AACA;AACA;AACA,6BAA6B,UAAU,yBAAyB,QAAQ,EAAE;AAC1E,aAAa,sBAAsB,4BAA4B,eAAe;AAC9E,oDAAoD,UAAU;AAC9D,gBAAgB,WAAW,qCAAqC,UAAU;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;;AAEA;AACA;AACA,kCAAkC,sBAAsB;AACxD;AACA,uBAAuB,WAAW,GAAG,iBAAiB;AACtD;AACA;AACA;AACA,wBAAwB,YAAY;AACpC,+BAA+B,YAAY;AAC3C,QAAQ,WAAW;AACnB;AACA;AACA;AACA,gBAAgB,WAAW;AAC3B,6DAA6D;AAC7D;AACA;AACA;AACA;AACA,yDAAyD;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA,kCAAkC,sBAAsB;AACxD;AACA;AACA,QAAQ,iBAAiB;AACzB;AACA;AACA;AACA,QAAQ,4BAA4B;AACpC,QAAQ,sBAAsB;AAC9B,yBAAyB,oBAAoB;AAC7C;AACA;AACA;AACA,yCAAyC,YAAY;AACrD;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,yCAAyC;AACzC;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,0BAA0B,OAAO;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,QAAQ;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA,2BAA2B,yBAAyB;AACpD;AACA,IAAI,iCAAiC;AACrC,IAAI,mCAAmC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8BAA8B;AACpD;AACA;AACA;AACA,QAAQ,wBAAwB;AAChC;AACA;AACA;AACA;AACA,IAAI,yDAAyD;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6CAA6C,QAAQ;AACrD,aAAa,iCAAiC;AAC9C,mCAAmC,4BAA4B;AAC/D,iBAAiB,2BAA2B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA,kBAAkB;;;;;;;;ACvwBlB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,oBAAoB,GAAG,mBAAO,CAAC,EAAqB;AAC3D,OAAO,SAAS,GAAG,iCAAkC;;AAErD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC,qEAAqE;AACrE;AACA;AACA;AACA;AACA;AACA,0BAA0B,2BAA2B;AACrD,YAAY,gCAAgC;AAC5C,YAAY,oBAAoB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,4BAA4B,WAAW;AACvC;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,wDAAwD;AACvE;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAA4D;AAC3E;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8FAA8F;AAC7G;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,mCAAmC,kBAAkB;AACrD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7KA;AACA;AACA;AACA;;AAEA,mFAA8E;AAC9E,mFAA8E;AAC9E,wEAAwF;AACxF,qEAAkF;AAClF,2FAAsF;AACtF,8CAA6E;AAC7E,gEAA+E;AAC/E,mEAAqF;AACrF,qEAAuE;;;;;;;;ACbvE;AACA;AACA;AACA;AACA,sCAAoC;AACpC,8CAAwD;AACxD,qCAAoC;AACpC,8CAA4D;AAC5D,uCAAsC;AACtC,wCAAwC;AACxC,8CAAwC;AACxC,8CAA8C;AAC9C,0DAAoD;AACpD,8CAA8C;AAC9C,8CAA4C;AAC5C,oDAA0D;AAC1D,wCAAkC;AAClC,wCAAoC;AACpC,SAAS,mBAAO,CAAC,GAAqB;AACtC,SAA8B;AAC9B,oDAA0D;AAC1D,uDAAoD;AACpD,0DAA0D;AAC1D,8CAAkC;AAClC,0DAA0D;;;;;;;;ACxB1D;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;AACA,EAAE;AACF;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA,KAAK,OAAO,sBAAsB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;AACA,EAAE;AACF;;;;;;;;AC9DA;AACA;AACA;AACA;;AAEA,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,OAAO,SAAS,GAAG,mBAAO,CAAC,GAAkB;AAC7C;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,4CAA4C,iCAAiC;AAC7E;AACA,KAAK,gCAAgC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,kBAAkB,uBAAuB;AACzC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iEAAiE;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnOA;AACA;AACA;AACA;;AAEA,cAAc,mBAAO,CAAC,GAAY;AAClC,OAAO,MAAM,GAAG,mBAAO,CAAC,GAAY;AACpC,OAAO,kCAAkC,GAAG,mBAAO,CAAC,GAAQ;;AAE5D;AACA;AACA;AACA,6CAA6C,oBAAoB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,IAAI;AACxB;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA,KAAK;;AAEL;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACzIA;AACA;AACA;AACA;;AAEA,aAAa,mBAAO,CAAC,GAAQ;AAC7B,cAAc,mBAAO,CAAC,EAAS;AAC/B,kBAAkB;;;;;;;;ACPlB;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kBAAkB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,4CAA4C;AAC5C,eAAe;AACf,+BAA+B;AAC/B;AACA,mDAAmD;AACnD;AACA,eAAe;AACf;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,+BAA+B;AAC/B;AACA,4CAA4C;AAC5C,eAAe;AACf;AACA;AACA,+BAA+B;AAC/B;AACA,4CAA4C;AAC5C,eAAe;AACf;AACA;AACA,+BAA+B;AAC/B;AACA,4CAA4C;AAC5C,eAAe;AACf;AACA,eAAe;AACf;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA,mCAAmC,yCAAyC;AAC5E,mBAAmB;AACnB,mCAAmC,2CAA2C;AAC9E;AACA,eAAe;AACf;AACA;AACA;AACA;AACA,mCAAmC,wCAAwC;AAC3E,mBAAmB;AACnB,mCAAmC,yCAAyC;AAC5E;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB,WAAW;AACX;AACA,sBAAsB;AACtB,WAAW;AACX,sBAAsB;AACtB;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,eAAe;AACf,wBAAwB;AACxB;AACA,WAAW;AACX;AACA;AACA,0BAA0B;AAC1B,eAAe;AACf,0BAA0B;AAC1B;AACA,WAAW;AACX;AACA;AACA,0BAA0B;AAC1B,eAAe;AACf,0BAA0B;AAC1B;AACA,WAAW;AACX;AACA;AACA,0BAA0B;AAC1B;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,iCAAiC;AACjC;AACA;;AAEA;AACA;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,uBAAuB,mDAAmD;AAC1E;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA,OAAO;;AAEP;AACA;AACA,OAAO;;AAEP;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA,wBAAwB;AACxB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA,yBAAyB;AACzB,aAAa;AACb;AACA;AACA,oBAAoB;AACpB;AACA,yCAAyC,iBAAiB;AAC1D;AACA;AACA;AACA,oBAAoB,+BAA+B,iBAAiB;AACpE;AACA,oBAAoB;AACpB;AACA;AACA;AACA,6CAA6C,iBAAiB;AAC9D,aAAa;AACb;AACA;AACA;AACA;AACA,wBAAwB;AACxB,oCAAoC,iBAAiB;AACrD,aAAa;AACb;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB,aAAa;AACb;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,aAAa;AACb;AACA;AACA,oBAAoB;AACpB;AACA,4BAA4B;AAC5B;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;;AAGP;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA,gBAAgB;AAChB,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA,uBAAuB;AACvB,WAAW;AACX;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB,OAAO;;AAEP;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C;AACA;AACA,eAAe;AACf,iCAAiC,UAAU;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA,6BAA6B,qBAAqB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qBAAqB;AAC9C;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,wCAAwC,qBAAqB,EAAE;AAC7E,cAAc,wCAAwC,2BAA2B,EAAE;AACnF,eAAe,yCAAyC,qBAAqB,EAAE;AAC/E;AACA;AACA,0BAA0B,iCAAiC;AAC3D,yBAAyB,kBAAkB,EAAE;AAC7C;AACA;AACA,0BAA0B,qBAAqB,GAAG,qBAAqB,EAAE;AACzE,gBAAgB,0CAA0C,qBAAqB,EAAE;AACjF;AACA;AACA,0BAA0B,8CAA8C,EAAE;AAC1E;AACA;AACA,0BAA0B,qBAAqB,GAAG,oBAAoB,EAAE;AACxE;AACA;AACA,0BAA0B,8CAA8C,EAAE;AAC1E;AACA;AACA,0BAA0B,qCAAqC;AAC/D,SAAS;AACT;AACA;AACA,wBAAwB,oBAAoB,GAAG,qBAAqB;AACpE,SAAS;AACT,cAAc,wCAAwC,2BAA2B,EAAE;AACnF;AACA;AACA,0BAA0B,qBAAqB,GAAG,qBAAqB,EAAE;AACzE;AACA;AACA,0BAA0B,8CAA8C,EAAE;AAC1E;AACA;AACA,wBAAwB,oBAAoB,GAAG,qBAAqB;AACpE,SAAS;AACT,eAAe,yCAAyC,kBAAkB,EAAE;AAC5E,eAAe,yCAAyC,qBAAqB,EAAE;AAC/E,iBAAiB,2CAA2C,qBAAqB,EAAE;AACnF,eAAe,yCAAyC,8CAA8C,EAAE;AACxG;AACA;AACA,wBAAwB,oBAAoB,GAAG,qBAAqB;AACpE,SAAS;AACT;AACA;AACA;AACA,iBAAiB,qBAAqB;AACtC,iBAAiB;AACjB;AACA,SAAS;AACT;AACA;AACA,0BAA0B,iCAAiC,EAAE;AAC7D,qBAAqB,4CAA4C,kBAAkB,EAAE;AACrF,sBAAsB,6CAA6C,kBAAkB,EAAE;AACvF,sBAAsB,6CAA6C,kBAAkB,EAAE;AACvF;AACA;AACA,0BAA0B,kCAAkC;AAC5D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA;AACA,2BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,+BAA+B,qBAAqB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,8CAA8C,QAAQ;AACtD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,qBAAqB,qBAAqB;AAC1C;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,qBAAqB,yBAAyB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yBAAyB,qBAAqB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yBAAyB,qBAAqB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,qBAAqB,sBAAsB;AAC3C;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA,uBAAuB,yBAAyB;AAChD;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,0BAA0B;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,0BAA0B;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,CAAC,EAAE,MAA8B,GAAG,CAAkB;;;;;;;;ACloDtD,e;;;;;;UCAA;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;WCtBA;WACA;WACA;WACA,sDAAsD,kBAAkB;WACxE;WACA,+CAA+C,cAAc;WAC7D,E;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACNA;AACA;CAGA;;IACqBA,mB;;;;;;;;;;;;;WAEpB;AACA,0BAAaC,GAAb,EAAkB,CACjB,C,CAED;;;;WACA,qBAAYA,GAAZ,EAAiB,CAChB,C,CAGD;;;;WACA,+BAAsBA,GAAtB,EAA2B,CAC1B,C,CAED;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAGD;;;;WACA,uBAAcA,GAAd,EAAmB,CAClB,C,CAED;;;;WACA,sBAAaA,GAAb,EAAkB,CACjB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAED;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAGD;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAED;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,sBAAaA,GAAb,EAAkB,CACjB,C,CAED;;;;WACA,qBAAYA,GAAZ,EAAiB,CAChB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,uBAAcA,GAAd,EAAmB,CAClB,C,CAED;;;;WACA,sBAAaA,GAAb,EAAkB,CACjB,C,CAGD;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAED;;;;WACA,uBAAcA,GAAd,EAAmB,CAClB,C,CAGD;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAED;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAGD;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAED;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAGD;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAED;;;;WACA,uBAAcA,GAAd,EAAmB,CAClB,C,CAGD;;;;WACA,iCAAwBA,GAAxB,EAA6B,CAC5B,C,CAED;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,mCAA0BA,GAA1B,EAA+B,CAC9B,C,CAED;;;;WACA,kCAAyBA,GAAzB,EAA8B,CAC7B,C,CAGD;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAED;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAGD;;;;WACA,kCAAyBA,GAAzB,EAA8B,CAC7B,C,CAED;;;;WACA,iCAAwBA,GAAxB,EAA6B,CAC5B,C,CAGD;;;;WACA,mCAA0BA,GAA1B,EAA+B,CAC9B,C,CAED;;;;WACA,kCAAyBA,GAAzB,EAA8B,CAC7B,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAED;;;;WACA,+BAAsBA,GAAtB,EAA2B,CAC1B,C,CAGD;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAED;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAGD;;;;WACA,oCAA2BA,GAA3B,EAAgC,CAC/B,C,CAED;;;;WACA,mCAA0BA,GAA1B,EAA+B,CAC9B,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAED;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAGD;;;;WACA,wCAA+BA,GAA/B,EAAoC,CACnC,C,CAED;;;;WACA,uCAA8BA,GAA9B,EAAmC,CAClC,C,CAGD;;;;WACA,iCAAwBA,GAAxB,EAA6B,CAC5B,C,CAED;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAGD;;;;WACA,qCAA4BA,GAA5B,EAAiC,CAChC,C,CAED;;;;WACA,oCAA2BA,GAA3B,EAAgC,CAC/B,C,CAGD;;;;WACA,wCAA+BA,GAA/B,EAAoC,CACnC,C,CAED;;;;WACA,uCAA8BA,GAA9B,EAAmC,CAClC,C,CAGD;;;;WACA,kCAAyBA,GAAzB,EAA8B,CAC7B,C,CAED;;;;WACA,iCAAwBA,GAAxB,EAA6B,CAC5B,C,CAGD;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAED;;;;WACA,+BAAsBA,GAAtB,EAA2B,CAC1B,C,CAGD;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAED;;;;WACA,+BAAsBA,GAAtB,EAA2B,CAC1B,C,CAGD;;;;WACA,qCAA4BA,GAA5B,EAAiC,CAChC,C,CAED;;;;WACA,oCAA2BA,GAA3B,EAAgC,CAC/B,C,CAGD;;;;WACA,qCAA4BA,GAA5B,EAAiC,CAChC,C,CAED;;;;WACA,oCAA2BA,GAA3B,EAAgC,CAC/B,C,CAGD;;;;WACA,wCAA+BA,GAA/B,EAAoC,CACnC,C,CAED;;;;WACA,uCAA8BA,GAA9B,EAAmC,CAClC,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,uBAAcA,GAAd,EAAmB,CAClB,C,CAED;;;;WACA,sBAAaA,GAAb,EAAkB,CACjB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAED;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAGD;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAED;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAGD;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAED;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAGD;;;;WACA,2BAAkBA,GAAlB,EAAuB,CACtB,C,CAED;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,qBAAYA,GAAZ,EAAiB,CAChB,C,CAED;;;;WACA,oBAAWA,GAAX,EAAgB,CACf,C,CAGD;;;;WACA,oBAAWA,GAAX,EAAgB,CACf,C,CAED;;;;WACA,mBAAUA,GAAV,EAAe,CACd,C,CAGD;;;;WACA,iCAAwBA,GAAxB,EAA6B,CAC5B,C,CAED;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAGD;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAED;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAGD;;;;WACA,0BAAiBA,GAAjB,EAAsB,CACrB,C,CAED;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,sBAAaA,GAAb,EAAkB,CACjB,C,CAED;;;;WACA,qBAAYA,GAAZ,EAAiB,CAChB,C,CAGD;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAED;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAGD;;;;WACA,yBAAgBA,GAAhB,EAAqB,CACpB,C,CAED;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,wBAAeA,GAAf,EAAoB,CACnB,C,CAED;;;;WACA,uBAAcA,GAAd,EAAmB,CAClB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,8BAAqBA,GAArB,EAA0B,CACzB,C,CAED;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAGD;;;;WACA,6BAAoBA,GAApB,EAAyB,CACxB,C,CAED;;;;WACA,4BAAmBA,GAAnB,EAAwB,CACvB,C,CAGD;;;;WACA,gCAAuBA,GAAvB,EAA4B,CAC3B,C,CAED;;;;WACA,+BAAsBA,GAAtB,EAA2B,CAC1B;;;;EA/jB+CC,6B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLjD;AACA;AACA;AACA;AAEA,IAAMC,aAAa,GAAG,CAAC,gDAAD,EAClB,uDADkB,EAElB,kDAFkB,EAGlB,wDAHkB,EAIlB,sDAJkB,EAKlB,oDALkB,EAMlB,kDANkB,EAOlB,oDAPkB,EAQlB,oDARkB,EASlB,kDATkB,EAUlB,kDAVkB,EAWlB,iDAXkB,EAYlB,iDAZkB,EAalB,iDAbkB,EAclB,kDAdkB,EAelB,oDAfkB,EAgBlB,wDAhBkB,EAiBlB,mDAjBkB,EAkBlB,wDAlBkB,EAmBlB,sDAnBkB,EAoBlB,sDApBkB,EAqBlB,sDArBkB,EAsBlB,wDAtBkB,EAuBlB,oDAvBkB,EAwBlB,kDAxBkB,EAyBlB,kDAzBkB,EA0BlB,kDA1BkB,EA2BlB,kDA3BkB,EA4BlB,kDA5BkB,EA6BlB,kDA7BkB,EA8BlB,gDA9BkB,EA+BlB,gDA/BkB,EAgClB,gDAhCkB,EAiClB,kDAjCkB,EAkClB,kDAlCkB,EAmClB,kDAnCkB,EAoClB,gDApCkB,EAqClB,gDArCkB,EAsClB,kDAtCkB,EAuClB,oDAvCkB,EAwClB,oDAxCkB,EAyClB,kDAzCkB,EA0ClB,kDA1CkB,EA2ClB,sDA3CkB,EA4ClB,kDA5CkB,EA6ClB,kDA7CkB,EA8ClB,kDA9CkB,EA+ClB,oDA/CkB,EAgDlB,oDAhDkB,EAiDlB,mDAjDkB,EAkDlB,kDAlDkB,EAmDlB,iDAnDkB,EAoDlB,kDApDkB,EAqDlB,gDArDkB,EAsDlB,+CAtDkB,EAuDlB,kDAvDkB,EAwDlB,kDAxDkB,EAyDlB,kDAzDkB,EA0DlB,gDA1DkB,EA2DlB,gDA3DkB,EA4DlB,gDA5DkB,EA6DlB,oDA7DkB,EA8DlB,sDA9DkB,EA+DlB,iDA/DkB,EAgElB,kDAhEkB,EAiElB,oDAjEkB,EAkElB,kDAlEkB,EAmElB,oDAnEkB,EAoElB,oDApEkB,EAqElB,oDArEkB,EAsElB,oDAtEkB,EAuElB,oDAvEkB,EAwElB,sDAxEkB,EAyElB,kDAzEkB,EA0ElB,kDA1EkB,EA2ElB,mDA3EkB,EA4ElB,iDA5EkB,EA6ElB,oDA7EkB,EA8ElB,oDA9EkB,EA+ElB,mDA/EkB,EAgFlB,iDAhFkB,EAiFlB,sDAjFkB,EAkFlB,oDAlFkB,EAmFlB,oDAnFkB,EAoFlB,mDApFkB,EAqFlB,kDArFkB,EAsFlB,kDAtFkB,EAuFlB,oDAvFkB,EAwFlB,oDAxFkB,EAyFlB,kDAzFkB,EA0FlB,kDA1FkB,EA2FlB,+CA3FkB,EA4FlB,kDA5FkB,EA6FlB,gDA7FkB,EA8FlB,+CA9FkB,EA+FlB,gDA/FkB,EAgGlB,gDAhGkB,EAiGlB,kDAjGkB,EAkGlB,kDAlGkB,EAmGlB,kDAnGkB,EAoGlB,kDApGkB,EAqGlB,gDArGkB,EAsGlB,kDAtGkB,EAuGlB,kDAvGkB,EAwGlB,kDAxGkB,EAyGlB,kDAzGkB,EA0GlB,kDA1GkB,EA2GlB,gDA3GkB,EA4GlB,kDA5GkB,EA6GlB,kDA7GkB,EA8GlB,kDA9GkB,EA+GlB,kDA/GkB,EAgHlB,kDAhHkB,EAiHlB,kDAjHkB,EAkHlB,+CAlHkB,EAmHlB,kDAnHkB,EAoHlB,+CApHkB,EAqHlB,kDArHkB,EAsHlB,kDAtHkB,EAuHlB,kDAvHkB,EAwHlB,gDAxHkB,EAyHlB,gDAzHkB,EA0HlB,kDA1HkB,EA2HlB,kDA3HkB,EA4HlB,kDA5HkB,EA6HlB,kDA7HkB,EA8HlB,kDA9HkB,EA+HlB,+CA/HkB,EAgIlB,iDAhIkB,EAiIlB,kDAjIkB,EAkIlB,kDAlIkB,EAmIlB,kDAnIkB,EAoIlB,kDApIkB,EAqIlB,+CArIkB,EAsIlB,iDAtIkB,EAuIlB,kDAvIkB,EAwIlB,gDAxIkB,EAyIlB,kDAzIkB,EA0IlB,+CA1IkB,EA2IlB,kDA3IkB,EA4IlB,kDA5IkB,EA6IlB,gDA7IkB,EA8IlB,kDA9IkB,EA+IlB,kDA/IkB,EAgJlB,kDAhJkB,EAiJlB,+CAjJkB,EAkJlB,kDAlJkB,EAmJlB,kDAnJkB,EAoJlB,kDApJkB,EAqJlB,kDArJkB,EAsJlB,kDAtJkB,EAuJlB,kDAvJkB,EAwJlB,kDAxJkB,EAyJlB,+CAzJkB,EA0JlB,+CA1JkB,EA2JlB,iDA3JkB,EA4JlB,+CA5JkB,EA6JlB,kDA7JkB,EA8JlB,kDA9JkB,EA+JlB,kDA/JkB,EAgKlB,+CAhKkB,EAiKlB,kDAjKkB,EAkKlB,kDAlKkB,EAmKlB,iDAnKkB,EAoKlB,+CApKkB,EAqKlB,+CArKkB,EAsKlB,+CAtKkB,EAuKlB,kDAvKkB,EAwKlB,+CAxKkB,EAyKlB,+CAzKkB,EA0KlB,kDA1KkB,EA2KlB,0DA3KkB,EA4KlB,0DA5KkB,EA6KlB,0DA7KkB,EA8KlB,0DA9KkB,EA+KlB,0DA/KkB,EAgLlB,0DAhLkB,EAiLlB,0DAjLkB,EAkLlB,0DAlLkB,EAmLlB,uDAnLkB,EAoLlB,uDApLkB,EAqLlB,qDArLkB,EAsLlB,2DAtLkB,EAuLlB,uDAvLkB,EAwLlB,0DAxLkB,EAyLlB,0DAzLkB,EA0LlB,0DA1LkB,EA2LlB,0DA3LkB,EA4LlB,0DA5LkB,EA6LlB,qDA7LkB,EA8LlB,4DA9LkB,EA+LlB,wDA/LkB,EAgMlB,uDAhMkB,EAiMlB,0DAjMkB,EAkMlB,qDAlMkB,EAmMlB,mDAnMkB,EAoMlB,4DApMkB,EAoM0DC,IApM1D,CAoM+D,EApM/D,CAAtB;AAuMA,IAAMC,GAAG,GAAG,IAAIH,0BAAJ,GAAiCI,WAAjC,CAA6CH,aAA7C,CAAZ;AAEA,IAAMI,cAAc,GAAGF,GAAG,CAACG,eAAJ,CAAoBC,GAApB,CAAyB,UAACC,EAAD,EAAKC,KAAL;AAAA,SAAe,IAAIT,cAAJ,CAAmBQ,EAAnB,EAAuBC,KAAvB,CAAf;AAAA,CAAzB,CAAvB;AAEA,IAAMC,kBAAkB,GAAG,IAAIV,oCAAJ,EAA3B;;IAEqBW,iB;;;;;AAuBjB,6BAAYC,KAAZ,EAAmB;AAAA;;AAAA;;AACf,8BAAMA,KAAN;AACA,UAAKC,OAAL,GAAe,IAAIb,6BAAJ,iDAAwCG,GAAxC,EAA6CE,cAA7C,EAA6DK,kBAA7D,CAAf;AACA,UAAKI,SAAL,GAAiBH,iBAAiB,CAACG,SAAnC;AACA,UAAKC,YAAL,GAAoBJ,iBAAiB,CAACI,YAAtC;AACA,UAAKC,aAAL,GAAqBL,iBAAiB,CAACK,aAAvC;AALe;AAMlB;;;;SAED,eAAU;AACN,aAAOb,GAAP;AACH;;;WAED,iBAAQc,QAAR,EAAkBC,SAAlB,EAA6BC,SAA7B,EAAwC;AACvC,cAAOD,SAAP;AACA,aAAK,CAAL;AACM,iBAAO,KAAKE,kBAAL,CAAwBH,QAAxB,EAAkCE,SAAlC,CAAP;;AACN,aAAK,CAAL;AACM,iBAAO,KAAKE,0BAAL,CAAgCJ,QAAhC,EAA0CE,SAA1C,CAAP;;AACN,aAAK,EAAL;AACM,iBAAO,KAAKG,0BAAL,CAAgCL,QAAhC,EAA0CE,SAA1C,CAAP;;AACH;AACI,gBAAM,6BAA6BD,SAAnC;AARP;AAUA;;;WAED,4BAAmBD,QAAnB,EAA6BE,SAA7B,EAAwC;AACvC,cAAOA,SAAP;AACC,aAAK,CAAL;AACC,iBAAO,KAAKI,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP;;AACD,aAAK,CAAL;AACC,iBAAO,KAAKD,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP;;AACD;AACC,gBAAM,6BAA6BL,SAAnC;AANF;AAQA;;;WAED,oCAA2BF,QAA3B,EAAqCE,SAArC,EAAgD;AAC/C,cAAOA,SAAP;AACC,aAAK,CAAL;AACC,iBAAO,KAAKI,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP;;AACD;AACC,gBAAM,6BAA6BL,SAAnC;AAJF;AAMA;;;WAED,oCAA2BF,QAA3B,EAAqCE,SAArC,EAAgD;AAC/C,cAAOA,SAAP;AACC,aAAK,CAAL;AACC,iBAAO,KAAKI,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP;;AACD,aAAK,CAAL;AACC,iBAAO,KAAKD,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP;;AACD,aAAK,CAAL;AACC,iBAAO,KAAKD,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP;;AACD,aAAK,CAAL;AACC,iBAAO,KAAKD,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP;;AACD,aAAK,CAAL;AACC,iBAAO,KAAKD,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP;;AACD,aAAK,CAAL;AACC,iBAAO,KAAKD,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP;;AACD;AACC,gBAAM,6BAA6BL,SAAnC;AAdF;AAgBA;;;WAKJ,mBAAU;AACN,UAAIF,QAAQ,GAAG,IAAIQ,cAAJ,CAAmB,IAAnB,EAAyB,KAAKD,IAA9B,EAAoC,KAAKE,KAAzC,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,CAAzB,EAA4BN,iBAAiB,CAACiB,YAA9C;;AACA,UAAI;AACA,aAAKC,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACA,aAAKI,UAAL,CAAgB,CAAhB;AACA,aAAKJ,KAAL,GAAa,EAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACqB,GAA7B;AACH,OAND,CAME,OAAOC,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAdD,SAcU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAGD,oBAAWsB,EAAX,EAAe;AACd,UAAGA,EAAE,KAAGC,SAAR,EAAmB;AACfD,UAAE,GAAG,CAAL;AACH;;AACE,UAAME,UAAU,GAAG,KAAKjB,IAAxB;AACA,UAAMkB,YAAY,GAAG,KAAKhB,KAA1B;AACA,UAAIT,QAAQ,GAAG,IAAI0B,iBAAJ,CAAsB,IAAtB,EAA4B,KAAKnB,IAAjC,EAAuCkB,YAAvC,CAAf;AACA,UAAIE,QAAQ,GAAG3B,QAAf;AACA,UAAM4B,WAAW,GAAG,CAApB;AACA,WAAKC,kBAAL,CAAwB7B,QAAxB,EAAkC,CAAlC,EAAqCN,iBAAiB,CAACoC,eAAvD,EAAwER,EAAxE;;AACA,UAAI;AACA,aAAKV,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACIhC,oBAAQ,GAAG,IAAImC,kBAAJ,CAAuB,IAAvB,EAA6BnC,QAA7B,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AAEA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC0C,UAA7B;AACA;;AAEJ,eAAK,CAAL;AACIpC,oBAAQ,GAAG,IAAIqC,qBAAJ,CAA0B,IAA1B,EAAgCrC,QAAhC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4C,MAA7B;AACA;;AAEJ,eAAK,CAAL;AACItC,oBAAQ,GAAG,IAAIuC,qBAAJ,CAA0B,IAA1B,EAAgCvC,QAAhC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC8C,UAA7B;AACA;;AAEJ,eAAK,CAAL;AACIxC,oBAAQ,GAAG,IAAIyC,sBAAJ,CAA2B,IAA3B,EAAiCzC,QAAjC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKiC,QAAL;AACA,iBAAKjC,KAAL,GAAa,EAAb;AACA,iBAAKI,UAAL,CAAgB,CAAhB;AACA;;AAEJ,eAAK,CAAL;AACIb,oBAAQ,GAAG,IAAI2C,sBAAJ,CAA2B,IAA3B,EAAiC3C,QAAjC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACkD,IAA7B;AACA,iBAAKnC,KAAL,GAAa,EAAb;AACA,iBAAKI,UAAL,CAAgB,CAAhB;AACA,iBAAKJ,KAAL,GAAa,EAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACmD,IAA7B;AACA;;AAEJ,eAAK,CAAL;AACI7C,oBAAQ,GAAG,IAAI8C,mBAAJ,CAAwB,IAAxB,EAA8B9C,QAA9B,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKsC,aAAL;AACA;;AAEJ,eAAK,CAAL;AACI/C,oBAAQ,GAAG,IAAIgD,eAAJ,CAAoB,IAApB,EAA0BhD,QAA1B,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;AACA,iBAAKwC,kBAAL,CAAwB,CAAxB;AACA;AA9DJ;;AAiEA,aAAK1C,IAAL,CAAU2C,IAAV,GAAiB,KAAKhB,MAAL,CAAYiB,EAAZ,CAAe,CAAC,CAAhB,CAAjB;AACA,aAAK1C,KAAL,GAAa,EAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIqB,IAAI,GAAG,KAAKxD,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAX;;AACA,eAAM6C,IAAI,IAAE,CAAN,IAAWA,IAAI,IAAErE,iCAAvB,EAA0D;AACtD,cAAGqE,IAAI,KAAG,CAAV,EAAa;AACT,gBAAG,KAAKC,eAAL,KAAuB,IAA1B,EAAgC;AAC5B,mBAAKC,oBAAL;AACH;;AACD3B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,EAAb;;AACA,iBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,gBAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAV;;AACA,oBAAOyB,GAAP;AACA,mBAAK,CAAL;AACIhC,wBAAQ,GAAG,IAAIuD,uBAAJ,CAA4B,IAA5B,EAAkC,IAAI7B,iBAAJ,CAAsB,IAAtB,EAA4BF,UAA5B,EAAwCC,YAAxC,CAAlC,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACoC,eAAtE;AACA,qBAAKrB,KAAL,GAAa,EAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP,EAAqC;AACjC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,6BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,EAAb;AACA,qBAAKgD,SAAL;AACA,qBAAKhD,KAAL,GAAa,EAAb;AACA,qBAAKI,UAAL,CAAgB,CAAhB;AACA;;AAEJ,mBAAK,CAAL;AACIb,wBAAQ,GAAG,IAAI0D,cAAJ,CAAmB,IAAnB,EAAyB,IAAIhC,iBAAJ,CAAsB,IAAtB,EAA4BF,UAA5B,EAAwCC,YAAxC,CAAzB,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACoC,eAAtE;AACA,qBAAKrB,KAAL,GAAa,EAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP,EAAqC;AACjC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,6BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,EAAb;AACA,qBAAKkD,UAAL;AACA;AAvBJ;AA0BH;;AACD,eAAKlD,KAAL,GAAa,EAAb;;AACA,eAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAqB,cAAI,GAAG,KAAKxD,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAP;AACH;AAEJ,OAnHD,CAmHE,OAAOqD,KAAP,EAAc;AACZ,YAAGA,KAAK,YAAY7E,iCAApB,EAAuD;AACtDiB,kBAAQ,CAACiB,SAAT,GAAqB2C,KAArB;;AACA,eAAK1C,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCyC,KAAnC;;AACA,eAAK1C,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BwC,KAA/B;AACH,SAJE,MAII;AACN,gBAAMA,KAAN;AACA;AACD,OA3HD,SA2HU;AACN,aAAKC,uBAAL,CAA6BrC,UAA7B;AACH;;AACD,aAAOxB,QAAP;AACH;;;WAID,oBAAW;AACP,UAAIA,QAAQ,GAAG,IAAI8D,eAAJ,CAAoB,IAApB,EAA0B,KAAKvD,IAA/B,EAAqC,KAAKE,KAA1C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,CAAzB,EAA4BN,iBAAiB,CAACqE,aAA9C;AACA,UAAIC,GAAG,GAAG,CAAV,CAHO,CAGM;;AACb,UAAI;AACA,aAAKpD,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACAuD,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,YAAG,EAAED,GAAG,KAAGtE,iBAAiB,CAACwE,IAAxB,IAAgCF,GAAG,KAAGtE,iBAAiB,CAACyE,IAA1D,CAAH,EAAoE;AACpE,eAAKjD,WAAL,CAAiBkD,aAAjB,CAA+B,IAA/B;AACC,SAFD,MAGK;AACJ,eAAKlD,WAAL,CAAiBmD,WAAjB,CAA6B,IAA7B;;AACG,eAAKC,OAAL;AACH;AACJ,OAXD,CAWE,OAAOtD,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAnBD,SAmBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,qBAAY;AACR,UAAIA,QAAQ,GAAG,IAAIuE,gBAAJ,CAAqB,IAArB,EAA2B,KAAKhE,IAAhC,EAAsC,KAAKE,KAA3C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,CAAzB,EAA4BN,iBAAiB,CAAC8E,cAA9C;AACA,UAAIR,GAAG,GAAG,CAAV,CAHQ,CAGK;;AACb,UAAI;AACA,aAAKpD,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACAuD,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,YAAG,EAAG,CAAED,GAAD,GAAQ,CAAC,IAAV,KAAmB,CAAnB,IAAwB,CAAE,KAAKA,GAAN,IAAe,KAAKtE,iBAAiB,CAACwE,IAAxB,GAAiC,KAAKxE,iBAAiB,CAACyE,IAAxD,GAAiE,KAAKzE,iBAAiB,CAAC+E,IAAxF,GAAiG,KAAK/E,iBAAiB,CAACgF,IAAxH,GAAiI,KAAKhF,iBAAiB,CAACiF,IAAxJ,GAAiK,KAAKjF,iBAAiB,CAACkF,IAAxL,GAAiM,KAAKlF,iBAAiB,CAACmF,IAAxN,GAAiO,KAAKnF,iBAAiB,CAACoF,UAAtQ,CAAD,MAAyR,CAApT,CAAH,EAA4T;AAC5T,eAAK5D,WAAL,CAAiBkD,aAAjB,CAA+B,IAA/B;AACC,SAFD,MAGK;AACJ,eAAKlD,WAAL,CAAiBmD,WAAjB,CAA6B,IAA7B;;AACG,eAAKC,OAAL;AACH;AACJ,OAXD,CAWE,OAAOtD,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAnBD,SAmBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,sBAAa;AACT,UAAIA,QAAQ,GAAG,IAAI+E,iBAAJ,CAAsB,IAAtB,EAA4B,KAAKxE,IAAjC,EAAuC,KAAKE,KAA5C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,CAAzB,EAA4BN,iBAAiB,CAACsF,eAA9C;;AACA,UAAI;AACA,aAAKpE,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACuF,IAA7B;AACH,OAJD,CAIE,OAAOjE,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAZD,SAYU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,yBAAgB;AACZ,UAAIA,QAAQ,GAAG,IAAIkF,oBAAJ,CAAyB,IAAzB,EAA+B,KAAK3E,IAApC,EAA0C,KAAKE,KAA/C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACyF,kBAA/C;;AACA,UAAI;AACA,aAAKvE,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAAC0F,SAA7B;AACA,aAAK3E,KAAL,GAAa,EAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACkD,IAA7B;AACA,aAAKnC,KAAL,GAAa,EAAb;AACA,aAAK4E,eAAL;AACA,aAAK5E,KAAL,GAAa,EAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACmD,IAA7B;AACH,OAVD,CAUE,OAAO7B,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAlBD,SAkBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,qBAAY;AACR,UAAIA,QAAQ,GAAG,IAAIsF,gBAAJ,CAAqB,IAArB,EAA2B,KAAK/E,IAAhC,EAAsC,KAAKE,KAA3C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC6F,cAA/C;;AACA,UAAI;AACA,aAAK3E,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACA,aAAKI,UAAL,CAAgB,CAAhB;AACH,OAJD,CAIE,OAAOG,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAZD,SAYU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAGD,4BAAmBsB,EAAnB,EAAuB;AACtB,UAAGA,EAAE,KAAGC,SAAR,EAAmB;AACfD,UAAE,GAAG,CAAL;AACH;;AACE,UAAME,UAAU,GAAG,KAAKjB,IAAxB;AACA,UAAMkB,YAAY,GAAG,KAAKhB,KAA1B;AACA,UAAIT,QAAQ,GAAG,IAAIwF,yBAAJ,CAA8B,IAA9B,EAAoC,KAAKjF,IAAzC,EAA+CkB,YAA/C,CAAf;AACA,UAAIE,QAAQ,GAAG3B,QAAf;AACA,UAAM4B,WAAW,GAAG,EAApB;AACA,WAAKC,kBAAL,CAAwB7B,QAAxB,EAAkC,EAAlC,EAAsCN,iBAAiB,CAAC+F,uBAAxD,EAAiFnE,EAAjF;;AACA,UAAI;AACA,aAAKV,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,EAAb;AACA,aAAKiF,SAAL;AACA,aAAKnF,IAAL,CAAU2C,IAAV,GAAiB,KAAKhB,MAAL,CAAYiB,EAAZ,CAAe,CAAC,CAAhB,CAAjB;AACA,aAAK1C,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIqB,IAAI,GAAG,KAAKxD,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAX;;AACA,eAAM6C,IAAI,IAAE,CAAN,IAAWA,IAAI,IAAErE,iCAAvB,EAA0D;AACtD,cAAGqE,IAAI,KAAG,CAAV,EAAa;AACT,gBAAG,KAAKC,eAAL,KAAuB,IAA1B,EAAgC;AAC5B,mBAAKC,oBAAL;AACH;;AACD3B,oBAAQ,GAAG3B,QAAX;AACAA,oBAAQ,GAAG,IAAIwF,yBAAJ,CAA8B,IAA9B,EAAoChE,UAApC,EAAgDC,YAAhD,CAAX;AACA,iBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAAC+F,uBAAtE;AACA,iBAAKhF,KAAL,GAAa,GAAb;;AACA,gBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP,EAAqC;AACjC,oBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,6BAAhD,CAAN;AACH;;AACD,iBAAK0B,KAAL,GAAa,GAAb;AACA,iBAAKkF,cAAL;AACA,iBAAKlF,KAAL,GAAa,GAAb;AACA,iBAAKiF,SAAL;AACH;;AACD,eAAKjF,KAAL,GAAa,GAAb;;AACA,eAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAqB,cAAI,GAAG,KAAKxD,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAP;AACH;AAEJ,OA9BD,CA8BE,OAAOqD,KAAP,EAAc;AACZ,YAAGA,KAAK,YAAY7E,iCAApB,EAAuD;AACtDiB,kBAAQ,CAACiB,SAAT,GAAqB2C,KAArB;;AACA,eAAK1C,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCyC,KAAnC;;AACA,eAAK1C,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BwC,KAA/B;AACH,SAJE,MAII;AACN,gBAAMA,KAAN;AACA;AACD,OAtCD,SAsCU;AACN,aAAKC,uBAAL,CAA6BrC,UAA7B;AACH;;AACD,aAAOxB,QAAP;AACH;;;WAID,2BAAkB;AACd,UAAIA,QAAQ,GAAG,IAAI4F,sBAAJ,CAA2B,IAA3B,EAAiC,KAAKrF,IAAtC,EAA4C,KAAKE,KAAjD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACmG,oBAA/C;;AACA,UAAI;AACA,aAAKpF,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,gBAAO,KAAKG,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAP;AACA,eAAKvE,iBAAiB,CAACmD,IAAvB;AACI,iBAAKjC,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AAEA;;AACJ,eAAKN,iBAAiB,CAACkD,IAAvB;AACA,eAAKlD,iBAAiB,CAACwE,IAAvB;AACA,eAAKxE,iBAAiB,CAACyE,IAAvB;AACA,eAAKzE,iBAAiB,CAACiF,IAAvB;AACA,eAAKjF,iBAAiB,CAACoG,KAAvB;AACA,eAAKpG,iBAAiB,CAACqG,KAAvB;AACA,eAAKrG,iBAAiB,CAACsG,KAAvB;AACA,eAAKtG,iBAAiB,CAACuG,KAAvB;AACA,eAAKvG,iBAAiB,CAACwG,KAAvB;AACA,eAAKxG,iBAAiB,CAACyG,KAAvB;AACA,eAAKzG,iBAAiB,CAAC0C,UAAvB;AACA,eAAK1C,iBAAiB,CAAC4C,MAAvB;AACA,eAAK5C,iBAAiB,CAAC0F,SAAvB;AACA,eAAK1F,iBAAiB,CAAC8C,UAAvB;AACA,eAAK9C,iBAAiB,CAAC0G,aAAvB;AACA,eAAK1G,iBAAiB,CAAC2G,IAAvB;AACA,eAAK3G,iBAAiB,CAAC4G,MAAvB;AACI,iBAAK1F,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK8F,kBAAL,CAAwB,CAAxB;AACA;;AACJ;AACI,kBAAM,IAAIxH,iCAAJ,CAAsC,IAAtC,CAAN;AA3BJ;AA6BH,OAhCD,CAgCE,OAAOiC,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAxCD,SAwCU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,0BAAiB;AACb,UAAIA,QAAQ,GAAG,IAAIwG,qBAAJ,CAA0B,IAA1B,EAAgC,KAAKjG,IAArC,EAA2C,KAAKE,KAAhD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC+G,mBAA/C;;AACA,UAAI;AACA,aAAK7F,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACgH,KAA7B;AACH,OAJD,CAIE,OAAO1F,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAZD,SAYU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAGD,4BAAmBsB,EAAnB,EAAuB;AACtB,UAAGA,EAAE,KAAGC,SAAR,EAAmB;AACfD,UAAE,GAAG,CAAL;AACH;;AACE,UAAME,UAAU,GAAG,KAAKjB,IAAxB;AACA,UAAMkB,YAAY,GAAG,KAAKhB,KAA1B;AACA,UAAIT,QAAQ,GAAG,IAAI2G,yBAAJ,CAA8B,IAA9B,EAAoC,KAAKpG,IAAzC,EAA+CkB,YAA/C,CAAf;AACA,UAAIE,QAAQ,GAAG3B,QAAf;AACA,UAAM4B,WAAW,GAAG,EAApB;AACA,WAAKC,kBAAL,CAAwB7B,QAAxB,EAAkC,EAAlC,EAAsCN,iBAAiB,CAACkH,uBAAxD,EAAiFtF,EAAjF;;AACA,UAAI;AACA,aAAKV,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACIhC,oBAAQ,GAAG,IAAI6G,wBAAJ,CAA6B,IAA7B,EAAmC7G,QAAnC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AAEA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKqG,gBAAL;AACA;;AAEJ,eAAK,CAAL;AACI9G,oBAAQ,GAAG,IAAI+G,2BAAJ,CAAgC,IAAhC,EAAsC/G,QAAtC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKuG,UAAL;AACA;;AAEJ,eAAK,CAAL;AACIhH,oBAAQ,GAAG,IAAIiH,oBAAJ,CAAyB,IAAzB,EAA+BjH,QAA/B,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACoG,KAA7B;AACA,iBAAKrF,KAAL,GAAa,GAAb;AACA,iBAAKwC,kBAAL,CAAwB,EAAxB;AACA;;AAEJ,eAAK,CAAL;AACIjD,oBAAQ,GAAG,IAAIkH,sBAAJ,CAA2B,IAA3B,EAAiClH,QAAjC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACkD,IAA7B;AACA,iBAAKnC,KAAL,GAAa,GAAb;AACA,iBAAKwC,kBAAL,CAAwB,CAAxB;AACA,iBAAKxC,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACmD,IAA7B;AACA;;AAEJ,eAAK,CAAL;AACI7C,oBAAQ,GAAG,IAAImH,yBAAJ,CAA8B,IAA9B,EAAoCnH,QAApC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK2G,QAAL;AACA;;AAEJ,eAAK,CAAL;AACIpH,oBAAQ,GAAG,IAAIqH,gCAAJ,CAAqC,IAArC,EAA2CrH,QAA3C,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK6G,eAAL;AACA;;AAEJ,eAAK,CAAL;AACItH,oBAAQ,GAAG,IAAIuH,gCAAJ,CAAqC,IAArC,EAA2CvH,QAA3C,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK+G,eAAL;AACA;;AAEJ,eAAK,CAAL;AACIxH,oBAAQ,GAAG,IAAIyH,wBAAJ,CAA6B,IAA7B,EAAmCzH,QAAnC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKiH,OAAL;AACA;;AAEJ,eAAK,CAAL;AACI1H,oBAAQ,GAAG,IAAI2H,6BAAJ,CAAkC,IAAlC,EAAwC3H,QAAxC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKmH,kBAAL;AACA;;AAEJ,eAAK,EAAL;AACI5H,oBAAQ,GAAG,IAAI6H,0BAAJ,CAA+B,IAA/B,EAAqC7H,QAArC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC8C,UAA7B;AACA;;AAEJ,eAAK,EAAL;AACIxC,oBAAQ,GAAG,IAAI8H,4BAAJ,CAAiC,IAAjC,EAAuC9H,QAAvC,CAAX;AACA,iBAAKO,IAAL,GAAYP,QAAZ;AACA2B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKsH,WAAL;AACA;AA9FJ;;AAiGA,aAAKxH,IAAL,CAAU2C,IAAV,GAAiB,KAAKhB,MAAL,CAAYiB,EAAZ,CAAe,CAAC,CAAhB,CAAjB;AACA,aAAK1C,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIqB,IAAI,GAAG,KAAKxD,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAX;;AACA,eAAM6C,IAAI,IAAE,CAAN,IAAWA,IAAI,IAAErE,iCAAvB,EAA0D;AACtD,cAAGqE,IAAI,KAAG,CAAV,EAAa;AACT,gBAAG,KAAKC,eAAL,KAAuB,IAA1B,EAAgC;AAC5B,mBAAKC,oBAAL;AACH;;AACD3B,oBAAQ,GAAG3B,QAAX;AACA,iBAAKS,KAAL,GAAa,GAAb;;AACA,iBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,gBAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAV;;AACA,oBAAOyB,GAAP;AACA,mBAAK,CAAL;AACIhC,wBAAQ,GAAG,IAAIgI,2BAAJ,CAAgC,IAAhC,EAAsC,IAAIrB,yBAAJ,CAA8B,IAA9B,EAAoCnF,UAApC,EAAgDC,YAAhD,CAAtC,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACkH,uBAAtE;AACA,qBAAKnG,KAAL,GAAa,GAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP,EAAsC;AAClC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,8BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,GAAb;AACA,qBAAKK,KAAL,CAAWpB,iBAAiB,CAACoF,UAA7B;AACA,qBAAKrE,KAAL,GAAa,GAAb;AACA,qBAAKwC,kBAAL,CAAwB,EAAxB;AACA;;AAEJ,mBAAK,CAAL;AACIjD,wBAAQ,GAAG,IAAIiI,oBAAJ,CAAyB,IAAzB,EAA+B,IAAItB,yBAAJ,CAA8B,IAA9B,EAAoCnF,UAApC,EAAgDC,YAAhD,CAA/B,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACkH,uBAAtE;AACA,qBAAKnG,KAAL,GAAa,GAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP,EAAsC;AAClC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,8BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,GAAb;AACA,qBAAKK,KAAL,CAAWpB,iBAAiB,CAACwI,KAA7B;AACA,qBAAKzH,KAAL,GAAa,GAAb;AACA,qBAAKwC,kBAAL,CAAwB,EAAxB;AACA;;AAEJ,mBAAK,CAAL;AACIjD,wBAAQ,GAAG,IAAImI,mBAAJ,CAAwB,IAAxB,EAA8B,IAAIxB,yBAAJ,CAA8B,IAA9B,EAAoCnF,UAApC,EAAgDC,YAAhD,CAA9B,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACkH,uBAAtE;AACA,qBAAKnG,KAAL,GAAa,GAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP,EAAsC;AAClC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,8BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,GAAb;AACA,qBAAKK,KAAL,CAAWpB,iBAAiB,CAAC0I,KAA7B;AACA,qBAAK3H,KAAL,GAAa,GAAb;AACA,qBAAKwC,kBAAL,CAAwB,EAAxB;AACA;;AAEJ,mBAAK,CAAL;AACIjD,wBAAQ,GAAG,IAAIqI,qBAAJ,CAA0B,IAA1B,EAAgC,IAAI1B,yBAAJ,CAA8B,IAA9B,EAAoCnF,UAApC,EAAgDC,YAAhD,CAAhC,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACkH,uBAAtE;AACA,qBAAKnG,KAAL,GAAa,GAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,CAAzB,CAAP,EAAqC;AACjC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,6BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,GAAb;AACA,qBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4I,KAA7B;AACA,qBAAK7H,KAAL,GAAa,GAAb;AACA,qBAAKwC,kBAAL,CAAwB,CAAxB;AACA;;AAEJ,mBAAK,CAAL;AACIjD,wBAAQ,GAAG,IAAIuI,sBAAJ,CAA2B,IAA3B,EAAiC,IAAI5B,yBAAJ,CAA8B,IAA9B,EAAoCnF,UAApC,EAAgDC,YAAhD,CAAjC,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACkH,uBAAtE;AACA,qBAAKnG,KAAL,GAAa,GAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP,EAAsC;AAClC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,8BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,GAAb;AACA,qBAAKK,KAAL,CAAWpB,iBAAiB,CAAC8I,KAA7B;AACA,qBAAK/H,KAAL,GAAa,GAAb;AACA,qBAAKgI,iBAAL;AACA;;AAEJ,mBAAK,CAAL;AACIzI,wBAAQ,GAAG,IAAI0I,0BAAJ,CAA+B,IAA/B,EAAqC,IAAI/B,yBAAJ,CAA8B,IAA9B,EAAoCnF,UAApC,EAAgDC,YAAhD,CAArC,CAAX;AACA,qBAAK+B,uBAAL,CAA6BxD,QAA7B,EAAuC4B,WAAvC,EAAoDlC,iBAAiB,CAACkH,uBAAtE;AACA,qBAAKnG,KAAL,GAAa,GAAb;;AACA,oBAAI,CAAG,KAAKH,QAAL,CAAc,KAAKC,IAAnB,EAAyB,EAAzB,CAAP,EAAsC;AAClC,wBAAM,IAAIxB,qCAAJ,CAA0C,IAA1C,EAAgD,8BAAhD,CAAN;AACH;;AACD,qBAAK0B,KAAL,GAAa,GAAb;AACA,qBAAKqG,gBAAL;AACA;AA3EJ;AA8EH;;AACD,eAAKrG,KAAL,GAAa,GAAb;;AACA,eAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAqB,cAAI,GAAG,KAAKxD,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAP;AACH;AAEJ,OAvMD,CAuME,OAAOqD,KAAP,EAAc;AACZ,YAAGA,KAAK,YAAY7E,iCAApB,EAAuD;AACtDiB,kBAAQ,CAACiB,SAAT,GAAqB2C,KAArB;;AACA,eAAK1C,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCyC,KAAnC;;AACA,eAAK1C,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BwC,KAA/B;AACH,SAJE,MAII;AACN,gBAAMA,KAAN;AACA;AACD,OA/MD,SA+MU;AACN,aAAKC,uBAAL,CAA6BrC,UAA7B;AACH;;AACD,aAAOxB,QAAP;AACH;;;WAID,6BAAoB;AAChB,UAAIA,QAAQ,GAAG,IAAI2I,wBAAJ,CAA6B,IAA7B,EAAmC,KAAKpI,IAAxC,EAA8C,KAAKE,KAAnD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACkJ,sBAA/C;;AACA,UAAI;AACA,aAAKnI,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,CAAzC,EAA2C,KAAK3B,IAAhD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACIhC,oBAAQ,GAAG,IAAI6I,wBAAJ,CAA6B,IAA7B,EAAmC7I,QAAnC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKuG,UAAL;AACA;;AAEJ,eAAK,CAAL;AACIhH,oBAAQ,GAAG,IAAI8I,6BAAJ,CAAkC,IAAlC,EAAwC9I,QAAxC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK6G,eAAL;AACA;;AAEJ,eAAK,CAAL;AACItH,oBAAQ,GAAG,IAAI+I,6BAAJ,CAAkC,IAAlC,EAAwC/I,QAAxC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK+G,eAAL;AACA;;AAEJ,eAAK,CAAL;AACIxH,oBAAQ,GAAG,IAAIgJ,gCAAJ,CAAqC,IAArC,EAA2ChJ,QAA3C,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKmH,kBAAL;AACA;;AAEJ,eAAK,CAAL;AACI5H,oBAAQ,GAAG,IAAIiJ,sBAAJ,CAA2B,IAA3B,EAAiCjJ,QAAjC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK2G,QAAL;AACA;AAlCJ;AAqCH,OAzCD,CAyCE,OAAOpG,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAjDD,SAiDU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,oBAAW;AACP,UAAIA,QAAQ,GAAG,IAAIkJ,eAAJ,CAAoB,IAApB,EAA0B,KAAK3I,IAA/B,EAAqC,KAAKE,KAA1C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACyJ,aAA/C;;AACA,UAAI;AACA,aAAKvI,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACiF,IAA7B;AACH,OAJD,CAIE,OAAO3D,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAZD,SAYU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,2BAAkB;AACd,UAAIA,QAAQ,GAAG,IAAIoJ,sBAAJ,CAA2B,IAA3B,EAAiC,KAAK7I,IAAtC,EAA4C,KAAKE,KAAjD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC2J,oBAA/C;AACA,UAAIrF,GAAG,GAAG,CAAV,CAHc,CAGD;;AACb,UAAI;AACA,aAAKpD,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,aAAKtF,KAAL,GAAa,GAAb;AACA,aAAKwC,kBAAL,CAAwB,CAAxB;AACA,aAAKxC,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,eAAMD,GAAG,KAAGtE,iBAAiB,CAACgH,KAA9B,EAAqC;AACjC,eAAKjG,KAAL,GAAa,GAAb;AACA,eAAKK,KAAL,CAAWpB,iBAAiB,CAACgH,KAA7B;AACA,eAAKjG,KAAL,GAAa,GAAb;AACA,eAAKwC,kBAAL,CAAwB,CAAxB;AACA,eAAKxC,KAAL,GAAa,GAAb;;AACA,eAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,aAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;AACH;;AACD,aAAKxD,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACH,OApBD,CAoBE,OAAOtI,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OA5BD,SA4BU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,2BAAkB;AACd,UAAIA,QAAQ,GAAG,IAAIuJ,sBAAJ,CAA2B,IAA3B,EAAiC,KAAKhJ,IAAtC,EAA4C,KAAKE,KAAjD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC8J,oBAA/C;AACA,UAAIxF,GAAG,GAAG,CAAV,CAHc,CAGD;;AACb,UAAI;AACA,aAAKpD,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACsG,KAA7B;AACA,aAAKvF,KAAL,GAAa,GAAb;AACA,aAAKgJ,UAAL;AACA,aAAKhJ,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,eAAMD,GAAG,KAAGtE,iBAAiB,CAACgH,KAA9B,EAAqC;AACjC,eAAKjG,KAAL,GAAa,GAAb;AACA,eAAKK,KAAL,CAAWpB,iBAAiB,CAACgH,KAA7B;AACA,eAAKjG,KAAL,GAAa,GAAb;AACA,eAAKgJ,UAAL;AACA,eAAKhJ,KAAL,GAAa,GAAb;;AACA,eAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,aAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;AACH;;AACD,aAAKxD,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACgK,KAA7B;AACH,OApBD,CAoBE,OAAO1I,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OA5BD,SA4BU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,sBAAa;AACT,UAAIA,QAAQ,GAAG,IAAI2J,iBAAJ,CAAsB,IAAtB,EAA4B,KAAKpJ,IAAjC,EAAuC,KAAKE,KAA5C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACkK,eAA/C;;AACA,UAAI;AACA,aAAKhJ,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKuG,UAAL;AACA,aAAKvG,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACmK,KAA7B;AACA,aAAKpJ,KAAL,GAAa,GAAb;AACA,aAAKwC,kBAAL,CAAwB,CAAxB;AACH,OARD,CAQE,OAAOjC,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAhBD,SAgBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,4BAAmB;AACf,UAAIA,QAAQ,GAAG,IAAI8J,uBAAJ,CAA4B,IAA5B,EAAkC,KAAKvJ,IAAvC,EAA6C,KAAKE,KAAlD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACqK,qBAA/C;;AACA,UAAI;AACA,aAAKtJ,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,EAAzC,EAA4C,KAAK3B,IAAjD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACIhC,oBAAQ,GAAG,IAAIgK,mBAAJ,CAAwB,IAAxB,EAA8BhK,QAA9B,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,iBAAKtF,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC0C,UAA7B;AACA,iBAAK3B,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;;AAEJ,eAAK,CAAL;AACItJ,oBAAQ,GAAG,IAAIiK,kBAAJ,CAAuB,IAAvB,EAA6BjK,QAA7B,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,iBAAKtF,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACiF,IAA7B;AACA,iBAAKlE,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;;AAEJ,eAAK,CAAL;AACItJ,oBAAQ,GAAG,IAAIkK,mBAAJ,CAAwB,IAAxB,EAA8BlK,QAA9B,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,iBAAKtF,KAAL,GAAa,GAAb;AACA,iBAAK0J,KAAL;AACA,iBAAK1J,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;;AAEJ,eAAK,CAAL;AACItJ,oBAAQ,GAAG,IAAIoK,qBAAJ,CAA0B,IAA1B,EAAgCpK,QAAhC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,iBAAKtF,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;;AAEJ,eAAK,CAAL;AACItJ,oBAAQ,GAAG,IAAIqK,aAAJ,CAAkB,IAAlB,EAAwBrK,QAAxB,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACuG,KAA7B;AACA,iBAAKxF,KAAL,GAAa,GAAb;AACA,iBAAKwC,kBAAL,CAAwB,CAAxB;AACA,iBAAKxC,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;AApDJ;AAuDH,OA3DD,CA2DE,OAAOtI,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAnED,SAmEU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,iBAAQ;AACJ,UAAIA,QAAQ,GAAG,IAAIsK,YAAJ,CAAiB,IAAjB,EAAuB,KAAK/J,IAA5B,EAAkC,KAAKE,KAAvC,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC6K,UAA/C;AACA,UAAIvG,GAAG,GAAG,CAAV,CAHI,CAGS;;AACb,UAAI;AACA,aAAKpD,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,YAAGD,GAAG,KAAGtE,iBAAiB,CAAC0C,UAA3B,EAAuC;AACnC,eAAK3B,KAAL,GAAa,GAAb;AACAT,kBAAQ,CAACwK,KAAT,GAAiB,KAAK1J,KAAL,CAAWpB,iBAAiB,CAAC0C,UAA7B,CAAjB;AACH;;AAED,aAAK3B,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACmK,KAA7B;AACA,aAAKpJ,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,YAAGD,GAAG,KAAGtE,iBAAiB,CAAC0C,UAA3B,EAAuC;AACnC,eAAK3B,KAAL,GAAa,GAAb;AACAT,kBAAQ,CAACkD,IAAT,GAAgB,KAAKpC,KAAL,CAAWpB,iBAAiB,CAAC0C,UAA7B,CAAhB;AACH;;AAED,aAAK3B,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,YAAGD,GAAG,KAAGtE,iBAAiB,CAACmK,KAA3B,EAAkC;AAC9B,eAAKpJ,KAAL,GAAa,GAAb;AACA,eAAKK,KAAL,CAAWpB,iBAAiB,CAACmK,KAA7B;AACA,eAAKpJ,KAAL,GAAa,GAAb;;AACA,eAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,aAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,cAAGD,GAAG,KAAGtE,iBAAiB,CAAC0C,UAA3B,EAAuC;AACnC,iBAAK3B,KAAL,GAAa,GAAb;AACAT,oBAAQ,CAACyK,IAAT,GAAgB,KAAK3J,KAAL,CAAWpB,iBAAiB,CAAC0C,UAA7B,CAAhB;AACH;AAEJ;AAEJ,OApCD,CAoCE,OAAOpB,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OA5CD,SA4CU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,8BAAqB;AACjB,UAAIA,QAAQ,GAAG,IAAI0K,yBAAJ,CAA8B,IAA9B,EAAoC,KAAKnK,IAAzC,EAA+C,KAAKE,KAApD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACiL,uBAA/C;AACA,UAAI3G,GAAG,GAAG,CAAV,CAHiB,CAGJ;;AACb,UAAI;AACA,aAAKvD,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,EAAzC,EAA4C,KAAK3B,IAAjD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACI,iBAAKpB,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC2G,IAA7B;AACA,iBAAK5F,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACkD,IAA7B;AACA,iBAAKnC,KAAL,GAAa,GAAb;AACA,iBAAKmK,WAAL;AACA,iBAAKnK,KAAL,GAAa,GAAb;;AACA,iBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,eAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,mBAAMD,GAAG,KAAGtE,iBAAiB,CAACgH,KAA9B,EAAqC;AACjC,mBAAKjG,KAAL,GAAa,GAAb;AACA,mBAAKK,KAAL,CAAWpB,iBAAiB,CAACgH,KAA7B;AACA,mBAAKjG,KAAL,GAAa,GAAb;AACA,mBAAKmK,WAAL;AACA,mBAAKnK,KAAL,GAAa,GAAb;;AACA,mBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,iBAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;AACH;;AACD,iBAAKxD,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACmD,IAA7B;AACA;;AAEJ,eAAK,CAAL;AACI,iBAAKjC,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC2G,IAA7B;AACA,iBAAK5F,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACkD,IAA7B;AACA,iBAAKnC,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACmD,IAA7B;AACA;AAjCJ;AAoCH,OAxCD,CAwCE,OAAO7B,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAhDD,SAgDU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,uBAAc;AACV,UAAIA,QAAQ,GAAG,IAAI6K,kBAAJ,CAAuB,IAAvB,EAA6B,KAAKtK,IAAlC,EAAwC,KAAKE,KAA7C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACoL,gBAA/C;;AACA,UAAI;AACA,aAAKrK,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,gBAAO,KAAKG,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAP;AACA,eAAKvE,iBAAiB,CAACkD,IAAvB;AACA,eAAKlD,iBAAiB,CAACiF,IAAvB;AACA,eAAKjF,iBAAiB,CAACoG,KAAvB;AACA,eAAKpG,iBAAiB,CAACqG,KAAvB;AACA,eAAKrG,iBAAiB,CAACsG,KAAvB;AACA,eAAKtG,iBAAiB,CAACuG,KAAvB;AACA,eAAKvG,iBAAiB,CAACwG,KAAvB;AACA,eAAKxG,iBAAiB,CAACyG,KAAvB;AACA,eAAKzG,iBAAiB,CAAC8C,UAAvB;AACA,eAAK9C,iBAAiB,CAAC0G,aAAvB;AACA,eAAK1G,iBAAiB,CAAC2G,IAAvB;AACA,eAAK3G,iBAAiB,CAAC4G,MAAvB;AACI,iBAAK1F,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKwC,kBAAL,CAAwB,CAAxB;AACA;;AACJ,eAAKvD,iBAAiB,CAACgF,IAAvB;AACI,iBAAK9D,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKsK,cAAL;AACA;;AACJ;AACI,kBAAM,IAAIhM,iCAAJ,CAAsC,IAAtC,CAAN;AAvBJ;AAyBH,OA5BD,CA4BE,OAAOiC,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OApCD,SAoCU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,uBAAc;AACV,UAAIA,QAAQ,GAAG,IAAIgL,kBAAJ,CAAuB,IAAvB,EAA6B,KAAKzK,IAAlC,EAAwC,KAAKE,KAA7C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACuL,gBAA/C;;AACA,UAAI;AACA,aAAKrK,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACwG,KAA7B;AACH,OAJD,CAIE,OAAOlF,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAZD,SAYU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,0BAAiB;AACb,UAAIA,QAAQ,GAAG,IAAIkL,qBAAJ,CAA0B,IAA1B,EAAgC,KAAK3K,IAArC,EAA2C,KAAKE,KAAhD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACyL,mBAA/C;;AACA,UAAI;AACA,aAAKvK,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACgF,IAA7B;AACA,aAAKjE,KAAL,GAAa,GAAb;AACA,aAAKwC,kBAAL,CAAwB,CAAxB;AACH,OAND,CAME,OAAOjC,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAdD,SAcU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,mBAAU;AACN,UAAIA,QAAQ,GAAG,IAAIoL,cAAJ,CAAmB,IAAnB,EAAyB,KAAK7K,IAA9B,EAAoC,KAAKE,KAAzC,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC2L,YAA/C;;AACA,UAAI;AACA,aAAKzK,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACyG,KAA7B;AACA,aAAK1F,KAAL,GAAa,GAAb;AACA,aAAK6K,SAAL;AACA,aAAK7K,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACyG,KAA7B;AACH,OARD,CAQE,OAAOnF,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAhBD,SAgBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,sBAAa;AACT,UAAIA,QAAQ,GAAG,IAAIuL,iBAAJ,CAAsB,IAAtB,EAA4B,KAAKhL,IAAjC,EAAuC,KAAKE,KAA5C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAAC8L,eAA/C;AACA,UAAIxH,GAAG,GAAG,CAAV,CAHS,CAGI;;AACb,UAAI;AACA,aAAKpD,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACAuD,WAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,YAAG,EAAG,CAAGD,GAAG,GAAG,EAAR,GAAe,CAAC,IAAjB,KAA0B,CAA1B,IAA+B,CAAE,KAAMA,GAAG,GAAG,EAAb,IAAsB,KAAMtE,iBAAiB,CAAC0G,aAAlB,GAAkC,EAAzC,GAAiD,KAAM1G,iBAAiB,CAAC2G,IAAlB,GAAyB,EAAhF,GAAwF,KAAM3G,iBAAiB,CAAC4G,MAAlB,GAA2B,EAA9I,CAAD,MAA0J,CAA5L,CAAH,EAAoM;AACpM,eAAKpF,WAAL,CAAiBkD,aAAjB,CAA+B,IAA/B;AACC,SAFD,MAGK;AACJ,eAAKlD,WAAL,CAAiBmD,WAAjB,CAA6B,IAA7B;;AACG,eAAKC,OAAL;AACH;AACJ,OAXD,CAWE,OAAOtD,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAnBD,SAmBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,sBAAa;AACT,UAAIA,QAAQ,GAAG,IAAIyL,iBAAJ,CAAsB,IAAtB,EAA4B,KAAKlL,IAAjC,EAAuC,KAAKE,KAA5C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACgM,eAA/C;AACA,UAAI1H,GAAG,GAAG,CAAV,CAHS,CAGI;;AACb,UAAI;AACA,aAAKvD,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,EAAzC,EAA4C,KAAK3B,IAAjD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACI,iBAAKpB,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACsG,KAA7B;AACA,iBAAKvF,KAAL,GAAa,GAAb;AACA,iBAAKkL,cAAL;AACA,iBAAKlL,KAAL,GAAa,GAAb;;AACA,iBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,eAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,mBAAMD,GAAG,KAAGtE,iBAAiB,CAACgH,KAA9B,EAAqC;AACjC,mBAAKjG,KAAL,GAAa,GAAb;AACA,mBAAKK,KAAL,CAAWpB,iBAAiB,CAACgH,KAA7B;AACA,mBAAKjG,KAAL,GAAa,GAAb;AACA,mBAAKkL,cAAL;AACA,mBAAKlL,KAAL,GAAa,GAAb;;AACA,mBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,iBAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;AACH;;AACD,iBAAKxD,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACgK,KAA7B;AACA;;AAEJ,eAAK,CAAL;AACI,iBAAK9I,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACsG,KAA7B;AACA,iBAAKvF,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACgK,KAA7B;AACA;AA7BJ;AAgCH,OApCD,CAoCE,OAAO1I,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OA5CD,SA4CU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,0BAAiB;AACb,UAAIA,QAAQ,GAAG,IAAI4L,qBAAJ,CAA0B,IAA1B,EAAgC,KAAKrL,IAArC,EAA2C,KAAKE,KAAhD,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACmM,mBAA/C;;AACA,UAAI;AACA,aAAKjL,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,aAAKS,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAAC4G,MAA7B;AACA,aAAK7F,KAAL,GAAa,GAAb;AACA,aAAKK,KAAL,CAAWpB,iBAAiB,CAACmK,KAA7B;AACA,aAAKpJ,KAAL,GAAa,GAAb;AACA,aAAK6K,SAAL;AACH,OARD,CAQE,OAAOtK,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OAhBD,SAgBU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,qBAAY;AACR,UAAIA,QAAQ,GAAG,IAAI8L,gBAAJ,CAAqB,IAArB,EAA2B,KAAKvL,IAAhC,EAAsC,KAAKE,KAA3C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACqM,cAA/C;AACA,UAAI/H,GAAG,GAAG,CAAV,CAHQ,CAGK;;AACb,UAAI;AACA,aAAKvD,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,YAAIC,GAAG,GAAG,KAAKpC,OAAL,CAAaqC,eAAb,CAA6B,KAAKC,MAAlC,EAAyC,EAAzC,EAA4C,KAAK3B,IAAjD,CAAV;;AACA,gBAAOyB,GAAP;AACA,eAAK,CAAL;AACI,iBAAKpB,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,iBAAKtF,KAAL,GAAa,GAAb;AACA,iBAAK6K,SAAL;AACA,iBAAK7K,KAAL,GAAa,GAAb;;AACA,iBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,eAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,mBAAMD,GAAG,KAAGtE,iBAAiB,CAACgH,KAA9B,EAAqC;AACjC,mBAAKjG,KAAL,GAAa,GAAb;AACA,mBAAKK,KAAL,CAAWpB,iBAAiB,CAACgH,KAA7B;AACA,mBAAKjG,KAAL,GAAa,GAAb;AACA,mBAAK6K,SAAL;AACA,mBAAK7K,KAAL,GAAa,GAAb;;AACA,mBAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACAiC,iBAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;AACH;;AACD,iBAAKxD,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;;AAEJ,eAAK,CAAL;AACI,iBAAK1I,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAACqG,KAA7B;AACA,iBAAKtF,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4J,KAA7B;AACA;AA7BJ;AAgCH,OApCD,CAoCE,OAAOtI,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OA5CD,SA4CU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;WAID,qBAAY;AACR,UAAIA,QAAQ,GAAG,IAAIgM,gBAAJ,CAAqB,IAArB,EAA2B,KAAKzL,IAAhC,EAAsC,KAAKE,KAA3C,CAAf;AACA,WAAKC,SAAL,CAAeV,QAAf,EAAyB,EAAzB,EAA6BN,iBAAiB,CAACuM,cAA/C;AACA,UAAIjI,GAAG,GAAG,CAAV,CAHQ,CAGK;;AACb,UAAI;AACA,aAAKvD,KAAL,GAAa,GAAb;;AACA,aAAKS,WAAL,CAAiBa,IAAjB,CAAsB,IAAtB;;AACA,gBAAO,KAAKG,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAP;AACA,eAAKvE,iBAAiB,CAAC4G,MAAvB;AACItG,oBAAQ,GAAG,IAAIkM,sBAAJ,CAA2B,IAA3B,EAAiClM,QAAjC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC4G,MAA7B;AACA;;AACJ,eAAK5G,iBAAiB,CAAC0C,UAAvB;AACA,eAAK1C,iBAAiB,CAACyM,uBAAvB;AACInM,oBAAQ,GAAG,IAAIoM,sBAAJ,CAA2B,IAA3B,EAAiCpM,QAAjC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACAuD,eAAG,GAAG,KAAK9B,MAAL,CAAY+B,EAAZ,CAAe,CAAf,CAAN;;AACA,gBAAG,EAAED,GAAG,KAAGtE,iBAAiB,CAAC0C,UAAxB,IAAsC4B,GAAG,KAAGtE,iBAAiB,CAACyM,uBAAhE,CAAH,EAA6F;AAC7F,mBAAKjL,WAAL,CAAiBkD,aAAjB,CAA+B,IAA/B;AACC,aAFD,MAGK;AACJ,mBAAKlD,WAAL,CAAiBmD,WAAjB,CAA6B,IAA7B;;AACG,mBAAKC,OAAL;AACH;;AACD;;AACJ,eAAK5E,iBAAiB,CAACsG,KAAvB;AACIhG,oBAAQ,GAAG,IAAIqM,sBAAJ,CAA2B,IAA3B,EAAiCrM,QAAjC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK6L,UAAL;AACA;;AACJ,eAAK5M,iBAAiB,CAACqG,KAAvB;AACI/F,oBAAQ,GAAG,IAAIuM,qBAAJ,CAA0B,IAA1B,EAAgCvM,QAAhC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAK+L,SAAL;AACA;;AACJ,eAAK9M,iBAAiB,CAAC0G,aAAvB;AACIpG,oBAAQ,GAAG,IAAIyM,wBAAJ,CAA6B,IAA7B,EAAmCzM,QAAnC,CAAX;AACA,iBAAKY,aAAL,CAAmBZ,QAAnB,EAA6B,CAA7B;AACA,iBAAKS,KAAL,GAAa,GAAb;AACA,iBAAKK,KAAL,CAAWpB,iBAAiB,CAAC0G,aAA7B;AACA;;AACJ;AACI,kBAAM,IAAIrH,iCAAJ,CAAsC,IAAtC,CAAN;AAxCJ;AA0CH,OA7CD,CA6CE,OAAOiC,EAAP,EAAW;AACZ,YAAGA,EAAE,YAAYjC,iCAAjB,EAAoD;AAChDiB,kBAAQ,CAACiB,SAAT,GAAqBD,EAArB;;AACA,eAAKE,WAAL,CAAiBC,WAAjB,CAA6B,IAA7B,EAAmCH,EAAnC;;AACA,eAAKE,WAAL,CAAiBE,OAAjB,CAAyB,IAAzB,EAA+BJ,EAA/B;AACH,SAJD,MAIO;AACN,gBAAMA,EAAN;AACA;AACD,OArDD,SAqDU;AACN,aAAKK,QAAL;AACH;;AACD,aAAOrB,QAAP;AACH;;;;EA18C6CjB,a;;AAA1BW,iB,CAEVgN,e,GAAkB,gB;AAFRhN,iB,CAGVI,Y,GAAe,CAAE,IAAF,EAAQ,KAAR,EAAe,KAAf,EAAsB,KAAtB,EAA6B,KAA7B,EAAoC,MAApC,EAA4C,KAA5C,EACE,KADF,EACS,KADT,EACgB,KADhB,EACuB,KADvB,EAC8B,KAD9B,EACqC,KADrC,EAC4C,MAD5C,EAEE,MAFF,EAEU,KAFV,EAEiB,KAFjB,EAEwB,KAFxB,EAE+B,KAF/B,EAEsC,KAFtC,EAE6C,KAF7C,EAGE,KAHF,EAGS,MAHT,EAGiB,KAHjB,EAGwB,KAHxB,C;AAHLJ,iB,CAOVK,a,GAAgB,CAAE,IAAF,EAAQ,IAAR,EAAc,IAAd,EAAoB,IAApB,EAA0B,IAA1B,EAAgC,IAAhC,EAAsC,IAAtC,EAA4C,IAA5C,EACE,IADF,EACQ,IADR,EACc,IADd,EACoB,IADpB,EAC0B,IAD1B,EACgC,IADhC,EACsC,IADtC,EAC4C,IAD5C,EAEE,IAFF,EAEQ,IAFR,EAEc,IAFd,EAEoB,IAFpB,EAE0B,IAF1B,EAEgC,IAFhC,EAEsC,IAFtC,EAE4C,IAF5C,EAGE,IAHF,EAGQ,YAHR,EAGsB,QAHtB,EAGgC,WAHhC,EAIE,YAJF,EAIgB,YAJhB,EAI8B,eAJ9B,EAKE,MALF,EAKU,QALV,EAKoB,yBALpB,EAME,IANF,C;AAPNL,iB,CAcVG,S,GAAY,CAAE,SAAF,EAAa,YAAb,EAA2B,UAA3B,EAAuC,WAAvC,EACE,YADF,EACgB,eADhB,EACiC,WADjC,EAC8C,oBAD9C,EAEE,iBAFF,EAEqB,gBAFrB,EAEuC,oBAFvC,EAGE,mBAHF,EAGuB,UAHvB,EAGmC,iBAHnC,EAIE,iBAJF,EAIqB,YAJrB,EAImC,kBAJnC,EAKE,OALF,EAKW,oBALX,EAKiC,aALjC,EAKgD,aALhD,EAME,gBANF,EAMoB,SANpB,EAM+B,YAN/B,EAM6C,YAN7C,EAOE,gBAPF,EAOoB,WAPpB,EAOiC,WAPjC,C;;AAi8CvBH,iBAAiB,CAACqB,GAAlB,GAAwBhC,gBAAxB;AACAW,iBAAiB,CAACkD,IAAlB,GAAyB,CAAzB;AACAlD,iBAAiB,CAACmD,IAAlB,GAAyB,CAAzB;AACAnD,iBAAiB,CAACwE,IAAlB,GAAyB,CAAzB;AACAxE,iBAAiB,CAACyE,IAAlB,GAAyB,CAAzB;AACAzE,iBAAiB,CAAC+E,IAAlB,GAAyB,CAAzB;AACA/E,iBAAiB,CAACgF,IAAlB,GAAyB,CAAzB;AACAhF,iBAAiB,CAACiF,IAAlB,GAAyB,CAAzB;AACAjF,iBAAiB,CAACkF,IAAlB,GAAyB,CAAzB;AACAlF,iBAAiB,CAACmF,IAAlB,GAAyB,CAAzB;AACAnF,iBAAiB,CAACuF,IAAlB,GAAyB,EAAzB;AACAvF,iBAAiB,CAACgH,KAAlB,GAA0B,EAA1B;AACAhH,iBAAiB,CAAC8I,KAAlB,GAA0B,EAA1B;AACA9I,iBAAiB,CAACwI,KAAlB,GAA0B,EAA1B;AACAxI,iBAAiB,CAAC0I,KAAlB,GAA0B,EAA1B;AACA1I,iBAAiB,CAACoG,KAAlB,GAA0B,EAA1B;AACApG,iBAAiB,CAAC4I,KAAlB,GAA0B,EAA1B;AACA5I,iBAAiB,CAACqG,KAAlB,GAA0B,EAA1B;AACArG,iBAAiB,CAAC4J,KAAlB,GAA0B,EAA1B;AACA5J,iBAAiB,CAACsG,KAAlB,GAA0B,EAA1B;AACAtG,iBAAiB,CAACgK,KAAlB,GAA0B,EAA1B;AACAhK,iBAAiB,CAACmK,KAAlB,GAA0B,EAA1B;AACAnK,iBAAiB,CAACuG,KAAlB,GAA0B,EAA1B;AACAvG,iBAAiB,CAACwG,KAAlB,GAA0B,EAA1B;AACAxG,iBAAiB,CAACyG,KAAlB,GAA0B,EAA1B;AACAzG,iBAAiB,CAAC0C,UAAlB,GAA+B,EAA/B;AACA1C,iBAAiB,CAAC4C,MAAlB,GAA2B,EAA3B;AACA5C,iBAAiB,CAAC0F,SAAlB,GAA8B,EAA9B;AACA1F,iBAAiB,CAACoF,UAAlB,GAA+B,EAA/B;AACApF,iBAAiB,CAAC8C,UAAlB,GAA+B,EAA/B;AACA9C,iBAAiB,CAAC0G,aAAlB,GAAkC,EAAlC;AACA1G,iBAAiB,CAAC2G,IAAlB,GAAyB,EAAzB;AACA3G,iBAAiB,CAAC4G,MAAlB,GAA2B,EAA3B;AACA5G,iBAAiB,CAACyM,uBAAlB,GAA4C,EAA5C;AACAzM,iBAAiB,CAACiN,EAAlB,GAAuB,EAAvB;AAEAjN,iBAAiB,CAACiB,YAAlB,GAAiC,CAAjC;AACAjB,iBAAiB,CAACoC,eAAlB,GAAoC,CAApC;AACApC,iBAAiB,CAACqE,aAAlB,GAAkC,CAAlC;AACArE,iBAAiB,CAAC8E,cAAlB,GAAmC,CAAnC;AACA9E,iBAAiB,CAACsF,eAAlB,GAAoC,CAApC;AACAtF,iBAAiB,CAACyF,kBAAlB,GAAuC,CAAvC;AACAzF,iBAAiB,CAAC6F,cAAlB,GAAmC,CAAnC;AACA7F,iBAAiB,CAAC+F,uBAAlB,GAA4C,CAA5C;AACA/F,iBAAiB,CAACmG,oBAAlB,GAAyC,CAAzC;AACAnG,iBAAiB,CAAC+G,mBAAlB,GAAwC,CAAxC;AACA/G,iBAAiB,CAACkH,uBAAlB,GAA4C,EAA5C;AACAlH,iBAAiB,CAACkJ,sBAAlB,GAA2C,EAA3C;AACAlJ,iBAAiB,CAACyJ,aAAlB,GAAkC,EAAlC;AACAzJ,iBAAiB,CAAC2J,oBAAlB,GAAyC,EAAzC;AACA3J,iBAAiB,CAAC8J,oBAAlB,GAAyC,EAAzC;AACA9J,iBAAiB,CAACkK,eAAlB,GAAoC,EAApC;AACAlK,iBAAiB,CAACqK,qBAAlB,GAA0C,EAA1C;AACArK,iBAAiB,CAAC6K,UAAlB,GAA+B,EAA/B;AACA7K,iBAAiB,CAACiL,uBAAlB,GAA4C,EAA5C;AACAjL,iBAAiB,CAACoL,gBAAlB,GAAqC,EAArC;AACApL,iBAAiB,CAACuL,gBAAlB,GAAqC,EAArC;AACAvL,iBAAiB,CAACyL,mBAAlB,GAAwC,EAAxC;AACAzL,iBAAiB,CAAC2L,YAAlB,GAAiC,EAAjC;AACA3L,iBAAiB,CAAC8L,eAAlB,GAAoC,EAApC;AACA9L,iBAAiB,CAACgM,eAAlB,GAAoC,EAApC;AACAhM,iBAAiB,CAACmM,mBAAlB,GAAwC,EAAxC;AACAnM,iBAAiB,CAACqM,cAAlB,GAAmC,EAAnC;AACArM,iBAAiB,CAACuM,cAAlB,GAAmC,EAAnC;;IAEMzL,c;;;;;AAEF,0BAAYoM,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,gCAAMD,MAAN,EAAcC,aAAd;AACA,WAAKF,MAAL,GAAcA,MAAd;AACA,WAAK3M,SAAL,GAAiBP,iBAAiB,CAACiB,YAAnC;AATuC;AAU1C;;;;WAEJ,sBAAa;AACT,aAAO,KAAKoM,mBAAL,CAAyBrL,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,eAAM;AACF,aAAO,KAAKsL,QAAL,CAActN,iBAAiB,CAACqB,GAAhC,EAAqC,CAArC,CAAP;AACH;;;WAED,mBAAUkM,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACC,YAAT,CAAsB,IAAtB;AACN;AACD;;;WAED,kBAASD,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACE,WAAT,CAAqB,IAArB;AACN;AACD;;;;EAhC2BpO,wB;;IAuCvB2C,iB;;;;;AAEF,6BAAYkL,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,gCAAMD,MAAN,EAAcC,aAAd;AACA,WAAKF,MAAL,GAAcA,MAAd;AACA,WAAK3M,SAAL,GAAiBP,iBAAiB,CAACoC,eAAnC;AATuC;AAU1C;;;;WAIH,kBAAShD,GAAT,EAAc;AACb,uGAAeA,GAAf;AACA;;;;EAlB6BC,wB;;IAuB1BwE,uB;;;;;AAEF,mCAAYqJ,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,gCAAM8N,MAAN;;AADqB,WAK5B/L,UAL4B,GAKf,UAASuM,CAAT,EAAY;AACrB,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B3L,iBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKqL,mBAAL,CAAyBrL,iBAAzB,EAA2C0L,CAA3C,CAAP;AACH;AACJ,KAd2B;;AAErB,uLAAetO,GAAf;;AAFqB;AAGxB;;;;WAaJ,qBAAY;AACR,aAAO,KAAKiO,mBAAL,CAAyBxI,gBAAzB,EAA0C,CAA1C,CAAP;AACH;;;WAED,mBAAU0I,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACK,qBAAT,CAA+B,IAA/B;AACN;AACD;;;WAED,kBAASL,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACM,oBAAT,CAA8B,IAA9B;AACN;AACD;;;;EAhCoC7L,iB;;AAqCtChC,iBAAiB,CAAC6D,uBAAlB,GAA4CA,uBAA5C;;IAEMP,e;;;;;AAEF,2BAAY4J,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,gCAAM8N,MAAN;;AACA,kLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUsG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACO,aAAT,CAAuB,IAAvB;AACN;AACD;;;WAED,kBAASP,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACQ,YAAT,CAAsB,IAAtB;AACN;AACD;;;;EArB4B/L,iB;;AA0B9BhC,iBAAiB,CAACsD,eAAlB,GAAoCA,eAApC;;IAEMT,qB;;;;;AAEF,iCAAYqK,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,gCAAM8N,MAAN;;AACA,wLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC8C,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAUyK,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACS,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAAST,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACU,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EArBkCjM,iB;;AA0BpChC,iBAAiB,CAAC6C,qBAAlB,GAA0CA,qBAA1C;;IAEMJ,kB;;;;;AAEF,8BAAYyK,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,gCAAM8N,MAAN;;AACA,qLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC0C,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAU6K,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACW,gBAAT,CAA0B,IAA1B;AACN;AACD;;;WAED,kBAASX,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACY,eAAT,CAAyB,IAAzB;AACN;AACD;;;;EArB+BnM,iB;;AA0BjChC,iBAAiB,CAACyC,kBAAlB,GAAuCA,kBAAvC;;IAEMW,mB;;;;;AAEF,+BAAY8J,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,gCAAM8N,MAAN;;AACA,sLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,yBAAgB;AACZ,aAAO,KAAKiO,mBAAL,CAAyB7H,oBAAzB,EAA8C,CAA9C,CAAP;AACH;;;WAED,mBAAU+H,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACa,iBAAT,CAA2B,IAA3B;AACN;AACD;;;WAED,kBAASb,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACc,gBAAT,CAA0B,IAA1B;AACN;AACD;;;;EArBgCrM,iB;;AA0BlChC,iBAAiB,CAACoD,mBAAlB,GAAwCA,mBAAxC;;IAEMH,sB;;;;;AAEF,kCAAYiK,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,gCAAM8N,MAAN;;AACA,yLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKiO,mBAAL,CAAyBrL,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAUuL,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACe,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASf,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgB,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EArBmCvM,iB;;AA0BrChC,iBAAiB,CAACiD,sBAAlB,GAA2CA,sBAA3C;;IAEMe,c;;;;;AAEF,0BAAYkJ,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,kLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKiO,mBAAL,CAAyBrL,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,sBAAa;AACT,aAAO,KAAKqL,mBAAL,CAAyBhI,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAUkI,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiB,YAAT,CAAsB,IAAtB;AACN;AACD;;;WAED,kBAASjB,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkB,WAAT,CAAqB,IAArB;AACN;AACD;;;;EAzB2BzM,iB;;AA8B7BhC,iBAAiB,CAACgE,cAAlB,GAAmCA,cAAnC;;IAEMjB,sB;;;;;AAEF,kCAAYmK,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,0LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,oBAAW;AACP,aAAO,KAAKiO,mBAAL,CAAyBjJ,eAAzB,EAAyC,CAAzC,CAAP;AACH;;;WAED,sBAAa;AACT,aAAO,KAAKiJ,mBAAL,CAAyBrL,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAUuL,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmB,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASnB,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoB,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EAzBmC3M,iB;;AA8BrChC,iBAAiB,CAAC+C,sBAAlB,GAA2CA,sBAA3C;;IAEMJ,qB;;;;;AAEF,iCAAYuK,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,yLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,kBAAS;AACL,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC4C,MAAhC,EAAwC,CAAxC,CAAP;AACH;;;WAED,mBAAU2K,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACqB,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAASrB,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsB,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EArBkC7M,iB;;AA0BpChC,iBAAiB,CAAC2C,qBAAlB,GAA0CA,qBAA1C;;IAEMyB,e;;;;;AAEF,2BAAY8I,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACqE,aAAnC;AATuC;AAU1C;;;;WAGJ,mBAAUkJ,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuB,aAAT,CAAuB,IAAvB;AACN;AACD;;;WAED,kBAASvB,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwB,YAAT,CAAsB,IAAtB;AACN;AACD;;;;EAzB4B1P,wB;;IAgCxBwF,gB;;;;;AAEF,4BAAYqI,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC8E,cAAnC;AATuC;AAU1C;;;;WAEJ,sBAAa;AACT,aAAO,KAAKwI,QAAL,CAActN,iBAAiB,CAACoF,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAUmI,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyB,cAAT,CAAwB,IAAxB;AACN;AACD;;;WAED,kBAASzB,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0B,aAAT,CAAuB,IAAvB;AACN;AACD;;;;EA5B6B5P,wB;;IAmCzBgG,iB;;;;;AAEF,6BAAY6H,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACsF,eAAnC;AATuC;AAU1C;;;;WAGJ,mBAAUiI,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2B,eAAT,CAAyB,IAAzB;AACN;AACD;;;WAED,kBAAS3B,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4B,cAAT,CAAwB,IAAxB;AACN;AACD;;;;EAzB8B9P,wB;;IAgC1BmG,oB;;;;;AAEF,gCAAY0H,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACyF,kBAAnC;AATuC;AAU1C;;;;WAEJ,qBAAY;AACR,aAAO,KAAK6H,QAAL,CAActN,iBAAiB,CAAC0F,SAAhC,EAA2C,CAA3C,CAAP;AACH;;;WAED,2BAAkB;AACd,aAAO,KAAK2H,mBAAL,CAAyBnH,sBAAzB,EAAgD,CAAhD,CAAP;AACH;;;WAED,mBAAUqH,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6B,kBAAT,CAA4B,IAA5B;AACN;AACD;;;WAED,kBAAS7B,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8B,iBAAT,CAA2B,IAA3B;AACN;AACD;;;;EAhCiChQ,wB;;IAuC7BuG,gB;;;;;AAEF,4BAAYsH,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC6F,cAAnC;AATuC;AAU1C;;;;WAEJ,sBAAa;AACT,aAAO,KAAKwH,mBAAL,CAAyBrL,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAUuL,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+B,cAAT,CAAwB,IAAxB;AACN;AACD;;;WAED,kBAAS/B,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgC,aAAT,CAAuB,IAAvB;AACN;AACD;;;;EA5B6BlQ,wB;;IAmCzByG,yB;;;;;AAEF,qCAAYoH,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC+F,uBAAnC;AATuC;AAU1C;;;;WAEJ,qBAAY;AACR,aAAO,KAAKsH,mBAAL,CAAyBzH,gBAAzB,EAA0C,CAA1C,CAAP;AACH;;;WAED,8BAAqB;AACjB,aAAO,KAAKyH,mBAAL,CAAyBvH,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,0BAAiB;AACb,aAAO,KAAKuH,mBAAL,CAAyBvG,qBAAzB,EAA+C,CAA/C,CAAP;AACH;;;WAED,mBAAUyG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiC,uBAAT,CAAiC,IAAjC;AACN;AACD;;;WAED,kBAASjC,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkC,sBAAT,CAAgC,IAAhC;AACN;AACD;;;;EApCsCpQ,wB;;IA2ClC6G,sB;;;;;AAEF,kCAAYgH,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACmG,oBAAnC;AATuC;AAU1C;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKkH,mBAAL,CAAyBvH,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUyH,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmC,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASnC,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoC,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EA5BmCtQ,wB;;IAmC/ByH,qB;;;;;AAEF,iCAAYoG,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC+G,mBAAnC;AATuC;AAU1C;;;;WAGJ,mBAAUwG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACqC,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAASrC,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsC,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EAzBkCxQ,wB;;IAgC9B4H,yB;;;;;AAEF,qCAAYiG,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACkH,uBAAnC;AATuC;AAU1C;;;;WAIH,kBAAS9H,GAAT,EAAc;AACb,+GAAeA,GAAf;AACA;;;;EAlBqCC,wB;;IAuBlCsJ,qB;;;;;AAEF,iCAAYuE,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AADqB,YAK5B3J,kBAL4B,GAKP,UAASmK,CAAT,EAAY;AAC7B,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B1G,yBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKoG,mBAAL,CAAyBpG,yBAAzB,EAAmDyG,CAAnD,CAAP;AACH;AACJ,KAd2B;;AAErB,4LAAetO,GAAf;;AAFqB;AAGxB;;;;WAaJ,mBAAUmO,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuC,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAASvC,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwC,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EA5BkC9I,yB;;AAiCpCjH,iBAAiB,CAAC2I,qBAAlB,GAA0CA,qBAA1C;;IAEMtB,2B;;;;;AAEF,uCAAY6F,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,kMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKiO,mBAAL,CAAyBxB,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAU0B,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyC,yBAAT,CAAmC,IAAnC;AACN;AACD;;;WAED,kBAASzC,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0C,wBAAT,CAAkC,IAAlC;AACN;AACD;;;;EArBwChJ,yB;;AA0B1CjH,iBAAiB,CAACqH,2BAAlB,GAAgDA,2BAAhD;;IAEME,oB;;;;;AAEF,gCAAY2F,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,2LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUsG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2C,kBAAT,CAA4B,IAA5B;AACN;AACD;;;WAED,kBAAS3C,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4C,iBAAT,CAA2B,IAA3B;AACN;AACD;;;;EArBiClJ,yB;;AA0BnCjH,iBAAiB,CAACuH,oBAAlB,GAAyCA,oBAAzC;;IAEMY,0B;;;;;AAEF,sCAAY+E,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,iMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC8C,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAUyK,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6C,wBAAT,CAAkC,IAAlC;AACN;AACD;;;WAED,kBAAS7C,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8C,uBAAT,CAAiC,IAAjC;AACN;AACD;;;;EArBuCpJ,yB;;AA0BzCjH,iBAAiB,CAACmI,0BAAlB,GAA+CA,0BAA/C;;IAEMG,2B;;;;;AAEF,uCAAY4E,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AADqB,YAK5B3J,kBAL4B,GAKP,UAASmK,CAAT,EAAY;AAC7B,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B1G,yBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKoG,mBAAL,CAAyBpG,yBAAzB,EAAmDyG,CAAnD,CAAP;AACH;AACJ,KAd2B;;AAErB,kMAAetO,GAAf;;AAFqB;AAGxB;;;;WAaJ,sBAAa;AACT,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAACoF,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAUmI,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+C,yBAAT,CAAmC,IAAnC;AACN;AACD;;;WAED,kBAAS/C,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgD,wBAAT,CAAkC,IAAlC;AACN;AACD;;;;EAhCwCtJ,yB;;AAqC1CjH,iBAAiB,CAACsI,2BAAlB,GAAgDA,2BAAhD;;IAEMd,sB;;;;;AAEF,kCAAY0F,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,6LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUsG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiD,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASjD,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkD,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EArBmCxJ,yB;;AA0BrCjH,iBAAiB,CAACwH,sBAAlB,GAA2CA,sBAA3C;;IAEML,wB;;;;;AAEF,oCAAY+F,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,+LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,4BAAmB;AACf,aAAO,KAAKiO,mBAAL,CAAyBjD,uBAAzB,EAAiD,CAAjD,CAAP;AACH;;;WAED,mBAAUmD,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmD,sBAAT,CAAgC,IAAhC;AACN;AACD;;;WAED,kBAASnD,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoD,qBAAT,CAA+B,IAA/B;AACN;AACD;;;;EArBqC1J,yB;;AA0BvCjH,iBAAiB,CAACmH,wBAAlB,GAA6CA,wBAA7C;;IAEMsB,mB;;;;;AAEF,+BAAYyE,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AADqB,YAK5B3J,kBAL4B,GAKP,UAASmK,CAAT,EAAY;AAC7B,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B1G,yBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKoG,mBAAL,CAAyBpG,yBAAzB,EAAmDyG,CAAnD,CAAP;AACH;AACJ,KAd2B;;AAErB,0LAAetO,GAAf;;AAFqB;AAGxB;;;;WAaJ,mBAAUmO,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACqD,iBAAT,CAA2B,IAA3B;AACN;AACD;;;WAED,kBAASrD,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsD,gBAAT,CAA0B,IAA1B;AACN;AACD;;;;EA5BgC5J,yB;;AAiClCjH,iBAAiB,CAACyI,mBAAlB,GAAwCA,mBAAxC;;IAEML,4B;;;;;AAEF,wCAAY8E,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,mMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,uBAAc;AACV,aAAO,KAAKiO,mBAAL,CAAyB/B,kBAAzB,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAUiC,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuD,0BAAT,CAAoC,IAApC;AACN;AACD;;;WAED,kBAASvD,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwD,yBAAT,CAAmC,IAAnC;AACN;AACD;;;;EArByC9J,yB;;AA0B3CjH,iBAAiB,CAACoI,4BAAlB,GAAiDA,4BAAjD;;IAEMS,sB;;;;;AAEF,kCAAYqE,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,6LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,6BAAoB;AAChB,aAAO,KAAKoG,mBAAL,CAAyBpE,wBAAzB,EAAkD,CAAlD,CAAP;AACH;;;WAED,mBAAUsE,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyD,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASzD,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0D,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EAzBmChK,yB;;AA8BrCjH,iBAAiB,CAAC6I,sBAAlB,GAA2CA,sBAA3C;;IAEMN,oB;;;;;AAEF,gCAAY2E,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AADqB,YAK5B3J,kBAL4B,GAKP,UAASmK,CAAT,EAAY;AAC7B,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B1G,yBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKoG,mBAAL,CAAyBpG,yBAAzB,EAAmDyG,CAAnD,CAAP;AACH;AACJ,KAd2B;;AAErB,2LAAetO,GAAf;;AAFqB;AAGxB;;;;WAaJ,mBAAUmO,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2D,kBAAT,CAA4B,IAA5B;AACN;AACD;;;WAED,kBAAS3D,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4D,iBAAT,CAA2B,IAA3B;AACN;AACD;;;;EA5BiClK,yB;;AAiCnCjH,iBAAiB,CAACuI,oBAAlB,GAAyCA,oBAAzC;;IAEMV,gC;;;;;AAEF,4CAAYqF,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,uMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,2BAAkB;AACd,aAAO,KAAKiO,mBAAL,CAAyBxD,sBAAzB,EAAgD,CAAhD,CAAP;AACH;;;WAED,mBAAU0D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6D,8BAAT,CAAwC,IAAxC;AACN;AACD;;;WAED,kBAAS7D,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8D,6BAAT,CAAuC,IAAvC;AACN;AACD;;;;EArB6CpK,yB;;AA0B/CjH,iBAAiB,CAAC6H,gCAAlB,GAAqDA,gCAArD;;IAEMJ,yB;;;;;AAEF,qCAAYyF,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,gMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,oBAAW;AACP,aAAO,KAAKiO,mBAAL,CAAyB7D,eAAzB,EAAyC,CAAzC,CAAP;AACH;;;WAED,mBAAU+D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+D,uBAAT,CAAiC,IAAjC;AACN;AACD;;;WAED,kBAAS/D,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgE,sBAAT,CAAgC,IAAhC;AACN;AACD;;;;EArBsCtK,yB;;AA0BxCjH,iBAAiB,CAACyH,yBAAlB,GAA8CA,yBAA9C;;IAEMQ,6B;;;;;AAEF,yCAAYiF,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,oMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBrC,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUuC,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiE,2BAAT,CAAqC,IAArC;AACN;AACD;;;WAED,kBAASjE,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkE,0BAAT,CAAoC,IAApC;AACN;AACD;;;;EArB0CxK,yB;;AA0B5CjH,iBAAiB,CAACiI,6BAAlB,GAAkDA,6BAAlD;;IAEMN,gC;;;;;AAEF,4CAAYuF,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,uMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,2BAAkB;AACd,aAAO,KAAKiO,mBAAL,CAAyB3D,sBAAzB,EAAgD,CAAhD,CAAP;AACH;;;WAED,mBAAU6D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmE,8BAAT,CAAwC,IAAxC;AACN;AACD;;;WAED,kBAASnE,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoE,6BAAT,CAAuC,IAAvC;AACN;AACD;;;;EArB6C1K,yB;;AA0B/CjH,iBAAiB,CAAC2H,gCAAlB,GAAqDA,gCAArD;;IAEMqB,0B;;;;;AAEF,sCAAYkE,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,iMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,4BAAmB;AACf,aAAO,KAAKoG,mBAAL,CAAyBjD,uBAAzB,EAAiD,CAAjD,CAAP;AACH;;;WAED,mBAAUmD,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACqE,wBAAT,CAAkC,IAAlC;AACN;AACD;;;WAED,kBAASrE,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsE,uBAAT,CAAiC,IAAjC;AACN;AACD;;;;EAzBuC5K,yB;;AA8BzCjH,iBAAiB,CAACgJ,0BAAlB,GAA+CA,0BAA/C;;IAEMjB,wB;;;;;AAEF,oCAAYmF,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,+LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,mBAAU;AACN,aAAO,KAAKiO,mBAAL,CAAyB3B,cAAzB,EAAwC,CAAxC,CAAP;AACH;;;WAED,mBAAU6B,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuE,sBAAT,CAAgC,IAAhC;AACN;AACD;;;WAED,kBAASvE,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwE,qBAAT,CAA+B,IAA/B;AACN;AACD;;;;EArBqC9K,yB;;AA0BvCjH,iBAAiB,CAAC+H,wBAAlB,GAA6CA,wBAA7C;;IAEMkB,wB;;;;;AAEF,oCAAYiE,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACkJ,sBAAnC;AATuC;AAU1C;;;;WAIH,kBAAS9J,GAAT,EAAc;AACb,8GAAeA,GAAf;AACA;;;;EAlBoCC,wB;;IAuBjC+J,6B;;;;;AAEF,yCAAY8D,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,oMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,2BAAkB;AACd,aAAO,KAAKiO,mBAAL,CAAyB3D,sBAAzB,EAAgD,CAAhD,CAAP;AACH;;;WAED,mBAAU6D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyE,2BAAT,CAAqC,IAArC;AACN;AACD;;;WAED,kBAASzE,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0E,0BAAT,CAAoC,IAApC;AACN;AACD;;;;EArB0ChJ,wB;;AA0B5CjJ,iBAAiB,CAACoJ,6BAAlB,GAAkDA,6BAAlD;;IAEMG,sB;;;;;AAEF,kCAAY2D,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,6LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,oBAAW;AACP,aAAO,KAAKiO,mBAAL,CAAyB7D,eAAzB,EAAyC,CAAzC,CAAP;AACH;;;WAED,mBAAU+D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2E,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAAS3E,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4E,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EArBmClJ,wB;;AA0BrCjJ,iBAAiB,CAACuJ,sBAAlB,GAA2CA,sBAA3C;;IAEMF,6B;;;;;AAEF,yCAAY6D,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,oMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,2BAAkB;AACd,aAAO,KAAKiO,mBAAL,CAAyBxD,sBAAzB,EAAgD,CAAhD,CAAP;AACH;;;WAED,mBAAU0D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6E,2BAAT,CAAqC,IAArC;AACN;AACD;;;WAED,kBAAS7E,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8E,0BAAT,CAAoC,IAApC;AACN;AACD;;;;EArB0CpJ,wB;;AA0B5CjJ,iBAAiB,CAACqJ,6BAAlB,GAAkDA,6BAAlD;;IAEMF,wB;;;;;AAEF,oCAAY+D,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,+LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKiO,mBAAL,CAAyBxB,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAU0B,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+E,sBAAT,CAAgC,IAAhC;AACN;AACD;;;WAED,kBAAS/E,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgF,qBAAT,CAA+B,IAA/B;AACN;AACD;;;;EArBqCtJ,wB;;AA0BvCjJ,iBAAiB,CAACmJ,wBAAlB,GAA6CA,wBAA7C;;IAEMG,gC;;;;;AAEF,4CAAY4D,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,uMAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBrC,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUuC,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiF,8BAAT,CAAwC,IAAxC;AACN;AACD;;;WAED,kBAASjF,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkF,6BAAT,CAAuC,IAAvC;AACN;AACD;;;;EArB6CxJ,wB;;AA0B/CjJ,iBAAiB,CAACsJ,gCAAlB,GAAqDA,gCAArD;;IAEME,e;;;;;AAEF,2BAAY0D,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACyJ,aAAnC;AATuC;AAU1C;;;;WAGJ,mBAAU8D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmF,aAAT,CAAuB,IAAvB;AACN;AACD;;;WAED,kBAASnF,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoF,YAAT,CAAsB,IAAtB;AACN;AACD;;;;EAzB4BtT,wB;;IAgCxBqK,sB;;;;;AAEF,kCAAYwD,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;;AAPuC,YAY9C7J,kBAZ8C,GAYzB,UAASmK,CAAT,EAAY;AAC7B,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B1G,yBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKoG,mBAAL,CAAyBpG,yBAAzB,EAAmDyG,CAAnD,CAAP;AACH;AACJ,KArB6C;;AAQvC,YAAKR,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC2J,oBAAnC;AATuC;AAU1C;;;;WAaJ,mBAAU4D,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACqF,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASrF,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsF,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EAnCmCxT,wB;;IA0C/BwK,sB;;;;;AAEF,kCAAYqD,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;;AAPuC,YAY9CrD,UAZ8C,GAYjC,UAAS2D,CAAT,EAAY;AACrB,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0B1D,iBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKoD,mBAAL,CAAyBpD,iBAAzB,EAA2CyD,CAA3C,CAAP;AACH;AACJ,KArB6C;;AAQvC,YAAKR,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC8J,oBAAnC;AATuC;AAU1C;;;;WAaJ,mBAAUyD,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuF,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASvF,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwF,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EAnCmC1T,wB;;IA0C/B4K,iB;;;;;AAEF,6BAAYiD,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACkK,eAAnC;AATuC;AAU1C;;;;WAEJ,sBAAa;AACT,aAAO,KAAKmD,mBAAL,CAAyBxB,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,8BAAqB;AACjB,aAAO,KAAKwB,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUsG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyF,eAAT,CAAyB,IAAzB;AACN;AACD;;;WAED,kBAASzF,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0F,cAAT,CAAwB,IAAxB;AACN;AACD;;;;EAhC8B5T,wB;;IAuC1B+K,uB;;;;;AAEF,mCAAY8C,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACqK,qBAAnC;AATuC;AAU1C;;;;WAIH,kBAASjL,GAAT,EAAc;AACb,6GAAeA,GAAf;AACA;;;;EAlBmCC,wB;;IAuBhCsL,a;;;;;AAEF,yBAAYuC,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,oLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiO,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUsG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2F,WAAT,CAAqB,IAArB;AACN;AACD;;;WAED,kBAAS3F,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4F,UAAT,CAAoB,IAApB;AACN;AACD;;;;EArB0B/I,uB;;AA0B5BpK,iBAAiB,CAAC2K,aAAlB,GAAkCA,aAAlC;;IAEMD,qB;;;;;AAEF,iCAAYwC,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,4LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAGJ,mBAAUmO,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6F,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAAS7F,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8F,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EAlBkCjJ,uB;;AAuBpCpK,iBAAiB,CAAC0K,qBAAlB,GAA0CA,qBAA1C;;IAEMF,mB;;;;;AAEF,+BAAY0C,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,0LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,iBAAQ;AACJ,aAAO,KAAKiO,mBAAL,CAAyBzC,YAAzB,EAAsC,CAAtC,CAAP;AACH;;;WAED,mBAAU2C,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+F,iBAAT,CAA2B,IAA3B;AACN;AACD;;;WAED,kBAAS/F,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgG,gBAAT,CAA0B,IAA1B;AACN;AACD;;;;EArBgCnJ,uB;;AA0BlCpK,iBAAiB,CAACwK,mBAAlB,GAAwCA,mBAAxC;;IAEMF,mB;;;;;AAEF,+BAAY4C,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,0LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC0C,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAU6K,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiG,iBAAT,CAA2B,IAA3B;AACN;AACD;;;WAED,kBAASjG,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkG,gBAAT,CAA0B,IAA1B;AACN;AACD;;;;EArBgCrJ,uB;;AA0BlCpK,iBAAiB,CAACsK,mBAAlB,GAAwCA,mBAAxC;;IAEMC,kB;;;;;AAEF,8BAAY2C,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,yLAAe9N,GAAf;;AAFqB;AAGxB;;;;WAGJ,mBAAUmO,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmG,gBAAT,CAA0B,IAA1B;AACN;AACD;;;WAED,kBAASnG,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoG,eAAT,CAAyB,IAAzB;AACN;AACD;;;;EAlB+BvJ,uB;;AAuBjCpK,iBAAiB,CAACuK,kBAAlB,GAAuCA,kBAAvC;;IAEMK,Y;;;;;AAEF,wBAAYsC,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;;AAPuC,YAe9C1K,UAf8C,GAejC,UAASgL,CAAT,EAAY;AACxB,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACjB6L,SAAC,GAAG,IAAJ;AACA;;AACE,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKkG,SAAL,CAAe5T,iBAAiB,CAAC0C,UAAjC,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAK4K,QAAL,CAActN,iBAAiB,CAAC0C,UAAhC,EAA4CgL,CAA5C,CAAP;AACH;AACJ,KAxB6C;;AAQvC,YAAKR,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC6K,UAAnC;AACA,YAAKC,KAAL,GAAa,IAAb,CAVuC,CAUpB;;AACnB,YAAKtH,IAAL,GAAY,IAAZ,CAXuC,CAWrB;;AAClB,YAAKuH,IAAL,GAAY,IAAZ,CAZuC,CAYrB;;AAZqB;AAa1C;;;;WAcJ,mBAAUwC,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsG,UAAT,CAAoB,IAApB;AACN;AACD;;;WAED,kBAAStG,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuG,SAAT,CAAmB,IAAnB;AACN;AACD;;;;EAvCyBzU,wB;;IA8CrB2L,yB;;;;;AAEF,qCAAYkC,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;;AAPuC,YAgB9ClC,WAhB8C,GAgBhC,UAASwC,CAAT,EAAY;AACtB,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0BxC,kBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKkC,mBAAL,CAAyBlC,kBAAzB,EAA4CuC,CAA5C,CAAP;AACH;AACJ,KAzB6C;;AAQvC,YAAKR,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACiL,uBAAnC;AATuC;AAU1C;;;;WAEJ,gBAAO;AACH,aAAO,KAAKqC,QAAL,CAActN,iBAAiB,CAAC2G,IAAhC,EAAsC,CAAtC,CAAP;AACH;;;WAaD,mBAAU4G,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwG,uBAAT,CAAiC,IAAjC;AACN;AACD;;;WAED,kBAASxG,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyG,sBAAT,CAAgC,IAAhC;AACN;AACD;;;;EAvCsC3U,wB;;IA8ClC8L,kB;;;;;AAEF,8BAAY+B,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACoL,gBAAnC;AATuC;AAU1C;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAKiC,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,0BAAiB;AACb,aAAO,KAAKoG,mBAAL,CAAyB7B,qBAAzB,EAA+C,CAA/C,CAAP;AACH;;;WAED,mBAAU+B,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0G,gBAAT,CAA0B,IAA1B;AACN;AACD;;;WAED,kBAAS1G,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2G,eAAT,CAAyB,IAAzB;AACN;AACD;;;;EAhC+B7U,wB;;IAuC3BiM,kB;;;;;AAEF,8BAAY4B,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACuL,gBAAnC;AATuC;AAU1C;;;;WAGJ,mBAAUgC,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4G,gBAAT,CAA0B,IAA1B;AACN;AACD;;;WAED,kBAAS5G,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6G,eAAT,CAAyB,IAAzB;AACN;AACD;;;;EAzB+B/U,wB;;IAgC3BmM,qB;;;;;AAEF,iCAAY0B,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACyL,mBAAnC;AATuC;AAU1C;;;;WAEJ,8BAAqB;AACjB,aAAO,KAAK4B,mBAAL,CAAyBpG,yBAAzB,EAAmD,CAAnD,CAAP;AACH;;;WAED,mBAAUsG,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8G,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAAS9G,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+G,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EA5BkCjV,wB;;IAmC9BqM,c;;;;;AAEF,0BAAYwB,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC2L,YAAnC;AATuC;AAU1C;;;;WAEJ,qBAAY;AACR,aAAO,KAAK0B,mBAAL,CAAyBf,gBAAzB,EAA0C,CAA1C,CAAP;AACH;;;WAED,mBAAUiB,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgH,YAAT,CAAsB,IAAtB;AACN;AACD;;;WAED,kBAAShH,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiH,WAAT,CAAqB,IAArB;AACN;AACD;;;;EA5B2BnV,wB;;IAmCvBwM,iB;;;;;AAEF,6BAAYqB,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAAC8L,eAAnC;AATuC;AAU1C;;;;WAEJ,gBAAO;AACH,aAAO,KAAKwB,QAAL,CAActN,iBAAiB,CAAC2G,IAAhC,EAAsC,CAAtC,CAAP;AACH;;;WAED,kBAAS;AACL,aAAO,KAAK2G,QAAL,CAActN,iBAAiB,CAAC4G,MAAhC,EAAwC,CAAxC,CAAP;AACH;;;WAED,yBAAgB;AACZ,aAAO,KAAK0G,QAAL,CAActN,iBAAiB,CAAC0G,aAAhC,EAA+C,CAA/C,CAAP;AACH;;;WAED,mBAAU6G,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkH,eAAT,CAAyB,IAAzB;AACN;AACD;;;WAED,kBAASlH,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmH,cAAT,CAAwB,IAAxB;AACN;AACD;;;;EApC8BrV,wB;;IA2C1B0M,iB;;;;;AAEF,6BAAYmB,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;;AAPuC,YAY9CnB,cAZ8C,GAY7B,UAASyB,CAAT,EAAY;AACzB,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0BzB,qBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKmB,mBAAL,CAAyBnB,qBAAzB,EAA+CwB,CAA/C,CAAP;AACH;AACJ,KArB6C;;AAQvC,YAAKR,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACgM,eAAnC;AATuC;AAU1C;;;;WAaJ,mBAAUuB,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACoH,eAAT,CAAyB,IAAzB;AACN;AACD;;;WAED,kBAASpH,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACqH,cAAT,CAAwB,IAAxB;AACN;AACD;;;;EAnC8BvV,wB;;IA0C1B6M,qB;;;;;AAEF,iCAAYgB,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACmM,mBAAnC;AATuC;AAU1C;;;;WAEJ,kBAAS;AACL,aAAO,KAAKmB,QAAL,CAActN,iBAAiB,CAAC4G,MAAhC,EAAwC,CAAxC,CAAP;AACH;;;WAED,qBAAY;AACR,aAAO,KAAKyG,mBAAL,CAAyBf,gBAAzB,EAA0C,CAA1C,CAAP;AACH;;;WAED,mBAAUiB,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACsH,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAAStH,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACuH,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EAhCkCzV,wB;;IAuC9B+M,gB;;;;;AAEF,4BAAYc,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;;AAPuC,YAY9CxB,SAZ8C,GAYlC,UAAS8B,CAAT,EAAY;AACpB,UAAGA,CAAC,KAAG7L,SAAP,EAAkB;AACd6L,SAAC,GAAG,IAAJ;AACH;;AACD,UAAGA,CAAC,KAAG,IAAP,EAAa;AACT,eAAO,KAAKC,oBAAL,CAA0BrB,gBAA1B,CAAP;AACH,OAFD,MAEO;AACH,eAAO,KAAKe,mBAAL,CAAyBf,gBAAzB,EAA0CoB,CAA1C,CAAP;AACH;AACJ,KArB6C;;AAQvC,YAAKR,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACqM,cAAnC;AATuC;AAU1C;;;;WAaJ,mBAAUkB,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACwH,cAAT,CAAwB,IAAxB;AACN;AACD;;;WAED,kBAASxH,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACyH,aAAT,CAAuB,IAAvB;AACN;AACD;;;;EAnC6B3V,wB;;IA0CzBiN,gB;;;;;AAEF,4BAAYY,MAAZ,EAAoBC,MAApB,EAA4BC,aAA5B,EAA2C;AAAA;;AAAA;;AACvC,QAAGD,MAAM,KAAGtL,SAAZ,EAAuB;AACnBsL,YAAM,GAAG,IAAT;AACH;;AACD,QAAGC,aAAa,KAAGvL,SAAhB,IAA6BuL,aAAa,KAAG,IAAhD,EAAsD;AAClDA,mBAAa,GAAG,CAAC,CAAjB;AACH;;AACD,kCAAMD,MAAN,EAAcC,aAAd;AACA,YAAKF,MAAL,GAAcA,MAAd;AACA,YAAK3M,SAAL,GAAiBP,iBAAiB,CAACuM,cAAnC;AATuC;AAU1C;;;;WAIH,kBAASnN,GAAT,EAAc;AACb,sGAAeA,GAAf;AACA;;;;EAlB4BC,wB;;IAuBzBwN,qB;;;;;AAEF,iCAAYK,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,4LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,qBAAY;AACR,aAAO,KAAKiO,mBAAL,CAAyBjB,gBAAzB,EAA0C,CAA1C,CAAP;AACH;;;WAED,mBAAUmB,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC0H,mBAAT,CAA6B,IAA7B;AACN;AACD;;;WAED,kBAAS1H,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC2H,kBAAT,CAA4B,IAA5B;AACN;AACD;;;;EArBkC5I,gB;;AA0BpCtM,iBAAiB,CAAC6M,qBAAlB,GAA0CA,qBAA1C;;IAEML,sB;;;;;AAEF,kCAAYU,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,6LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,kBAAS;AACL,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC4G,MAAhC,EAAwC,CAAxC,CAAP;AACH;;;WAED,mBAAU2G,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC4H,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAAS5H,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC6H,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EArBmC9I,gB;;AA0BrCtM,iBAAiB,CAACwM,sBAAlB,GAA2CA,sBAA3C;;IAEMG,sB;;;;;AAEF,kCAAYO,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,6LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,sBAAa;AACT,aAAO,KAAKiO,mBAAL,CAAyBtB,iBAAzB,EAA2C,CAA3C,CAAP;AACH;;;WAED,mBAAUwB,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC8H,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAAS9H,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAAC+H,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EArBmChJ,gB;;AA0BrCtM,iBAAiB,CAAC2M,sBAAlB,GAA2CA,sBAA3C;;IAEMI,wB;;;;;AAEF,oCAAYG,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,+LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,yBAAgB;AACZ,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAAC0G,aAAhC,EAA+C,CAA/C,CAAP;AACH;;;WAED,mBAAU6G,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACgI,sBAAT,CAAgC,IAAhC;AACN;AACD;;;WAED,kBAAShI,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACiI,qBAAT,CAA+B,IAA/B;AACN;AACD;;;;EArBqClJ,gB;;AA0BvCtM,iBAAiB,CAAC+M,wBAAlB,GAA6CA,wBAA7C;;IAEML,sB;;;;;AAEF,kCAAYQ,MAAZ,EAAoB9N,GAApB,EAAyB;AAAA;;AAAA;;AACrB,kCAAM8N,MAAN;;AACA,6LAAe9N,GAAf;;AAFqB;AAGxB;;;;WAEJ,mCAA0B;AACtB,aAAO,KAAKkO,QAAL,CAActN,iBAAiB,CAACyM,uBAAhC,EAAyD,CAAzD,CAAP;AACH;;;WAED,sBAAa;AACT,aAAO,KAAKa,QAAL,CAActN,iBAAiB,CAAC0C,UAAhC,EAA4C,CAA5C,CAAP;AACH;;;WAED,mBAAU6K,QAAV,EAAoB;AAChB,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACkI,oBAAT,CAA8B,IAA9B;AACN;AACD;;;WAED,kBAASlI,QAAT,EAAmB;AACf,UAAGA,QAAQ,YAAYpO,mBAAvB,EAA6C;AACzCoO,gBAAQ,CAACmI,mBAAT,CAA6B,IAA7B;AACN;AACD;;;;EAzBmCpJ,gB;;AA8BrCtM,iBAAiB,CAAC0M,sBAAlB,GAA2CA,sBAA3C;AAGA1M,iBAAiB,CAACc,cAAlB,GAAmCA,cAAnC;AACAd,iBAAiB,CAACgC,iBAAlB,GAAsCA,iBAAtC;AACAhC,iBAAiB,CAACoE,eAAlB,GAAoCA,eAApC;AACApE,iBAAiB,CAAC6E,gBAAlB,GAAqCA,gBAArC;AACA7E,iBAAiB,CAACqF,iBAAlB,GAAsCA,iBAAtC;AACArF,iBAAiB,CAACwF,oBAAlB,GAAyCA,oBAAzC;AACAxF,iBAAiB,CAAC4F,gBAAlB,GAAqCA,gBAArC;AACA5F,iBAAiB,CAAC8F,yBAAlB,GAA8CA,yBAA9C;AACA9F,iBAAiB,CAACkG,sBAAlB,GAA2CA,sBAA3C;AACAlG,iBAAiB,CAAC8G,qBAAlB,GAA0CA,qBAA1C;AACA9G,iBAAiB,CAACiH,yBAAlB,GAA8CA,yBAA9C;AACAjH,iBAAiB,CAACiJ,wBAAlB,GAA6CA,wBAA7C;AACAjJ,iBAAiB,CAACwJ,eAAlB,GAAoCA,eAApC;AACAxJ,iBAAiB,CAAC0J,sBAAlB,GAA2CA,sBAA3C;AACA1J,iBAAiB,CAAC6J,sBAAlB,GAA2CA,sBAA3C;AACA7J,iBAAiB,CAACiK,iBAAlB,GAAsCA,iBAAtC;AACAjK,iBAAiB,CAACoK,uBAAlB,GAA4CA,uBAA5C;AACApK,iBAAiB,CAAC4K,YAAlB,GAAiCA,YAAjC;AACA5K,iBAAiB,CAACgL,yBAAlB,GAA8CA,yBAA9C;AACAhL,iBAAiB,CAACmL,kBAAlB,GAAuCA,kBAAvC;AACAnL,iBAAiB,CAACsL,kBAAlB,GAAuCA,kBAAvC;AACAtL,iBAAiB,CAACwL,qBAAlB,GAA0CA,qBAA1C;AACAxL,iBAAiB,CAAC0L,cAAlB,GAAmCA,cAAnC;AACA1L,iBAAiB,CAAC6L,iBAAlB,GAAsCA,iBAAtC;AACA7L,iBAAiB,CAAC+L,iBAAlB,GAAsCA,iBAAtC;AACA/L,iBAAiB,CAACkM,qBAAlB,GAA0CA,qBAA1C;AACAlM,iBAAiB,CAACoM,gBAAlB,GAAqCA,gBAArC;AACApM,iBAAiB,CAACsM,gBAAlB,GAAqCA,gBAArC,C;;;;;;;;;;;;;;;;;;;;;;;;ACl5HA;AACA;AACA;AAIA,IAAMhN,8BAAa,GAAG,CAAC,gDAAD,EAClB,qDADkB,EAElB,oDAFkB,EAGlB,wDAHkB,EAIlB,sDAJkB,EAKlB,kDALkB,EAMlB,oDANkB,EAOlB,kDAPkB,EAQlB,oDARkB,EASlB,qDATkB,EAUlB,yDAVkB,EAWlB,kDAXkB,EAYlB,kDAZkB,EAalB,sDAbkB,EAclB,kDAdkB,EAelB,kDAfkB,EAgBlB,kDAhBkB,EAiBlB,kDAjBkB,EAkBlB,kDAlBkB,EAmBlB,gDAnBkB,EAoBlB,gDApBkB,EAqBlB,kDArBkB,EAsBlB,kDAtBkB,EAuBlB,gDAvBkB,EAwBlB,kDAxBkB,EAyBlB,gDAzBkB,EA0BlB,kDA1BkB,EA2BlB,gDA3BkB,EA4BlB,kDA5BkB,EA6BlB,iDA7BkB,EA8BlB,uDA9BkB,EA+BlB,mDA/BkB,EAgClB,sDAhCkB,EAiClB,iDAjCkB,EAkClB,8CAlCkB,EAmClB,8CAnCkB,EAoClB,yDApCkB,EAqClB,uDArCkB,EAsClB,0DAtCkB,EAuClB,oDAvCkB,EAwClB,kDAxCkB,EAyClB,oDAzCkB,EA0ClB,sDA1CkB,EA2ClB,oDA3CkB,EA4ClB,uDA5CkB,EA6ClB,uDA7CkB,EA8ClB,sDA9CkB,EA+ClB,kDA/CkB,EAgDlB,gDAhDkB,EAiDlB,gDAjDkB,EAkDlB,kDAlDkB,EAmDlB,kDAnDkB,EAoDlB,kDApDkB,EAqDlB,kDArDkB,EAsDlB,gDAtDkB,EAuDlB,gDAvDkB,EAwDlB,gDAxDkB,EAyDlB,gDAzDkB,EA0DlB,gDA1DkB,EA2DlB,iDA3DkB,EA4DlB,gDA5DkB,EA6DlB,gDA7DkB,EA8DlB,gDA9DkB,EA+DlB,gDA/DkB,EAgElB,mDAhEkB,EAiElB,kDAjEkB,EAkElB,gDAlEkB,EAmElB,iDAnEkB,EAoElB,gDApEkB,EAqElB,iDArEkB,EAsElB,gDAtEkB,EAuElB,iDAvEkB,EAwElB,iDAxEkB,EAyElB,gDAzEkB,EA0ElB,gDA1EkB,EA2ElB,gDA3EkB,EA4ElB,gDA5EkB,EA6ElB,iDA7EkB,EA8ElB,gDA9EkB,EA+ElB,kDA/EkB,EAgFlB,oDAhFkB,EAiFlB,iDAjFkB,EAkFlB,iDAlFkB,EAmFlB,kDAnFkB,EAoFlB,mDApFkB,EAqFlB,iDArFkB,EAsFlB,mDAtFkB,EAuFlB,kDAvFkB,EAwFlB,gDAxFkB,EAyFlB,oDAzFkB,EA0FlB,iDA1FkB,EA2FlB,oDA3FkB,EA4FlB,oDA5FkB,EA6FlB,mDA7FkB,EA8FlB,iDA9FkB,EA+FlB,oDA/FkB,EAgGlB,+CAhGkB,EAiGlB,iDAjGkB,EAkGlB,gDAlGkB,EAmGlB,gDAnGkB,EAoGlB,gDApGkB,EAqGlB,+CArGkB,EAsGlB,kDAtGkB,EAuGlB,kDAvGkB,EAwGlB,+CAxGkB,EAyGlB,kDAzGkB,EA0GlB,gDA1GkB,EA2GlB,kDA3GkB,EA4GlB,+CA5GkB,EA6GlB,+CA7GkB,EA8GlB,gDA9GkB,EA+GlB,gDA/GkB,EAgHlB,gDAhHkB,EAiHlB,gDAjHkB,EAkHlB,+CAlHkB,EAmHlB,+CAnHkB,EAoHlB,iDApHkB,EAqHlB,gDArHkB,EAsHlB,kDAtHkB,EAuHlB,+CAvHkB,EAwHlB,gDAxHkB,EAyHlB,gDAzHkB,EA0HlB,gDA1HkB,EA2HlB,iDA3HkB,EA4HlB,+CA5HkB,EA6HlB,kDA7HkB,EA8HlB,kDA9HkB,EA+HlB,+CA/HkB,EAgIlB,iDAhIkB,EAiIlB,gDAjIkB,EAkIlB,kDAlIkB,EAmIlB,kDAnIkB,EAoIlB,kDApIkB,EAqIlB,gDArIkB,EAsIlB,gDAtIkB,EAuIlB,+CAvIkB,EAwIlB,iDAxIkB,EAyIlB,+CAzIkB,EA0IlB,+CA1IkB,EA2IlB,kDA3IkB,EA4IlB,kDA5IkB,EA6IlB,kDA7IkB,EA8IlB,+CA9IkB,EA+IlB,iDA/IkB,EAgJlB,gDAhJkB,EAiJlB,kDAjJkB,EAkJlB,kDAlJkB,EAmJlB,kDAnJkB,EAoJlB,gDApJkB,EAqJlB,mDArJkB,EAsJlB,kDAtJkB,EAuJlB,gDAvJkB,EAwJlB,oDAxJkB,EAyJlB,iDAzJkB,EA0JlB,oDA1JkB,EA2JlB,kDA3JkB,EA4JlB,gDA5JkB,EA6JlB,iDA7JkB,EA8JlB,kDA9JkB,EA+JlB,kDA/JkB,EAgKlB,gDAhKkB,EAiKlB,kDAjKkB,EAkKlB,+CAlKkB,EAmKlB,kDAnKkB,EAoKlB,gDApKkB,EAqKlB,gDArKkB,EAsKlB,+CAtKkB,EAuKlB,uDAvKkB,EAwKlB,wDAxKkB,EAyKlB,0DAzKkB,EA0KlB,0DA1KkB,EA2KlB,wDA3KkB,EA4KlB,mDA5KkB,EA6KlB,gEA7KkB,EA8KlB,0DA9KkB,EA+KlB,uDA/KkB,EAgLlB,0DAhLkB,EAiLlB,0DAjLkB,EAkLlB,0DAlLkB,EAmLlB,wDAnLkB,EAoLlB,kDApLkB,EAqLlB,0DArLkB,EAsLlB,YAtLkB,EAsLAC,IAtLA,CAsLK,EAtLL,CAAtB;AAyLA,IAAMC,oBAAG,GAAG,IAAIH,0BAAJ,GAAiCI,WAAjC,CAA6CH,8BAA7C,CAAZ;AAEA,IAAMI,+BAAc,GAAGF,oBAAG,CAACG,eAAJ,CAAoBC,GAApB,CAAyB,UAACC,EAAD,EAAKC,KAAL;AAAA,SAAe,IAAIT,cAAJ,CAAmBQ,EAAnB,EAAuBC,KAAvB,CAAf;AAAA,CAAzB,CAAvB;;IAEqB6V,gB;;;;;AAwBjB,4BAAY1V,KAAZ,EAAmB;AAAA;;AAAA;;AACf,8BAAMA,KAAN;AACA,UAAKC,OAAL,GAAe,IAAIb,4BAAJ,gDAAuCG,oBAAvC,EAA4CE,+BAA5C,EAA4D,IAAIL,oCAAJ,EAA5D,CAAf;AAFe;AAGlB;;;;SAED,eAAU;AACN,aAAOG,oBAAP;AACH;;;;EA/ByCH,Y;;AAAzBsW,gB,CAEV3I,e,GAAkB,gB;AAFR2I,gB,CAGVC,Y,GAAe,CAAE,uBAAF,EAA2B,QAA3B,C;AAHLD,gB,CAIbE,S,GAAY,CAAE,cAAF,C;AAJCF,gB,CAKbvV,Y,GAAe,CAAE,IAAF,EAAQ,KAAR,EAAe,KAAf,EAAsB,KAAtB,EAA6B,KAA7B,EAAoC,MAApC,EAA4C,KAA5C,EACE,KADF,EACS,KADT,EACgB,KADhB,EACuB,KADvB,EAC8B,KAD9B,EACqC,KADrC,EAC4C,MAD5C,EAEE,MAFF,EAEU,KAFV,EAEiB,KAFjB,EAEwB,KAFxB,EAE+B,KAF/B,EAEsC,KAFtC,EAE6C,KAF7C,EAGE,KAHF,EAGS,MAHT,EAGiB,KAHjB,EAGwB,KAHxB,C;AALFuV,gB,CASbtV,a,GAAgB,CAAE,IAAF,EAAQ,IAAR,EAAc,IAAd,EAAoB,IAApB,EAA0B,IAA1B,EAAgC,IAAhC,EAAsC,IAAtC,EAA4C,IAA5C,EACE,IADF,EACQ,IADR,EACc,IADd,EACoB,IADpB,EAC0B,IAD1B,EACgC,IADhC,EACsC,IADtC,EAC4C,IAD5C,EAEE,IAFF,EAEQ,IAFR,EAEc,IAFd,EAEoB,IAFpB,EAE0B,IAF1B,EAEgC,IAFhC,EAEsC,IAFtC,EAE4C,IAF5C,EAGE,IAHF,EAGQ,YAHR,EAGsB,QAHtB,EAGgC,WAHhC,EAG6C,YAH7C,EAIE,YAJF,EAIgB,eAJhB,EAIiC,MAJjC,EAIyC,QAJzC,EAKE,yBALF,EAK6B,IAL7B,C;AATHsV,gB,CAebxV,S,GAAY,CAAE,MAAF,EAAU,MAAV,EAAkB,MAAlB,EAA0B,MAA1B,EAAkC,MAAlC,EAA0C,MAA1C,EAAkD,MAAlD,EACE,MADF,EACU,MADV,EACkB,MADlB,EAC0B,OAD1B,EACmC,OADnC,EAC4C,OAD5C,EAEE,OAFF,EAEW,OAFX,EAEoB,OAFpB,EAE6B,OAF7B,EAEsC,OAFtC,EAE+C,OAF/C,EAGE,OAHF,EAGW,OAHX,EAGoB,OAHpB,EAG6B,OAH7B,EAGsC,OAHtC,EAG+C,YAH/C,EAIE,QAJF,EAIY,UAJZ,EAIwB,WAJxB,EAIqC,YAJrC,EAImD,YAJnD,EAKE,SALF,EAKa,eALb,EAK8B,MAL9B,EAKsC,QALtC,EAKgD,KALhD,EAME,SANF,EAMa,KANb,EAMoB,yBANpB,EAM+C,KAN/C,EAOE,KAPF,EAOS,IAPT,C;;AAmBpBwV,gBAAgB,CAACtU,GAAjB,GAAuBhC,gBAAvB;AACAsW,gBAAgB,CAACzS,IAAjB,GAAwB,CAAxB;AACAyS,gBAAgB,CAACxS,IAAjB,GAAwB,CAAxB;AACAwS,gBAAgB,CAACnR,IAAjB,GAAwB,CAAxB;AACAmR,gBAAgB,CAAClR,IAAjB,GAAwB,CAAxB;AACAkR,gBAAgB,CAAC5Q,IAAjB,GAAwB,CAAxB;AACA4Q,gBAAgB,CAAC3Q,IAAjB,GAAwB,CAAxB;AACA2Q,gBAAgB,CAAC1Q,IAAjB,GAAwB,CAAxB;AACA0Q,gBAAgB,CAACzQ,IAAjB,GAAwB,CAAxB;AACAyQ,gBAAgB,CAACxQ,IAAjB,GAAwB,CAAxB;AACAwQ,gBAAgB,CAACpQ,IAAjB,GAAwB,EAAxB;AACAoQ,gBAAgB,CAAC3O,KAAjB,GAAyB,EAAzB;AACA2O,gBAAgB,CAAC7M,KAAjB,GAAyB,EAAzB;AACA6M,gBAAgB,CAACnN,KAAjB,GAAyB,EAAzB;AACAmN,gBAAgB,CAACjN,KAAjB,GAAyB,EAAzB;AACAiN,gBAAgB,CAACvP,KAAjB,GAAyB,EAAzB;AACAuP,gBAAgB,CAAC/M,KAAjB,GAAyB,EAAzB;AACA+M,gBAAgB,CAACtP,KAAjB,GAAyB,EAAzB;AACAsP,gBAAgB,CAAC/L,KAAjB,GAAyB,EAAzB;AACA+L,gBAAgB,CAACrP,KAAjB,GAAyB,EAAzB;AACAqP,gBAAgB,CAAC3L,KAAjB,GAAyB,EAAzB;AACA2L,gBAAgB,CAACxL,KAAjB,GAAyB,EAAzB;AACAwL,gBAAgB,CAACpP,KAAjB,GAAyB,EAAzB;AACAoP,gBAAgB,CAACnP,KAAjB,GAAyB,EAAzB;AACAmP,gBAAgB,CAAClP,KAAjB,GAAyB,EAAzB;AACAkP,gBAAgB,CAACjT,UAAjB,GAA8B,EAA9B;AACAiT,gBAAgB,CAAC/S,MAAjB,GAA0B,EAA1B;AACA+S,gBAAgB,CAACjQ,SAAjB,GAA6B,EAA7B;AACAiQ,gBAAgB,CAACvQ,UAAjB,GAA8B,EAA9B;AACAuQ,gBAAgB,CAAC7S,UAAjB,GAA8B,EAA9B;AACA6S,gBAAgB,CAACjP,aAAjB,GAAiC,EAAjC;AACAiP,gBAAgB,CAAChP,IAAjB,GAAwB,EAAxB;AACAgP,gBAAgB,CAAC/O,MAAjB,GAA0B,EAA1B;AACA+O,gBAAgB,CAAClJ,uBAAjB,GAA2C,EAA3C;AACAkJ,gBAAgB,CAAC1I,EAAjB,GAAsB,EAAtB,C;;;;;;;;;;;;;;;;;;;;;;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;IAEqB6I,Q;;;;;AACpB,oBAAYC,IAAZ,EAAkBC,OAAlB,EAA2B;AAAA;;AAAA;;AAC1B;AACA,UAAKC,KAAL,GAAa,EAAb;AACA,UAAKF,IAAL,GAAYA,IAAZ;AACA,UAAKC,OAAL,GAAeA,OAAf;AAJ0B;AAK1B;;;;WACD,eAAME,GAAN,EAAW;AACV,UAAI,KAAKF,OAAT,EAAkBG,OAAO,CAACC,GAAR,CAAYF,GAAZ;AAClB,K,CAED;;;;WACA,sBAAa9W,GAAb,EAAkB;AACjB,WAAKiX,KAAL,yBAA4BjX,GAAG,CAACkX,OAAJ,EAA5B;AACA,K,CAED;;;;WACA,qBAAYlX,GAAZ,EAAiB;AAChB,WAAKiX,KAAL,wBAA2BjX,GAAG,CAACkX,OAAJ,EAA3B;AACA,WAAKC,MAAL,GAAc,KAAKN,KAAL,CAAWO,GAAX,EAAd;AACA,WAAKH,KAAL,uBAA0B,KAAKE,MAA/B;AACA,K,CAED;;;;WACA,8BAAqBnX,GAArB,EAA0B;AACzB,WAAKiX,KAAL,iCAAoCjX,GAAG,CAACkX,OAAJ,EAApC;AACA,UAAMG,GAAG,GAAG,KAAKR,KAAL,CAAWO,GAAX,EAAZ;AACA,UAAME,EAAE,GAAG,KAAKT,KAAL,CAAWO,GAAX,EAAX;AACA,UAAMG,GAAG,GAAG,KAAKV,KAAL,CAAWO,GAAX,EAAZ;;AACA,UAAIE,EAAE,KAAK,GAAX,EAAgB;AACf,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,GAAGF,GAAtB;AACA,OAFD,MAEO,IAAIC,EAAE,KAAK,GAAX,EAAgB;AACtB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,GAAGF,GAAtB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,GAAX,EAAgB;AACtB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,GAAGF,GAAtB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,GAAX,EAAgB;AACtB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,GAAGF,GAAtB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,GAAX,EAAgB;AACtB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,GAAGF,GAAtB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,GAAX,EAAgB;AACtB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,GAAGF,GAAtB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,IAAX,EAAiB;AACvB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,IAAIF,GAAvB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,IAAX,EAAiB;AACvB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,IAAIF,GAAvB;AACA,OAFM,MAEA,IAAIC,EAAE,KAAK,IAAX,EAAiB;AACvB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,IAAIF,GAAvB;AACE,OAFI,MAEE,IAAIC,EAAE,KAAK,IAAP,IAAeA,EAAE,KAAK,IAA1B,EAAgC;AACxC,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,IAAIF,GAAvB;AACE,OAFM,MAEA,IAAIC,EAAE,KAAK,GAAX,EAAgB;AACxB,aAAKT,KAAL,CAAWW,IAAX,CAAgBD,GAAG,CAACE,QAAJ,KAAiBJ,GAAG,CAACI,QAAJ,EAAjC;AACE,OAFM,MAEA,IAAIH,EAAE,KAAK,GAAX,EAAgB;AACxB,aAAKT,KAAL,CAAWW,IAAX,CAAgBE,IAAI,CAACC,GAAL,CAASJ,GAAT,EAAcF,GAAd,CAAhB;AACE;AACH,K,CAED;;;;WACA,uBAAcrX,GAAd,EAAmB;AAClB,WAAKiX,KAAL,0BAA6BjX,GAAG,CAACkX,OAAJ,EAA7B;AACA,K,CAED;;;;WACA,sBAAalX,GAAb,EAAkB;AACjB,WAAKiX,KAAL,wBAA2BjX,GAAG,CAACkX,OAAJ,EAA3B;AACA,UAAMU,IAAI,GAAG5X,GAAG,CAACkX,OAAJ,EAAb;AACA,UAAMW,CAAC,GAAGC,eAAA,CAAgB,KAAKnB,IAArB,EAA2BiB,IAA3B,CAAV;AACA,WAAKX,KAAL,CAAWY,CAAX;AACA,WAAKhB,KAAL,CAAWW,IAAX,CAAgBK,CAAhB;AACA,K,CAED;;;;WACA,4BAAmB7X,GAAnB,EAAwB;AACvB,WAAKiX,KAAL,+BAAkCjX,GAAG,CAACkX,OAAJ,EAAlC;AACA,UAAMa,GAAG,GAAG/X,GAAG,CAACkX,OAAJ,GAAcc,OAAd,CAAsB,aAAtB,EAAqC,IAArC,EAA2CA,OAA3C,CAAmD,IAAnD,EAAyD,EAAzD,EAA6DA,OAA7D,CAAqE,MAArE,EAA6E,GAA7E,CAAZ;AACA,WAAKnB,KAAL,CAAWW,IAAX,CAAgBO,GAAhB;AACA,K,CAED;;;;WACA,0BAAiB/X,GAAjB,EAAsB;AAAA;;AACrB,WAAKiX,KAAL,6BAAgCjX,GAAG,CAACkX,OAAJ,EAAhC;AACA,UAAMe,IAAI,GAAGjY,GAAG,CAAC0L,KAAJ,CAAUwM,IAAV,CAAeC,WAAf,EAAb;;AACA,UAAIF,IAAI,KAAK,KAAb,EAAoB;AAAA;AACnB,cAAId,MAAM,GAAG,CAAb;;AACA,iBAAO,MAAI,CAACN,KAAL,CAAWuB,MAAlB,EAA0B;AACzB,gBAAMC,IAAI,GAAG,MAAI,CAACxB,KAAL,CAAWO,GAAX,EAAb;;AACA,gBAAIiB,IAAI,YAAYC,KAApB,EAA2B;AAC1BD,kBAAI,CAACE,OAAL,CAAa,UAAAC,CAAC;AAAA,uBAAIrB,MAAM,GAAGA,MAAM,GAAGqB,CAAtB;AAAA,eAAd;AACA,aAFD,MAEO;AACNrB,oBAAM,GAAGA,MAAM,GAAGkB,IAAlB;AACA;AACD;;AACD,gBAAI,CAACxB,KAAL,CAAWW,IAAX,CAAgBL,MAAhB;AAVmB;AAWnB,OAXD,MAWO,IAAIc,IAAI,KAAK,IAAb,EAAmB;AACzB,YAAMQ,OAAO,GAAG,KAAK5B,KAAL,CAAWO,GAAX,EAAhB;AACA,YAAMsB,OAAO,GAAG,KAAK7B,KAAL,CAAWO,GAAX,EAAhB;AACA,YAAMuB,SAAS,GAAG,KAAK9B,KAAL,CAAWO,GAAX,EAAlB;;AACA,YAAIuB,SAAJ,EAAe;AACd,eAAK9B,KAAL,CAAWW,IAAX,CAAgBkB,OAAhB;AACA,SAFD,MAEO;AACN,eAAK7B,KAAL,CAAWW,IAAX,CAAgBiB,OAAhB;AACA;AACD,OATM,MASA,IAAIR,IAAI,KAAK,MAAb,EAAqB;AAC3B,aAAKpB,KAAL,CAAWW,IAAX,CAAgB,IAAhB;AACA,OAFM,MAEA,IAAIS,IAAI,KAAK,OAAb,EAAsB;AAC5B,aAAKpB,KAAL,CAAWW,IAAX,CAAgB,KAAhB;AACA,OAFM,MAEA;AACN,cAAM,IAAIoB,KAAJ,mCAAqCX,IAArC,EAAN;AACA;AACD,K,CAED;;;;WACA,6BAAoBjY,GAApB,EAAyB;AACxB,WAAKiX,KAAL,gCAAmCjX,GAAG,CAACkX,OAAJ,EAAnC;AACA,K,CAED;;;;WACA,qBAAYlX,GAAZ,EAAiB;AAChB,WAAKiX,KAAL,wBAA2BjX,GAAG,CAACkX,OAAJ,EAA3B;AACA,K,CAED;;;;WACA,6BAAoBlX,GAApB,EAAyB;AACxB,WAAKiX,KAAL,gCAAmCjX,GAAG,CAACkX,OAAJ,EAAnC;AACA,UAAMG,GAAG,GAAG,KAAKR,KAAL,CAAWO,GAAX,EAAZ;AACA,UAAME,EAAE,GAAG,KAAKT,KAAL,CAAWO,GAAX,EAAX;;AACA,UAAIE,EAAE,KAAK,GAAX,EAAgB;AACf,aAAKT,KAAL,CAAWW,IAAX,CAAgB,CAAEH,GAAlB;AACA,OAFD,MAEO;AACN,aAAKR,KAAL,CAAWW,IAAX,CAAgBH,GAAhB;AACA;AACD;;;WAED,yBAAgBrX,GAAhB,EAAqB;AACpB,WAAKiX,KAAL,+BAAkCjX,GAAG,CAACkX,OAAJ,EAAlC;AACA,WAAKL,KAAL,CAAWW,IAAX,CAAgBxX,GAAG,CAACkX,OAAJ,KAAgB,CAAhC;AACA,K,CAED;;;;WACA,4BAAmBlX,GAAnB,EAAwB;AACvB,WAAKiX,KAAL,+BAAkCjX,GAAG,CAACkX,OAAJ,EAAlC;AACA,WAAKL,KAAL,CAAWW,IAAX,CAAgBxX,GAAG,CAACkX,OAAJ,KAAgB,GAAhC;AACA,K,CAED;;;;WACA,sBAAalX,GAAb,EAAkB;AACjB,WAAKiX,KAAL,yBAA4BjX,GAAG,CAACkX,OAAJ,EAA5B;AACA,WAAKL,KAAL,CAAWW,IAAX,CAAgBxX,GAAG,CAACkX,OAAJ,EAAhB;AACA,K,CAED;;;;WACA,uBAAclX,GAAd,EAAmB;AAClB,WAAKiX,KAAL,0BAA6BjX,GAAG,CAACkX,OAAJ,EAA7B;AACA,WAAKL,KAAL,CAAWW,IAAX,CAAgBxX,GAAG,CAACkX,OAAJ,EAAhB;AACA,K,CAED;;;;WACA,2BAAkBlX,GAAlB,EAAuB;AACtB,WAAKiX,KAAL,8BAAiCjX,GAAG,CAACkX,OAAJ,EAAjC;AACC,K,CAEF;;;;WACA,wBAAelX,GAAf,EAAoB;AACnB,WAAKiX,KAAL,2BAA8BjX,GAAG,CAACkX,OAAJ,EAA9B;AACA,K,CAED;;;;WACA,2BAAkBlX,GAAlB,EAAuB;AACtB,WAAKiX,KAAL,8BAAiCjX,GAAG,CAACkX,OAAJ,EAAjC;AACA,K,CAED;;;;WACA,uBAAclX,GAAd,EAAmB;AAClB,WAAKiX,KAAL,0BAA6BjX,GAAG,CAACkX,OAAJ,EAA7B;AACA,K,CAED;;;;WACA,gCAAuBlX,GAAvB,EAA4B;AAC3B,WAAKiX,KAAL,mCAAsCjX,GAAG,CAACkX,OAAJ,EAAtC;AACA,K,CAED;;;;WACA,6BAAoBlX,GAApB,EAAyB;AACxB,WAAKiX,KAAL,gCAAmCjX,GAAG,CAACkX,OAAJ,EAAnC;AACA,K,CAED;;;;WACA,6BAAoBlX,GAApB,EAAyB;AACxB,WAAKiX,KAAL,gCAAmCjX,GAAG,CAACkX,OAAJ,EAAnC;AACA,K,CAED;;;;WACA,4BAAmBlX,GAAnB,EAAwB;AACvB,WAAKiX,KAAL,+BAAkCjX,GAAG,CAACkX,OAAJ,EAAlC;AACA;;;;EAjMoCnX,mB;;;;;;;;;;;;;;;;;;;;;;;;;;ACdtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEe,SAAS8Y,QAAT,CAAkBC,IAAlB,EAAwB/W,UAAxB,EAAoCkV,KAApC,EAA2C;AACxD,MAAM8B,KAAK,GAAG,IAAI9Y,kBAAJ,CAAuB8B,UAAvB,CAAd;AACA,MAAMiX,KAAK,GAAG,IAAIC,gBAAJ,CAAYF,KAAZ,CAAd;AACAC,OAAK,CAAClY,OAAN,CAAcoY,KAAd,GAAsB,IAAtB;AACA,MAAMC,MAAM,GAAI,IAAIlZ,wBAAJ,CAA6B+Y,KAA7B,CAAhB;AACA,MAAMlL,MAAM,GAAG,IAAIsL,iBAAJ,CAAaD,MAAb,CAAf;AACArL,QAAM,CAACuL,eAAP,GAAyB,IAAzB;AAEA,MAAIC,UAAJ;;AARwD,MASlDC,kBATkD;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,aAUtD,qBAAYC,UAAZ,EAAwBC,eAAxB,EAAyCC,IAAzC,EAA+CC,MAA/C,EAAuD7C,GAAvD,EAA4D;AAC1DwC,kBAAU,kBAAWI,IAAX,mBAAwBC,MAAxB,eAAmC7C,GAAnC,CAAV;AACA,YAAIG,KAAJ,EAAWF,OAAO,CAACC,GAAR,kBAAsBsC,UAAtB;AACZ;AAbqD;;AAAA;AAAA,IASvBrZ,0BATuB;AAexD;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACE,MAAM2Z,eAAe,GAAG,IAAIL,kBAAJ,EAAxB;AACAzL,QAAM,CAAC+L,oBAAP;AACA/L,QAAM,CAACgM,gBAAP,CAAwBF,eAAxB;AAGA,MAAIG,IAAJ;;AACA,MAAI;AACFA,QAAI,GAAGjM,MAAM,CAACkM,OAAP,EAAP;AACD,GAFD,CAEE,OAAOxB,CAAP,EAAU;AACVzB,WAAO,CAACC,GAAR,CAAYwB,CAAZ;AACD;;AACD,MAAMyB,SAAS,GAAG,IAAIvD,QAAJ,CAAaoC,IAAb,EAAmB7B,KAAnB,CAAlB;AACAhX,0CAAA,CAAyCga,SAAzC,EAAoDF,IAApD;;AACA,MAAIT,UAAJ,EAAgB;AACd,QAAIW,SAAS,CAAC9C,MAAV,KAAqB1U,SAAzB,EAAoC;AAClC;AACA,aAAOwX,SAAS,CAAC9C,MAAjB;AACD;;AACD,UAAM,IAAIyB,KAAJ,CAAUU,UAAV,CAAN;AACD;;AACD,SAAOW,SAAS,CAAC9C,MAAjB;AACD,C;;;;;;;;;;AClED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,IAAMR,IAAI,GAAGuD,QAAQ,CAACC,cAAT,CAAwB,MAAxB,CAAb;AACA,IAAMpY,UAAU,GAAGmY,QAAQ,CAACC,cAAT,CAAwB,YAAxB,CAAnB;AACA,IAAMhD,MAAM,GAAG+C,QAAQ,CAACC,cAAT,CAAwB,QAAxB,CAAf;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;IACMC,K;AACJ,iBAAYC,IAAZ,EAAkBC,GAAlB,EAAuB;AAAA;;AACrB,SAAKC,KAAL,GAAaD,GAAb;AACA,SAAKD,IAAL,GAAYA,IAAZ;AACA,SAAKG,QAAL,GAAgB,KAAhB;AACA,SAAKC,QAAL,GAAgB,IAAhB;AACD;;;;WACD,mBAAU;AAAE,aAAO,KAAKF,KAAZ;AAAmB;;;WAC/B,oBAAW;AAAE,aAAO,KAAKA,KAAL,CAAW9C,QAAX,EAAP;AAA8B;;;WAC3C,kBAAS;AAAE,aAAO,KAAK8C,KAAZ;AAAmB;;;;;;AAGhC,SAASG,YAAT,CAAsB3M,MAAtB,EAA8B4M,QAA9B,EAAwCC,KAAxC,EAA+C;AAC7C,MAAIA,KAAK,YAAYtC,KAArB,EAA4B;AAC1BsC,SAAK,CAACrC,OAAN,CAAc,UAACsC,IAAD,EAAOna,KAAP,EAAiB;AAC7Bga,kBAAY,CAACE,KAAD,EAAQla,KAAR,EAAema,IAAf,CAAZ;AACD,KAFD;AAGD,GAJD,MAIO,IAAI,WAAOD,KAAP,MAAiB,QAArB,EAA+B;AACpCE,UAAM,CAACC,IAAP,CAAYH,KAAZ,EAAmBrC,OAAnB,CAA2B,UAAAyC,CAAC,EAAI;AAC9BN,kBAAY,CAACE,KAAD,EAAQI,CAAR,EAAWJ,KAAK,CAACI,CAAD,CAAhB,CAAZ;AACD,KAFD;AAGD,GAJM,MAIA;AACLjN,UAAM,CAAC4M,QAAD,CAAN,GAAmB,IAAIP,KAAJ,CAAUO,QAAV,EAAoB5M,MAAM,CAAC4M,QAAD,CAA1B,CAAnB;AACD;AACF;;AAED,SAASM,GAAT,GAAe;AACb,MAAMpa,KAAK,GAAGkB,UAAU,CAACwY,KAAzB;AAEA,MAAIzB,IAAJ;;AACA,MAAI;AACFA,QAAI,GAAGoC,IAAI,CAACC,KAAL,CAAWxE,IAAI,CAAC4D,KAAhB,CAAP;;AACA,QAAIL,QAAQ,CAACC,cAAT,CAAwB,YAAxB,EAAsCiB,OAA1C,EAAmD;AACjDV,kBAAY,CAAC,IAAD,EAAO,IAAP,EAAa5B,IAAb,CAAZ;AACD;AACF,GALD,CAKE,OAAON,CAAP,EAAU;AACVrB,UAAM,CAACoD,KAAP,GAAe/B,CAAC,CAACf,QAAF,EAAf;AACA;AACD;;AACD,MAAI;AACF,QAAM4D,CAAC,GAAGxC,QAAQ,CAACC,IAAD,EAAOjY,KAAP,EAAc,IAAd,CAAlB;;AACA,QAAIwa,CAAC,YAAYjB,KAAjB,EAAwB;AACtBjD,YAAM,CAACoD,KAAP,GAAec,CAAC,CAACd,KAAjB;AACD,KAFD,MAEO,IAAI,WAAOc,CAAP,MAAa,QAAjB,EAA2B;AAChClE,YAAM,CAACoD,KAAP,GAAeW,IAAI,CAACI,SAAL,CAAeD,CAAf,EAAkB,IAAlB,EAAwB,CAAxB,CAAf;AACD,KAFM,MAEA;AACLlE,YAAM,CAACoD,KAAP,GAAec,CAAf;AACD;AACF,GATD,CASE,OAAO7C,CAAP,EAAU;AACVrB,UAAM,CAACoD,KAAP,GAAe/B,CAAC,CAACf,QAAF,EAAf;AACD;AACF;;AAEDd,IAAI,CAAC4E,gBAAL,CAAsB,MAAtB,EAA8BN,GAA9B;AACAlZ,UAAU,CAACwZ,gBAAX,CAA4B,MAA5B,EAAoCN,GAApC;AACAA,GAAG;AAEHO,KAAK,CAAC,wBAAD,CAAL,CAAgCC,IAAhC,CAAqC,UAAAJ,CAAC,EAAI;AACxCA,GAAC,CAACnD,IAAF,GAASuD,IAAT,CAAe,UAAAC,EAAE;AAAA,WAAIxB,QAAQ,CAACC,cAAT,CAAwB,aAAxB,EAAuCwB,SAAvC,GAAmDD,EAAvD;AAAA,GAAjB;AACD,CAFD,E","file":"jsonFormula.bundle.js","sourcesContent":["/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst Lexer = require('./Lexer');\nconst {Interval} = require('./IntervalSet');\n\n// this is just to keep meaningful parameter types to Parser\nclass TokenStream {}\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\nclass BufferedTokenStream extends TokenStream {\n\tconstructor(tokenSource) {\n\n\t\tsuper();\n\t\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\t\tthis.tokenSource = tokenSource;\n\t\t/**\n\t\t * A collection of all tokens fetched from the token source. The list is\n\t\t * considered a complete view of the input once {@link //fetchedEOF} is set\n\t\t * to {@code true}.\n\t\t */\n\t\tthis.tokens = [];\n\n\t\t/**\n\t\t * The index into {@link //tokens} of the current token (next token to\n\t\t * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t\t * be\n\t\t * {@link //LT LT(1)}.\n\t\t *\n\t\t * <p>This field is set to -1 when the stream is first constructed or when\n\t\t * {@link //setTokenSource} is called, indicating that the first token has\n\t\t * not yet been fetched from the token source. For additional information,\n\t\t * see the documentation of {@link IntStream} for a description of\n\t\t * Initializing Methods.</p>\n\t\t */\n\t\tthis.index = -1;\n\n\t\t/**\n\t\t * Indicates whether the {@link Token//EOF} token has been fetched from\n\t\t * {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t\t * performance for the following cases:\n\t\t *\n\t\t * <ul>\n\t\t * <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t\t * prevent\n\t\t * consuming the EOF symbol is optimized by checking the values of\n\t\t * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t\t * //LA}.</li>\n\t\t * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t\t * into\n\t\t * {@link //tokens} is trivial with this field.</li>\n\t\t * <ul>\n\t\t */\n\t\tthis.fetchedEOF = false;\n\t}\n\n\tmark() {\n\t\treturn 0;\n\t}\n\n\trelease(marker) {\n\t\t// no resources to release\n\t}\n\n\treset() {\n\t\tthis.seek(0);\n\t}\n\n\tseek(index) {\n\t\tthis.lazyInit();\n\t\tthis.index = this.adjustSeekIndex(index);\n\t}\n\n\tget(index) {\n\t\tthis.lazyInit();\n\t\treturn this.tokens[index];\n\t}\n\n\tconsume() {\n\t\tlet skipEofCheck = false;\n\t\tif (this.index >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow \"cannot consume EOF\";\n\t\t}\n\t\tif (this.sync(this.index + 1)) {\n\t\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t\t}\n\t}\n\n\t/**\n\t * Make sure index {@code i} in tokens has a token.\n\t *\n\t * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n\t * {@code false}.\n\t * @see //get(int i)\n\t */\n\tsync(i) {\n\t\tconst n = i - this.tokens.length + 1; // how many more elements we need?\n\t\tif (n > 0) {\n\t\t\tconst fetched = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * Add {@code n} elements to buffer.\n\t *\n\t * @return {Number} The actual number of elements added to the buffer.\n\t */\n\tfetch(n) {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\t\tfor (let i = 0; i < n; i++) {\n\t\t\tconst t = this.tokenSource.nextToken();\n\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t}\n\n// Get all tokens from start..stop inclusively///\n\tgetTokens(start, stop, types) {\n\t\tif (types === undefined) {\n\t\t\ttypes = null;\n\t\t}\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tthis.lazyInit();\n\t\tconst subset = [];\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tfor (let i = start; i < stop; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (types === null || types.contains(t.type)) {\n\t\t\t\tsubset.push(t);\n\t\t\t}\n\t\t}\n\t\treturn subset;\n\t}\n\n\tLA(i) {\n\t\treturn this.LT(i).type;\n\t}\n\n\tLB(k) {\n\t\tif (this.index - k < 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.tokens[this.index - k];\n\t}\n\n\tLT(k) {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\treturn null;\n\t\t}\n\t\tif (k < 0) {\n\t\t\treturn this.LB(-k);\n\t\t}\n\t\tconst i = this.index + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) { // return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\t\treturn this.tokens[i];\n\t}\n\n\t/**\n\t * Allowed derived classes to modify the behavior of operations which change\n\t * the current stream position by adjusting the target token index of a seek\n\t * operation. The default implementation simply returns {@code i}. If an\n\t * exception is thrown in this method, the current stream index should not be\n\t * changed.\n\t *\n\t * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n\t * that\n\t * the seek target is always an on-channel token.</p>\n\t *\n\t * @param {Number} i The target token index.\n\t * @return {Number} The adjusted target token index.\n\t */\n\tadjustSeekIndex(i) {\n\t\treturn i;\n\t}\n\n\tlazyInit() {\n\t\tif (this.index === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t}\n\n\tsetup() {\n\t\tthis.sync(0);\n\t\tthis.index = this.adjustSeekIndex(0);\n\t}\n\n// Reset this token stream by setting its token source.///\n\tsetTokenSource(tokenSource) {\n\t\tthis.tokenSource = tokenSource;\n\t\tthis.tokens = [];\n\t\tthis.index = -1;\n\t\tthis.fetchedEOF = false;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the next token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and EOF.\n\t */\n\tnextTokenOnChannel(i, channel) {\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\treturn -1;\n\t\t}\n\t\tlet token = this.tokens[i];\n\t\twhile (token.channel !== this.channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ti += 1;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the previous token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and 0.\n\t */\n\tpreviousTokenOnChannel(i, channel) {\n\t\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\t\ti -= 1;\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the right of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n\t * EOF. If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToRight(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tconst from_ = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tconst to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the left of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n\t * If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToLeft(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn null;\n\t\t}\n\t\t// if none on channel to left, prevOnChannel=-1 then from=0\n\t\tconst from_ = prevOnChannel + 1;\n\t\tconst to = tokenIndex - 1;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\tfilterForChannel(left, right, channel) {\n\t\tconst hidden = [];\n\t\tfor (let i = left; i < right + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else if (t.channel === channel) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t}\n\t\tif (hidden.length === 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn hidden;\n\t}\n\n\tgetSourceName() {\n\t\treturn this.tokenSource.getSourceName();\n\t}\n\n// Get the text of all tokens in this buffer.///\n\tgetText(interval) {\n\t\tthis.lazyInit();\n\t\tthis.fill();\n\t\tif (interval === undefined || interval === null) {\n\t\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t\t}\n\t\tlet start = interval.start;\n\t\tif (start instanceof Token) {\n\t\t\tstart = start.tokenIndex;\n\t\t}\n\t\tlet stop = interval.stop;\n\t\tif (stop instanceof Token) {\n\t\t\tstop = stop.tokenIndex;\n\t\t}\n\t\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tlet s = \"\";\n\t\tfor (let i = start; i < stop + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ts = s + t.text;\n\t\t}\n\t\treturn s;\n\t}\n\n// Get all tokens from lexer until EOF///\n\tfill() {\n\t\tthis.lazyInit();\n\t\twhile (this.fetch(1000) === 1000) {\n\t\t\tcontinue;\n\t\t}\n\t}\n}\n\n\nmodule.exports = BufferedTokenStream;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst InputStream = require('./InputStream');\nconst fs = require(\"fs\");\n\n/**\n * Utility functions to create InputStreams from various sources.\n *\n * All returned InputStreams support the full range of Unicode\n * up to U+10FFFF (the default behavior of InputStream only supports\n * code points up to U+FFFF).\n */\nconst CharStreams = {\n  // Creates an InputStream from a string.\n  fromString: function(str) {\n    return new InputStream(str, true);\n  },\n\n  /**\n   * Asynchronously creates an InputStream from a blob given the\n   * encoding of the bytes in that blob (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes onLoad(result) on success, onError(error) on\n   * failure.\n   */\n  fromBlob: function(blob, encoding, onLoad, onError) {\n    const reader = new window.FileReader();\n    reader.onload = function(e) {\n      const is = new InputStream(e.target.result, true);\n      onLoad(is);\n    };\n    reader.onerror = onError;\n    reader.readAsText(blob, encoding);\n  },\n\n  /**\n   * Creates an InputStream from a Buffer given the\n   * encoding of the bytes in that buffer (defaults to 'utf8' if\n   * encoding is null).\n   */\n  fromBuffer: function(buffer, encoding) {\n    return new InputStream(buffer.toString(encoding), true);\n  },\n\n  /** Asynchronously creates an InputStream from a file on disk given\n   * the encoding of the bytes in that file (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes callback(error, result) on completion.\n   */\n  fromPath: function(path, encoding, callback) {\n    fs.readFile(path, encoding, function(err, data) {\n      let is = null;\n      if (data !== null) {\n        is = new InputStream(data, true);\n      }\n      callback(err, is);\n    });\n  },\n\n  /**\n   * Synchronously creates an InputStream given a path to a file\n   * on disk and the encoding of the bytes in that file (defaults to\n   * 'utf8' if encoding is null).\n   */\n  fromPathSync: function(path, encoding) {\n    const data = fs.readFileSync(path, encoding);\n    return new InputStream(data, true);\n  }\n};\n\nmodule.exports = CharStreams;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst CommonToken = require('./Token').CommonToken;\n\nclass TokenFactory {}\n\n/**\n * This default implementation of {@link TokenFactory} creates\n * {@link CommonToken} objects.\n */\nclass CommonTokenFactory extends TokenFactory {\n    constructor(copyText) {\n        super();\n        /**\n         * Indicates whether {@link CommonToken//setText} should be called after\n         * constructing tokens to explicitly set the text. This is useful for cases\n         * where the input stream might not be able to provide arbitrary substrings\n         * of text from the input after the lexer creates a token (e.g. the\n         * implementation of {@link CharStream//getText} in\n         * {@link UnbufferedCharStream} throws an\n         * {@link UnsupportedOperationException}). Explicitly setting the token text\n         * allows {@link Token//getText} to be called at any time regardless of the\n         * input stream implementation.\n         *\n         * <p>\n         * The default value is {@code false} to avoid the performance and memory\n         * overhead of copying text for every token unless explicitly requested.</p>\n         */\n        this.copyText = copyText===undefined ? false : copyText;\n    }\n\n    create(source, type, text, channel, start, stop, line, column) {\n        const t = new CommonToken(source, type, channel, start, stop);\n        t.line = line;\n        t.column = column;\n        if (text !==null) {\n            t.text = text;\n        } else if (this.copyText && source[1] !==null) {\n            t.text = source[1].getText(start,stop);\n        }\n        return t;\n    }\n\n    createThin(type, text) {\n        const t = new CommonToken(null, type);\n        t.text = text;\n        return t;\n    }\n}\n\n/**\n * The default {@link CommonTokenFactory} instance.\n *\n * <p>\n * This token factory does not explicitly copy token text when constructing\n * tokens.</p>\n */\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n\nmodule.exports = CommonTokenFactory;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n\nconst Token = require('./Token').Token;\nconst BufferedTokenStream = require('./BufferedTokenStream');\n\n/**\n * This class extends {@link BufferedTokenStream} with functionality to filter\n * token streams to tokens on a particular channel (tokens where\n * {@link Token//getChannel} returns a particular value).\n *\n * <p>\n * This token stream provides access to all tokens by index or when calling\n * methods like {@link //getText}. The channel filtering is only used for code\n * accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n * {@link //LB}.</p>\n *\n * <p>\n * By default, tokens are placed on the default channel\n * ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n * {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n * call {@link Lexer//setChannel}.\n * </p>\n *\n * <p>\n * Note: lexer rules which use the {@code ->skip} lexer command or call\n * {@link Lexer//skip} do not produce tokens at all, so input text matched by\n * such a rule will not be available as part of the token stream, regardless of\n * channel.</p>\n */\nclass CommonTokenStream extends BufferedTokenStream {\n    constructor(lexer, channel) {\n        super(lexer);\n        this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n    }\n\n    adjustSeekIndex(i) {\n        return this.nextTokenOnChannel(i, this.channel);\n    }\n\n    LB(k) {\n        if (k===0 || this.index-k<0) {\n            return null;\n        }\n        let i = this.index;\n        let n = 1;\n        // find k good tokens looking backwards\n        while (n <= k) {\n            // skip off-channel tokens\n            i = this.previousTokenOnChannel(i - 1, this.channel);\n            n += 1;\n        }\n        if (i < 0) {\n            return null;\n        }\n        return this.tokens[i];\n    }\n\n    LT(k) {\n        this.lazyInit();\n        if (k === 0) {\n            return null;\n        }\n        if (k < 0) {\n            return this.LB(-k);\n        }\n        let i = this.index;\n        let n = 1; // we know tokens[pos] is a good one\n        // find k good tokens\n        while (n < k) {\n            // skip off-channel tokens, but make sure to not look past EOF\n            if (this.sync(i + 1)) {\n                i = this.nextTokenOnChannel(i + 1, this.channel);\n            }\n            n += 1;\n        }\n        return this.tokens[i];\n    }\n\n    // Count EOF just once.\n    getNumberOfOnChannelTokens() {\n        let n = 0;\n        this.fill();\n        for (let i =0; i< this.tokens.length;i++) {\n            const t = this.tokens[i];\n            if( t.channel===this.channel) {\n                n += 1;\n            }\n            if( t.type===Token.EOF) {\n                break;\n            }\n        }\n        return n;\n    }\n}\n\nmodule.exports = CommonTokenStream;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst InputStream = require('./InputStream');\nconst fs = require(\"fs\");\n\n/**\n * This is an InputStream that is loaded from a file all at once\n * when you construct the object.\n */\nclass FileStream extends InputStream {\n\tconstructor(fileName, decodeToUnicodeCodePoints) {\n\t\tconst data = fs.readFileSync(fileName, \"utf8\");\n\t\tsuper(data, decodeToUnicodeCodePoints);\n\t\tthis.fileName = fileName;\n\t}\n}\n\nmodule.exports = FileStream\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nrequire('./polyfills/codepointat');\nrequire('./polyfills/fromcodepoint');\n\n/**\n * If decodeToUnicodeCodePoints is true, the input is treated\n * as a series of Unicode code points.\n *\n * Otherwise, the input is treated as a series of 16-bit UTF-16 code\n * units.\n */\nclass InputStream {\n\tconstructor(data, decodeToUnicodeCodePoints) {\n\t\tthis.name = \"<empty>\";\n\t\tthis.strdata = data;\n\t\tthis.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;\n\t\t// _loadString - Vacuum all input from a string and then treat it like a buffer.\n\t\tthis._index = 0;\n\t\tthis.data = [];\n\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\tfor (let i = 0; i < this.strdata.length; ) {\n\t\t\t\tconst codePoint = this.strdata.codePointAt(i);\n\t\t\t\tthis.data.push(codePoint);\n\t\t\t\ti += codePoint <= 0xFFFF ? 1 : 2;\n\t\t\t}\n\t\t} else {\n\t\t\tfor (let i = 0; i < this.strdata.length; i++) {\n\t\t\t\tconst codeUnit = this.strdata.charCodeAt(i);\n\t\t\t\tthis.data.push(codeUnit);\n\t\t\t}\n\t\t}\n\t\tthis._size = this.data.length;\n\t}\n\n\t/**\n\t * Reset the stream so that it's in the same state it was\n\t * when the object was created *except* the data array is not\n\t * touched.\n\t */\n\treset() {\n\t\tthis._index = 0;\n\t}\n\n\tconsume() {\n\t\tif (this._index >= this._size) {\n\t\t\t// assert this.LA(1) == Token.EOF\n\t\t\tthrow (\"cannot consume EOF\");\n\t\t}\n\t\tthis._index += 1;\n\t}\n\n\tLA(offset) {\n\t\tif (offset === 0) {\n\t\t\treturn 0; // undefined\n\t\t}\n\t\tif (offset < 0) {\n\t\t\toffset += 1; // e.g., translate LA(-1) to use offset=0\n\t\t}\n\t\tconst pos = this._index + offset - 1;\n\t\tif (pos < 0 || pos >= this._size) { // invalid\n\t\t\treturn Token.EOF;\n\t\t}\n\t\treturn this.data[pos];\n\t}\n\n\tLT(offset) {\n\t\treturn this.LA(offset);\n\t}\n\n// mark/release do nothing; we have entire buffer\n\tmark() {\n\t\treturn -1;\n\t}\n\n\trelease(marker) {\n\t}\n\n\t/**\n\t * consume() ahead until p==_index; can't just set p=_index as we must\n\t * update line and column. If we seek backwards, just set p\n\t */\n\tseek(_index) {\n\t\tif (_index <= this._index) {\n\t\t\tthis._index = _index; // just jump; don't update stream state (line,\n\t\t\t\t\t\t\t\t\t// ...)\n\t\t\treturn;\n\t\t}\n\t\t// seek forward\n\t\tthis._index = Math.min(_index, this._size);\n\t}\n\n\tgetText(start, stop) {\n\t\tif (stop >= this._size) {\n\t\t\tstop = this._size - 1;\n\t\t}\n\t\tif (start >= this._size) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\t\tlet result = \"\";\n\t\t\t\tfor (let i = start; i <= stop; i++) {\n\t\t\t\t\tresult += String.fromCodePoint(this.data[i]);\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t} else {\n\t\t\t\treturn this.strdata.slice(start, stop + 1);\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn this.strdata;\n\t}\n\n\tget index(){\n\t\treturn this._index;\n\t}\n\n\tget size(){\n\t\treturn this._size;\n\t}\n}\n\n\nmodule.exports = InputStream;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\n\n/* stop is not included! */\nclass Interval {\n\tconstructor(start, stop) {\n\t\tthis.start = start;\n\t\tthis.stop = stop;\n\t}\n\n\tcontains(item) {\n\t\treturn item >= this.start && item < this.stop;\n\t}\n\n\ttoString() {\n\t\tif(this.start===this.stop-1) {\n\t\t\treturn this.start.toString();\n\t\t} else {\n\t\t\treturn this.start.toString() + \"..\" + (this.stop-1).toString();\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.stop - this.start;\n\t}\n}\n\n\nclass IntervalSet {\n\tconstructor() {\n\t\tthis.intervals = null;\n\t\tthis.readOnly = false;\n\t}\n\n\tfirst(v) {\n\t\tif (this.intervals === null || this.intervals.length===0) {\n\t\t\treturn Token.INVALID_TYPE;\n\t\t} else {\n\t\t\treturn this.intervals[0].start;\n\t\t}\n\t}\n\n\taddOne(v) {\n\t\tthis.addInterval(new Interval(v, v + 1));\n\t}\n\n\taddRange(l, h) {\n\t\tthis.addInterval(new Interval(l, h + 1));\n\t}\n\n\taddInterval(toAdd) {\n\t\tif (this.intervals === null) {\n\t\t\tthis.intervals = [];\n\t\t\tthis.intervals.push(toAdd);\n\t\t} else {\n\t\t\t// find insert pos\n\t\t\tfor (let pos = 0; pos < this.intervals.length; pos++) {\n\t\t\t\tconst existing = this.intervals[pos];\n\t\t\t\t// distinct range -> insert\n\t\t\t\tif (toAdd.stop < existing.start) {\n\t\t\t\t\tthis.intervals.splice(pos, 0, toAdd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// contiguous range -> adjust\n\t\t\t\telse if (toAdd.stop === existing.start) {\n\t\t\t\t\tthis.intervals[pos].start = toAdd.start;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// overlapping range -> adjust and reduce\n\t\t\t\telse if (toAdd.start <= existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(Math.min(existing.start, toAdd.start), Math.max(existing.stop, toAdd.stop));\n\t\t\t\t\tthis.reduce(pos);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// greater than any existing\n\t\t\tthis.intervals.push(toAdd);\n\t\t}\n\t}\n\n\taddSet(other) {\n\t\tif (other.intervals !== null) {\n\t\t\tother.intervals.forEach( toAdd => this.addInterval(toAdd), this);\n\t\t}\n\t\treturn this;\n\t}\n\n\treduce(pos) {\n\t\t// only need to reduce if pos is not the last\n\t\tif (pos < this.intervals.length - 1) {\n\t\t\tconst current = this.intervals[pos];\n\t\t\tconst next = this.intervals[pos + 1];\n\t\t\t// if next contained in current\n\t\t\tif (current.stop >= next.stop) {\n\t\t\t\tthis.intervals.splice(pos + 1, 1);\n\t\t\t\tthis.reduce(pos);\n\t\t\t} else if (current.stop >= next.start) {\n\t\t\t\tthis.intervals[pos] = new Interval(current.start, next.stop);\n\t\t\t\tthis.intervals.splice(pos + 1, 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tcomplement(start, stop) {\n\t\tconst result = new IntervalSet();\n\t\tresult.addInterval(new Interval(start,stop+1));\n\t\tif(this.intervals !== null)\n\t\t\tthis.intervals.forEach(toRemove => result.removeRange(toRemove));\n\t\treturn result;\n\t}\n\n\tcontains(item) {\n\t\tif (this.intervals === null) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tfor (let k = 0; k < this.intervals.length; k++) {\n\t\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tremoveRange(toRemove) {\n\t\tif(toRemove.start===toRemove.stop-1) {\n\t\t\tthis.removeOne(toRemove.start);\n\t\t} else if (this.intervals !== null) {\n\t\t\tlet pos = 0;\n\t\t\tfor(let n=0; n<this.intervals.length; n++) {\n\t\t\t\tconst existing = this.intervals[pos];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (toRemove.stop<=existing.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for including range, split it\n\t\t\t\telse if(toRemove.start>existing.start && toRemove.stop<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(existing.start, toRemove.start);\n\t\t\t\t\tconst x = new Interval(toRemove.stop, existing.stop);\n\t\t\t\t\tthis.intervals.splice(pos, 0, x);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for included range, remove it\n\t\t\t\telse if(toRemove.start<=existing.start && toRemove.stop>=existing.stop) {\n\t\t\t\t\tthis.intervals.splice(pos, 1);\n\t\t\t\t\tpos = pos - 1; // need another pass\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if(toRemove.start<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(existing.start, toRemove.start);\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if(toRemove.stop<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(toRemove.stop, existing.stop);\n\t\t\t\t}\n\t\t\t\tpos += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tremoveOne(value) {\n\t\tif (this.intervals !== null) {\n\t\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\t\tconst existing = this.intervals[i];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (value < existing.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for single value range\n\t\t\t\telse if (value === existing.start && value === existing.stop - 1) {\n\t\t\t\t\tthis.intervals.splice(i, 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if (value === existing.start) {\n\t\t\t\t\tthis.intervals[i] = new Interval(existing.start + 1, existing.stop);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if (value === existing.stop - 1) {\n\t\t\t\t\tthis.intervals[i] = new Interval(existing.start, existing.stop - 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// split existing range\n\t\t\t\telse if (value < existing.stop - 1) {\n\t\t\t\t\tconst replace = new Interval(existing.start, value);\n\t\t\t\t\texisting.start = value + 1;\n\t\t\t\t\tthis.intervals.splice(i, 0, replace);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString(literalNames, symbolicNames, elemsAreChar) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\telemsAreChar = elemsAreChar || false;\n\t\tif (this.intervals === null) {\n\t\t\treturn \"{}\";\n\t\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t\t} else if(elemsAreChar) {\n\t\t\treturn this.toCharString();\n\t\t} else {\n\t\t\treturn this.toIndexString();\n\t\t}\n\t}\n\n\ttoCharString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tif(existing.stop===existing.start+1) {\n\t\t\t\tif ( existing.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(\"'\" + String.fromCharCode(existing.start) + \"'\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(existing.start) + \"'..'\" + String.fromCharCode(existing.stop-1) + \"'\");\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoIndexString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tif(existing.stop===existing.start+1) {\n\t\t\t\tif ( existing.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(existing.start.toString());\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(existing.start.toString() + \"..\" + (existing.stop-1).toString());\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoTokenString(literalNames, symbolicNames) {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tfor (let j = existing.start; j < existing.stop; j++) {\n\t\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\telementName(literalNames, symbolicNames, token) {\n\t\tif (token === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (token === Token.EPSILON) {\n\t\t\treturn \"<EPSILON>\";\n\t\t} else {\n\t\t\treturn literalNames[token] || symbolicNames[token];\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.intervals.map( interval => interval.length ).reduce((acc, val) => acc + val);\n\t}\n}\n\nmodule.exports = {\n\tInterval,\n\tIntervalSet\n};\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set, BitSet} = require('./Utils');\nconst {Token} = require('./Token');\nconst {ATNConfig} = require('./atn/ATNConfig');\nconst {IntervalSet} = require('./IntervalSet');\nconst {RuleStopState} = require('./atn/ATNState');\nconst {RuleTransition, NotSetTransition, WildcardTransition, AbstractPredicateTransition} = require('./atn/Transition');\nconst {predictionContextFromRuleContext, PredictionContext, SingletonPredictionContext} = require('./PredictionContext');\n\nclass LL1Analyzer {\n    constructor(atn) {\n        this.atn = atn;\n    }\n\n    /**\n     * Calculates the SLL(1) expected lookahead set for each outgoing transition\n     * of an {@link ATNState}. The returned array has one element for each\n     * outgoing transition in {@code s}. If the closure from transition\n     * <em>i</em> leads to a semantic predicate before matching a symbol, the\n     * element at index <em>i</em> of the result will be {@code null}.\n     *\n     * @param s the ATN state\n     * @return the expected symbols for each outgoing transition of {@code s}.\n     */\n    getDecisionLookahead(s) {\n        if (s === null) {\n            return null;\n        }\n        const count = s.transitions.length;\n        const look = [];\n        for(let alt=0; alt< count; alt++) {\n            look[alt] = new IntervalSet();\n            const lookBusy = new Set();\n            const seeThruPreds = false; // fail to get lookahead upon pred\n            this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n                  look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n            // Wipe out lookahead for this alternative if we found nothing\n            // or we had a predicate when we !seeThruPreds\n            if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n                look[alt] = null;\n            }\n        }\n        return look;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and the end of the rule containing\n     * {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n     * If {@code ctx} is not {@code null} and the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx the complete parser context, or {@code null} if the context\n     * should be ignored\n     *\n     * @return The set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     */\n    LOOK(s, stopState, ctx) {\n        const r = new IntervalSet();\n        const seeThruPreds = true; // ignore preds; get all lookahead\n        ctx = ctx || null;\n        const lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n        this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);\n        return r;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n     * rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n     * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n     * {@code true} and {@code stopState} or the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state.\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx The outer context, or {@code null} if the outer context should\n     * not be used.\n     * @param look The result lookahead set.\n     * @param lookBusy A set used for preventing epsilon closures in the ATN\n     * from causing a stack overflow. Outside code should pass\n     * {@code new Set<ATNConfig>} for this argument.\n     * @param calledRuleStack A set used for preventing left recursion in the\n     * ATN from causing a stack overflow. Outside code should pass\n     * {@code new BitSet()} for this argument.\n     * @param seeThruPreds {@code true} to true semantic predicates as\n     * implicitly {@code true} and \"see through them\", otherwise {@code false}\n     * to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n     * result if one is encountered.\n     * @param addEOF Add {@link Token//EOF} to the result if the end of the\n     * outermost context is reached. This parameter has no effect if {@code ctx}\n     * is {@code null}.\n     */\n    _LOOK(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n        const c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n        if (lookBusy.contains(c)) {\n            return;\n        }\n        lookBusy.add(c);\n        if (s === stopState) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n        }\n        if (s instanceof RuleStopState ) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n            if (ctx !== PredictionContext.EMPTY) {\n                const removed = calledRuleStack.contains(s.ruleIndex);\n                try {\n                    calledRuleStack.remove(s.ruleIndex);\n                    // run thru all possible stack tops in ctx\n                    for (let i = 0; i < ctx.length; i++) {\n                        const returnState = this.atn.states[ctx.getReturnState(i)];\n                        this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                    }\n                }finally {\n                    if (removed) {\n                        calledRuleStack.add(s.ruleIndex);\n                    }\n                }\n                return;\n            }\n        }\n        for(let j=0; j<s.transitions.length; j++) {\n            const t = s.transitions[j];\n            if (t.constructor === RuleTransition) {\n                if (calledRuleStack.contains(t.target.ruleIndex)) {\n                    continue;\n                }\n                const newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n                try {\n                    calledRuleStack.add(t.target.ruleIndex);\n                    this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } finally {\n                    calledRuleStack.remove(t.target.ruleIndex);\n                }\n            } else if (t instanceof AbstractPredicateTransition ) {\n                if (seeThruPreds) {\n                    this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } else {\n                    look.addOne(LL1Analyzer.HIT_PRED);\n                }\n            } else if( t.isEpsilon) {\n                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } else if (t.constructor === WildcardTransition) {\n                look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n            } else {\n                let set = t.label;\n                if (set !== null) {\n                    if (t instanceof NotSetTransition) {\n                        set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n                    }\n                    look.addSet(set);\n                }\n            }\n        }\n    }\n}\n\n/**\n * Special value added to the lookahead sets to indicate that we hit\n * a predicate during analysis if {@code seeThruPreds==false}.\n */\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n\nmodule.exports = LL1Analyzer;\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst Recognizer = require('./Recognizer');\nconst CommonTokenFactory = require('./CommonTokenFactory');\nconst {RecognitionException} = require('./error/Errors');\nconst {LexerNoViableAltException} = require('./error/Errors');\n\nclass TokenSource {}\n\n/**\n * A lexer is recognizer that draws input symbols from a character stream.\n * lexer grammars result in a subclass of this object. A Lexer object\n * uses simplified match() and error recovery mechanisms in the interest of speed.\n */\nclass Lexer extends Recognizer {\n\tconstructor(input) {\n\t\tsuper();\n\t\tthis._input = input;\n\t\tthis._factory = CommonTokenFactory.DEFAULT;\n\t\tthis._tokenFactorySourcePair = [ this, input ];\n\n\t\tthis._interp = null; // child classes must populate this\n\n\t\t/**\n\t\t * The goal of all lexer rules/methods is to create a token object.\n\t\t * this is an instance variable as multiple rules may collaborate to\n\t\t * create a single token. nextToken will return this object after\n\t\t * matching lexer rule(s). If you subclass to allow multiple token\n\t\t * emissions, then set this to the last token to be matched or\n\t\t * something nonnull so that the auto token emit mechanism will not\n\t\t * emit another token.\n\t\t */\n\t\tthis._token = null;\n\n\t\t/**\n\t\t * What character index in the stream did the current token start at?\n\t\t * Needed, for example, to get the text for current token. Set at\n\t\t * the start of nextToken.\n\t\t */\n\t\tthis._tokenStartCharIndex = -1;\n\n\t\t// The line on which the first character of the token resides///\n\t\tthis._tokenStartLine = -1;\n\n\t\t// The character position of first character within the line///\n\t\tthis._tokenStartColumn = -1;\n\n\t\t// Once we see EOF on char stream, next token will be EOF.\n\t\t// If you have DONE : EOF ; then you see DONE EOF.\n\t\tthis._hitEOF = false;\n\n\t\t// The channel number for the current token///\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\n\t\t// The token type for the current token///\n\t\tthis._type = Token.INVALID_TYPE;\n\n\t\tthis._modeStack = [];\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\n\t\t/**\n\t\t * You can set the text for the current token to override what is in\n\t\t * the input char buffer. Use setText() or can set this instance var.\n\t\t */\n\t\tthis._text = null;\n\t}\n\n\treset() {\n\t\t// wack Lexer state variables\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0); // rewind the input\n\t\t}\n\t\tthis._token = null;\n\t\tthis._type = Token.INVALID_TYPE;\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\tthis._tokenStartCharIndex = -1;\n\t\tthis._tokenStartColumn = -1;\n\t\tthis._tokenStartLine = -1;\n\t\tthis._text = null;\n\n\t\tthis._hitEOF = false;\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\t\tthis._modeStack = [];\n\n\t\tthis._interp.reset();\n\t}\n\n// Return a token from this source; i.e., match a token on the char stream.\n\tnextToken() {\n\t\tif (this._input === null) {\n\t\t\tthrow \"nextToken requires a non-null input stream.\";\n\t\t}\n\n\t\t/**\n\t\t * Mark start location in char stream so unbuffered streams are\n\t\t * guaranteed at least have text of current token\n\t\t */\n\t\tconst tokenStartMarker = this._input.mark();\n\t\ttry {\n\t\t\twhile (true) {\n\t\t\t\tif (this._hitEOF) {\n\t\t\t\t\tthis.emitEOF();\n\t\t\t\t\treturn this._token;\n\t\t\t\t}\n\t\t\t\tthis._token = null;\n\t\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\t\tthis._text = null;\n\t\t\t\tlet continueOuter = false;\n\t\t\t\twhile (true) {\n\t\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\t\tlet ttype = Lexer.SKIP;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\tif(e instanceof RecognitionException) {\n\t\t\t\t\t\t\tthis.notifyListeners(e); // report error\n\t\t\t\t\t\t\tthis.recover(e);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconsole.log(e.stack);\n\t\t\t\t\t\t\tthrow e;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\t\tthis._type = ttype;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (continueOuter) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (this._token === null) {\n\t\t\t\t\tthis.emit();\n\t\t\t\t}\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t} finally {\n\t\t\t// make sure we release marker after match or\n\t\t\t// unbuffered char stream will keep buffering\n\t\t\tthis._input.release(tokenStartMarker);\n\t\t}\n\t}\n\n\t/**\n\t * Instruct the lexer to skip creating a token for current lexer rule\n\t * and look for another token. nextToken() knows to keep looking when\n\t * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n\t * if token==null at end of any token rule, it creates one for you\n\t * and emits it.\n\t */\n\tskip() {\n\t\tthis._type = Lexer.SKIP;\n\t}\n\n\tmore() {\n\t\tthis._type = Lexer.MORE;\n\t}\n\n\tmode(m) {\n\t\tthis._mode = m;\n\t}\n\n\tpushMode(m) {\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"pushMode \" + m);\n\t\t}\n\t\tthis._modeStack.push(this._mode);\n\t\tthis.mode(m);\n\t}\n\n\tpopMode() {\n\t\tif (this._modeStack.length === 0) {\n\t\t\tthrow \"Empty Stack\";\n\t\t}\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t\t}\n\t\tthis.mode(this._modeStack.pop());\n\t\treturn this._mode;\n\t}\n\n\t/**\n\t * By default does not support multiple emits per nextToken invocation\n\t * for efficiency reasons. Subclass and override this method, nextToken,\n\t * and getToken (to push tokens into a list and pull from that list\n\t * rather than a single variable as this implementation does).\n\t */\n\temitToken(token) {\n\t\tthis._token = token;\n\t}\n\n\t/**\n\t * The standard method called to automatically emit a token at the\n\t * outermost lexical rule. The token object should point into the\n\t * char buffer start..stop. If there is a text override in 'text',\n\t * use that to set the token's text. Override this method to emit\n\t * custom Token objects or provide a new factory.\n\t */\n\temit() {\n\t\tconst t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn);\n\t\tthis.emitToken(t);\n\t\treturn t;\n\t}\n\n\temitEOF() {\n\t\tconst cpos = this.column;\n\t\tconst lpos = this.line;\n\t\tconst eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\t\tthis._input.index - 1, lpos, cpos);\n\t\tthis.emitToken(eof);\n\t\treturn eof;\n\t}\n\n// What is the index of the current character of lookahead?///\n\tgetCharIndex() {\n\t\treturn this._input.index;\n\t}\n\n\t/**\n\t * Return a list of all Token objects in input char stream.\n\t * Forces load of all tokens. Does not include EOF token.\n\t */\n\tgetAllTokens() {\n\t\tconst tokens = [];\n\t\tlet t = this.nextToken();\n\t\twhile (t.type !== Token.EOF) {\n\t\t\ttokens.push(t);\n\t\t\tt = this.nextToken();\n\t\t}\n\t\treturn tokens;\n\t}\n\n\tnotifyListeners(e) {\n\t\tconst start = this._tokenStartCharIndex;\n\t\tconst stop = this._input.index;\n\t\tconst text = this._input.getText(start, stop);\n\t\tconst msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\t\tconst listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn, msg, e);\n\t}\n\n\tgetErrorDisplay(s) {\n\t\tconst d = [];\n\t\tfor (let i = 0; i < s.length; i++) {\n\t\t\td.push(s[i]);\n\t\t}\n\t\treturn d.join('');\n\t}\n\n\tgetErrorDisplayForChar(c) {\n\t\tif (c.charCodeAt(0) === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (c === '\\n') {\n\t\t\treturn \"\\\\n\";\n\t\t} else if (c === '\\t') {\n\t\t\treturn \"\\\\t\";\n\t\t} else if (c === '\\r') {\n\t\t\treturn \"\\\\r\";\n\t\t} else {\n\t\t\treturn c;\n\t\t}\n\t}\n\n\tgetCharErrorDisplay(c) {\n\t\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n\t}\n\n\t/**\n\t * Lexers can normally match any char in it's vocabulary after matching\n\t * a token, so do the easy thing and just kill a character and hope\n\t * it all works out. You can instead use the rule invocation stack\n\t * to do sophisticated error recovery if you are in a fragment rule.\n\t */\n\trecover(re) {\n\t\tif (this._input.LA(1) !== Token.EOF) {\n\t\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t\t// skip a char and try again\n\t\t\t\tthis._interp.consume(this._input);\n\t\t\t} else {\n\t\t\t\t// TODO: Do we lose character or line position information?\n\t\t\t\tthis._input.consume();\n\t\t\t}\n\t\t}\n\t}\n\n\tget inputStream(){\n\t\treturn this._input;\n\t}\n\n\tset inputStream(input) {\n\t\tthis._input = null;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\tthis.reset();\n\t\tthis._input = input;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t}\n\n\tget sourceName(){\n\t\treturn this._input.sourceName;\n\t}\n\n\tget type(){\n\t\treturn this.type;\n\t}\n\n\tset type(type) {\n\t\tthis._type = type;\n\t}\n\n\tget line(){\n\t\treturn this._interp.line;\n\t}\n\n\tset line(line) {\n\t\tthis._interp.line = line;\n\t}\n\n\tget column(){\n\t\treturn this._interp.column;\n\t}\n\n\tset column(column) {\n\t\tthis._interp.column = column;\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t} else {\n\t\t\treturn this._interp.getText(this._input);\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n\n\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10FFFF;\n\n// Set the char stream and reset the lexer\n\n\nmodule.exports = Lexer;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst {ParseTreeListener, TerminalNode, ErrorNode} = require('./tree/Tree');\nconst Recognizer = require('./Recognizer');\nconst {DefaultErrorStrategy} = require('./error/ErrorStrategy');\nconst ATNDeserializer = require('./atn/ATNDeserializer');\nconst ATNDeserializationOptions = require('./atn/ATNDeserializationOptions');\nconst Lexer = require('./Lexer');\n\nclass TraceListener extends ParseTreeListener {\n\tconstructor(parser) {\n\t\tsuper();\n\t\tthis.parser = parser;\n\t}\n\n\tenterEveryRule(ctx) {\n\t\tconsole.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t}\n\n\tvisitTerminal(node) {\n\t\tconsole.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n\t}\n\n\texitEveryRule(ctx) {\n\t\tconsole.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t}\n}\n\nclass Parser extends Recognizer {\n\t/**\n\t * this is all the parsing support code essentially; most of it is error\n\t * recovery stuff.\n\t */\n\tconstructor(input) {\n\t\tsuper();\n\t\t// The input stream.\n\t\tthis._input = null;\n\t\t/**\n\t\t * The error handling strategy for the parser. The default value is a new\n\t\t * instance of {@link DefaultErrorStrategy}.\n\t\t */\n\t\tthis._errHandler = new DefaultErrorStrategy();\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\t/**\n\t\t * The {@link ParserRuleContext} object for the currently executing rule.\n\t\t * this is always non-null during the parsing process.\n\t\t */\n\t\tthis._ctx = null;\n\t\t/**\n\t\t * Specifies whether or not the parser should construct a parse tree during\n\t\t * the parsing process. The default value is {@code true}.\n\t\t */\n\t\tthis.buildParseTrees = true;\n\t\t/**\n\t\t * When {@link //setTrace}{@code (true)} is called, a reference to the\n\t\t * {@link TraceListener} is stored here so it can be easily removed in a\n\t\t * later call to {@link //setTrace}{@code (false)}. The listener itself is\n\t\t * implemented as a parser listener so this field is not directly used by\n\t\t * other parser methods.\n\t\t */\n\t\tthis._tracer = null;\n\t\t/**\n\t\t * The list of {@link ParseTreeListener} listeners registered to receive\n\t\t * events during the parse.\n\t\t */\n\t\tthis._parseListeners = null;\n\t\t/**\n\t\t * The number of syntax errors reported during parsing. this value is\n\t\t * incremented each time {@link //notifyErrorListeners} is called.\n\t\t */\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setInputStream(input);\n\t}\n\n\t// reset the parser's state\n\treset() {\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0);\n\t\t}\n\t\tthis._errHandler.reset(this);\n\t\tthis._ctx = null;\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setTrace(false);\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\tif (this._interp !== null) {\n\t\t\tthis._interp.reset();\n\t\t}\n\t}\n\n\t/**\n\t * Match current input symbol against {@code ttype}. If the symbol type\n\t * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n\t * called to complete the match process.\n\t *\n\t * <p>If the symbol type does not match,\n\t * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t * strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t * {@code true} and the token index of the symbol returned by\n\t * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t *\n\t * @param ttype the token type to match\n\t * @return the matched symbol\n\t * @throws RecognitionException if the current input symbol did not match\n\t * {@code ttype} and the error strategy could not recover from the\n\t * mismatched symbol\n\t */\n\tmatch(ttype) {\n\t\tlet t = this.getCurrentToken();\n\t\tif (t.type === ttype) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this.buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t}\n\n\t/**\n\t * Match current input symbol as a wildcard. If the symbol type matches\n\t * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n\t * and {@link //consume} are called to complete the match process.\n\t *\n\t * <p>If the symbol type does not match,\n\t * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t * strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t * {@code true} and the token index of the symbol returned by\n\t * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t *\n\t * @return the matched symbol\n\t * @throws RecognitionException if the current input symbol did not match\n\t * a wildcard and the error strategy could not recover from the mismatched\n\t * symbol\n\t */\n\tmatchWildcard() {\n\t\tlet t = this.getCurrentToken();\n\t\tif (t.type > 0) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this._buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t}\n\n\tgetParseListeners() {\n\t\treturn this._parseListeners || [];\n\t}\n\n\t/**\n\t * Registers {@code listener} to receive events during the parsing process.\n\t *\n\t * <p>To support output-preserving grammar transformations (including but not\n\t * limited to left-recursion removal, automated left-factoring, and\n\t * optimized code generation), calls to listener methods during the parse\n\t * may differ substantially from calls made by\n\t * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n\t * particular, rule entry and exit events may occur in a different order\n\t * during the parse than after the parser. In addition, calls to certain\n\t * rule entry methods may be omitted.</p>\n\t *\n\t * <p>With the following specific exceptions, calls to listener events are\n\t * <em>deterministic</em>, i.e. for identical input the calls to listener\n\t * methods will be the same.</p>\n\t *\n\t * <ul>\n\t * <li>Alterations to the grammar used to generate code may change the\n\t * behavior of the listener calls.</li>\n\t * <li>Alterations to the command line options passed to ANTLR 4 when\n\t * generating the parser may change the behavior of the listener calls.</li>\n\t * <li>Changing the version of the ANTLR Tool used to generate the parser\n\t * may change the behavior of the listener calls.</li>\n\t * </ul>\n\t *\n\t * @param listener the listener to add\n\t *\n\t * @throws NullPointerException if {@code} listener is {@code null}\n\t */\n\taddParseListener(listener) {\n\t\tif (listener === null) {\n\t\t\tthrow \"listener\";\n\t\t}\n\t\tif (this._parseListeners === null) {\n\t\t\tthis._parseListeners = [];\n\t\t}\n\t\tthis._parseListeners.push(listener);\n\t}\n\n\t/**\n\t * Remove {@code listener} from the list of parse listeners.\n\t *\n\t * <p>If {@code listener} is {@code null} or has not been added as a parse\n\t * listener, this method does nothing.</p>\n\t * @param listener the listener to remove\n\t */\n\tremoveParseListener(listener) {\n\t\tif (this._parseListeners !== null) {\n\t\t\tconst idx = this._parseListeners.indexOf(listener);\n\t\t\tif (idx >= 0) {\n\t\t\t\tthis._parseListeners.splice(idx, 1);\n\t\t\t}\n\t\t\tif (this._parseListeners.length === 0) {\n\t\t\t\tthis._parseListeners = null;\n\t\t\t}\n\t\t}\n\t}\n\n// Remove all parse listeners.\n\tremoveParseListeners() {\n\t\tthis._parseListeners = null;\n\t}\n\n// Notify any parse listeners of an enter rule event.\n\ttriggerEnterRuleEvent() {\n\t\tif (this._parseListeners !== null) {\n\t\t\tconst ctx = this._ctx;\n\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\tlistener.enterEveryRule(ctx);\n\t\t\t\tctx.enterRule(listener);\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Notify any parse listeners of an exit rule event.\n\t * @see //addParseListener\n\t */\n\ttriggerExitRuleEvent() {\n\t\tif (this._parseListeners !== null) {\n\t\t\t// reverse order walk of listeners\n\t\t\tconst ctx = this._ctx;\n\t\t\tthis._parseListeners.slice(0).reverse().map(function(listener) {\n\t\t\t\tctx.exitRule(listener);\n\t\t\t\tlistener.exitEveryRule(ctx);\n\t\t\t});\n\t\t}\n\t}\n\n\tgetTokenFactory() {\n\t\treturn this._input.tokenSource._factory;\n\t}\n\n\t// Tell our token source and error strategy about a new way to create tokens.\n\tsetTokenFactory(factory) {\n\t\tthis._input.tokenSource._factory = factory;\n\t}\n\n\t/**\n\t * The ATN with bypass alternatives is expensive to create so we create it\n\t * lazily.\n\t *\n\t * @throws UnsupportedOperationException if the current parser does not\n\t * implement the {@link //getSerializedATN()} method.\n\t */\n\tgetATNWithBypassAlts() {\n\t\tconst serializedAtn = this.getSerializedATN();\n\t\tif (serializedAtn === null) {\n\t\t\tthrow \"The current parser does not support an ATN with bypass alternatives.\";\n\t\t}\n\t\tlet result = this.bypassAltsAtnCache[serializedAtn];\n\t\tif (result === null) {\n\t\t\tconst deserializationOptions = new ATNDeserializationOptions();\n\t\t\tdeserializationOptions.generateRuleBypassTransitions = true;\n\t\t\tresult = new ATNDeserializer(deserializationOptions)\n\t\t\t\t\t.deserialize(serializedAtn);\n\t\t\tthis.bypassAltsAtnCache[serializedAtn] = result;\n\t\t}\n\t\treturn result;\n\t}\n\n\t/**\n\t * The preferred method of getting a tree pattern. For example, here's a\n\t * sample use:\n\t *\n\t * <pre>\n\t * ParseTree t = parser.expr();\n\t * ParseTreePattern p = parser.compileParseTreePattern(\"&lt;ID&gt;+0\",\n\t * MyParser.RULE_expr);\n\t * ParseTreeMatch m = p.match(t);\n\t * String id = m.get(\"ID\");\n\t * </pre>\n\t */\n\tcompileParseTreePattern(pattern, patternRuleIndex, lexer) {\n\t\tlexer = lexer || null;\n\t\tif (lexer === null) {\n\t\t\tif (this.getTokenStream() !== null) {\n\t\t\t\tconst tokenSource = this.getTokenStream().tokenSource;\n\t\t\t\tif (tokenSource instanceof Lexer) {\n\t\t\t\t\tlexer = tokenSource;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (lexer === null) {\n\t\t\tthrow \"Parser can't discover a lexer to use\";\n\t\t}\n\t\tconst m = new ParseTreePatternMatcher(lexer, this);\n\t\treturn m.compile(pattern, patternRuleIndex);\n\t}\n\n\tgetInputStream() {\n\t\treturn this.getTokenStream();\n\t}\n\n\tsetInputStream(input) {\n\t\tthis.setTokenStream(input);\n\t}\n\n\tgetTokenStream() {\n\t\treturn this._input;\n\t}\n\n\t// Set the token stream and reset the parser.\n\tsetTokenStream(input) {\n\t\tthis._input = null;\n\t\tthis.reset();\n\t\tthis._input = input;\n\t}\n\n\t/**\n\t * Match needs to return the current input symbol, which gets put\n\t * into the label for the associated token ref; e.g., x=ID.\n\t */\n\tgetCurrentToken() {\n\t\treturn this._input.LT(1);\n\t}\n\n\tnotifyErrorListeners(msg, offendingToken, err) {\n\t\toffendingToken = offendingToken || null;\n\t\terr = err || null;\n\t\tif (offendingToken === null) {\n\t\t\toffendingToken = this.getCurrentToken();\n\t\t}\n\t\tthis._syntaxErrors += 1;\n\t\tconst line = offendingToken.line;\n\t\tconst column = offendingToken.column;\n\t\tconst listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, offendingToken, line, column, msg, err);\n\t}\n\n\t/**\n\t * Consume and return the {@linkplain //getCurrentToken current symbol}.\n\t *\n\t * <p>E.g., given the following input with {@code A} being the current\n\t * lookahead symbol, this function moves the cursor to {@code B} and returns\n\t * {@code A}.</p>\n\t *\n\t * <pre>\n\t * A B\n\t * ^\n\t * </pre>\n\t *\n\t * If the parser is not in error recovery mode, the consumed symbol is added\n\t * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n\t * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n\t * If the parser <em>is</em> in error recovery mode, the consumed symbol is\n\t * added to the parse tree using\n\t * {@link ParserRuleContext//addErrorNode(Token)}, and\n\t * {@link ParseTreeListener//visitErrorNode} is called on any parse\n\t * listeners.\n\t */\n\tconsume() {\n\t\tconst o = this.getCurrentToken();\n\t\tif (o.type !== Token.EOF) {\n\t\t\tthis.getInputStream().consume();\n\t\t}\n\t\tconst hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n\t\tif (this.buildParseTrees || hasListener) {\n\t\t\tlet node;\n\t\t\tif (this._errHandler.inErrorRecoveryMode(this)) {\n\t\t\t\tnode = this._ctx.addErrorNode(o);\n\t\t\t} else {\n\t\t\t\tnode = this._ctx.addTokenNode(o);\n\t\t\t}\n\t\t\tnode.invokingState = this.state;\n\t\t\tif (hasListener) {\n\t\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\t\tif (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {\n\t\t\t\t\t\tlistener.visitErrorNode(node);\n\t\t\t\t\t} else if (node instanceof TerminalNode) {\n\t\t\t\t\t\tlistener.visitTerminal(node);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn o;\n\t}\n\n\taddContextToParseTree() {\n\t\t// add current context to parent if we have a parent\n\t\tif (this._ctx.parentCtx !== null) {\n\t\t\tthis._ctx.parentCtx.addChild(this._ctx);\n\t\t}\n\t}\n\n\t/**\n\t * Always called by generated parsers upon entry to a rule. Access field\n\t * {@link //_ctx} get the current context.\n\t */\n\tenterRule(localctx, state, ruleIndex) {\n\t\tthis.state = state;\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = this._input.LT(1);\n\t\tif (this.buildParseTrees) {\n\t\t\tthis.addContextToParseTree();\n\t\t}\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent();\n\t\t}\n\t}\n\n\texitRule() {\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\t// trigger event on _ctx, before it reverts to parent\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerExitRuleEvent();\n\t\t}\n\t\tthis.state = this._ctx.invokingState;\n\t\tthis._ctx = this._ctx.parentCtx;\n\t}\n\n\tenterOuterAlt(localctx, altNum) {\n\t\tlocalctx.setAltNumber(altNum);\n\t\t// if we have new localctx, make sure we replace existing ctx\n\t\t// that is previous child of parse tree\n\t\tif (this.buildParseTrees && this._ctx !== localctx) {\n\t\t\tif (this._ctx.parentCtx !== null) {\n\t\t\t\tthis._ctx.parentCtx.removeLastChild();\n\t\t\t\tthis._ctx.parentCtx.addChild(localctx);\n\t\t\t}\n\t\t}\n\t\tthis._ctx = localctx;\n\t}\n\n\t/**\n\t * Get the precedence level for the top-most precedence rule.\n\t *\n\t * @return The precedence level for the top-most precedence rule, or -1 if\n\t * the parser context is not nested within a precedence rule.\n\t */\n\tgetPrecedence() {\n\t\tif (this._precedenceStack.length === 0) {\n\t\t\treturn -1;\n\t\t} else {\n\t\t\treturn this._precedenceStack[this._precedenceStack.length-1];\n\t\t}\n\t}\n\n\tenterRecursionRule(localctx, state, ruleIndex, precedence) {\n\t   this.state = state;\n\t   this._precedenceStack.push(precedence);\n\t   this._ctx = localctx;\n\t   this._ctx.start = this._input.LT(1);\n\t   if (this._parseListeners !== null) {\n\t\t   this.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t   \t\t\t\t\t\t\t\t\t// left-recursive rules\n\t   }\n   }\n\n\t// Like {@link //enterRule} but for recursive rules.\n\tpushNewRecursionContext(localctx, state, ruleIndex) {\n\t\tconst previous = this._ctx;\n\t\tprevious.parentCtx = localctx;\n\t\tprevious.invokingState = state;\n\t\tprevious.stop = this._input.LT(-1);\n\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = previous.start;\n\t\tif (this.buildParseTrees) {\n\t\t\tthis._ctx.addChild(previous);\n\t\t}\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t\t}\n\t}\n\n\tunrollRecursionContexts(parentCtx) {\n\t\tthis._precedenceStack.pop();\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\tconst retCtx = this._ctx; // save current ctx (return value)\n\t\t// unroll so _ctx is as it was before call to recursive method\n\t\tif (this._parseListeners !== null) {\n\t\t\twhile (this._ctx !== parentCtx) {\n\t\t\t\tthis.triggerExitRuleEvent();\n\t\t\t\tthis._ctx = this._ctx.parentCtx;\n\t\t\t}\n\t\t} else {\n\t\t\tthis._ctx = parentCtx;\n\t\t}\n\t\t// hook into tree\n\t\tretCtx.parentCtx = parentCtx;\n\t\tif (this.buildParseTrees && parentCtx !== null) {\n\t\t\t// add return ctx into invoking rule's tree\n\t\t\tparentCtx.addChild(retCtx);\n\t\t}\n\t}\n\n\tgetInvokingContext(ruleIndex) {\n\t\tlet ctx = this._ctx;\n\t\twhile (ctx !== null) {\n\t\t\tif (ctx.ruleIndex === ruleIndex) {\n\t\t\t\treturn ctx;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\treturn null;\n\t}\n\n\tprecpred(localctx, precedence) {\n\t\treturn precedence >= this._precedenceStack[this._precedenceStack.length-1];\n\t}\n\n\tinContext(context) {\n\t\t// TODO: useful in parser?\n\t\treturn false;\n\t}\n\n\t/**\n\t * Checks whether or not {@code symbol} can follow the current state in the\n\t * ATN. The behavior of this method is equivalent to the following, but is\n\t * implemented such that the complete context-sensitive follow set does not\n\t * need to be explicitly constructed.\n\t *\n\t * <pre>\n\t * return getExpectedTokens().contains(symbol);\n\t * </pre>\n\t *\n\t * @param symbol the symbol type to check\n\t * @return {@code true} if {@code symbol} can follow the current state in\n\t * the ATN, otherwise {@code false}.\n\t */\n\tisExpectedToken(symbol) {\n\t\tconst atn = this._interp.atn;\n\t\tlet ctx = this._ctx;\n\t\tconst s = atn.states[this.state];\n\t\tlet following = atn.nextTokens(s);\n\t\tif (following.contains(symbol)) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!following.contains(Token.EPSILON)) {\n\t\t\treturn false;\n\t\t}\n\t\twhile (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t\t\tconst invokingState = atn.states[ctx.invokingState];\n\t\t\tconst rt = invokingState.transitions[0];\n\t\t\tfollowing = atn.nextTokens(rt.followState);\n\t\t\tif (following.contains(symbol)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\tif (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\t/**\n\t * Computes the set of input symbols which could follow the current parser\n\t * state and context, as given by {@link //getState} and {@link //getContext},\n\t * respectively.\n\t *\n\t * @see ATN//getExpectedTokens(int, RuleContext)\n\t */\n\tgetExpectedTokens() {\n\t\treturn this._interp.atn.getExpectedTokens(this.state, this._ctx);\n\t}\n\n\tgetExpectedTokensWithinCurrentRule() {\n\t\tconst atn = this._interp.atn;\n\t\tconst s = atn.states[this.state];\n\t\treturn atn.nextTokens(s);\n\t}\n\n\t// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.\n\tgetRuleIndex(ruleName) {\n\t\tconst ruleIndex = this.getRuleIndexMap()[ruleName];\n\t\tif (ruleIndex !== null) {\n\t\t\treturn ruleIndex;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/**\n\t * Return List&lt;String&gt; of the rule names in your parser instance\n\t * leading up to a call to the current rule. You could override if\n\t * you want more details such as the file/line info of where\n\t * in the ATN a rule is invoked.\n\t *\n\t * this is very useful for error messages.\n\t */\n\tgetRuleInvocationStack(p) {\n\t\tp = p || null;\n\t\tif (p === null) {\n\t\t\tp = this._ctx;\n\t\t}\n\t\tconst stack = [];\n\t\twhile (p !== null) {\n\t\t\t// compute what follows who invoked us\n\t\t\tconst ruleIndex = p.ruleIndex;\n\t\t\tif (ruleIndex < 0) {\n\t\t\t\tstack.push(\"n/a\");\n\t\t\t} else {\n\t\t\t\tstack.push(this.ruleNames[ruleIndex]);\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\treturn stack;\n\t}\n\n\t// For debugging and other purposes.\n\tgetDFAStrings() {\n\t\treturn this._interp.decisionToDFA.toString();\n\t}\n\n\t// For debugging and other purposes.\n\tdumpDFA() {\n\t\tlet seenOne = false;\n\t\tfor (let i = 0; i < this._interp.decisionToDFA.length; i++) {\n\t\t\tconst dfa = this._interp.decisionToDFA[i];\n\t\t\tif (dfa.states.length > 0) {\n\t\t\t\tif (seenOne) {\n\t\t\t\t\tconsole.log();\n\t\t\t\t}\n\t\t\t\tthis.printer.println(\"Decision \" + dfa.decision + \":\");\n\t\t\t\tthis.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n\t\t\t\tseenOne = true;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t\t\"\t\t\tprinter = function() {\\r\\n\" +\n\t\t\"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n\t\t\"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n\t\t\"\t\t\t};\\r\\n\" +\n\t\t*/\n\tgetSourceName() {\n\t\treturn this._input.sourceName;\n\t}\n\n\t/**\n\t * During a parse is sometimes useful to listen in on the rule entry and exit\n\t * events as well as token matches. this is for quick and dirty debugging.\n\t */\n\tsetTrace(trace) {\n\t\tif (!trace) {\n\t\t\tthis.removeParseListener(this._tracer);\n\t\t\tthis._tracer = null;\n\t\t} else {\n\t\t\tif (this._tracer !== null) {\n\t\t\t\tthis.removeParseListener(this._tracer);\n\t\t\t}\n\t\t\tthis._tracer = new TraceListener(this);\n\t\t\tthis.addParseListener(this._tracer);\n\t\t}\n\t}\n}\n\n/**\n * this field maps from the serialized ATN string to the deserialized {@link\n * ATN} with\n * bypass alternatives.\n *\n * @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n */\nParser.bypassAltsAtnCache = {};\n\nmodule.exports = Parser;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst RuleContext = require('./RuleContext');\nconst Tree = require('./tree/Tree');\nconst INVALID_INTERVAL = Tree.INVALID_INTERVAL;\nconst TerminalNode = Tree.TerminalNode;\nconst TerminalNodeImpl = Tree.TerminalNodeImpl;\nconst ErrorNodeImpl = Tree.ErrorNodeImpl;\nconst Interval = require(\"./IntervalSet\").Interval;\n\n/**\n * A rule invocation record for parsing.\n *\n *  Contains all of the information about the current rule not stored in the\n *  RuleContext. It handles parse tree children list, Any ATN state\n *  tracing, and the default values available for rule indications:\n *  start, stop, rule index, current alt number, current\n *  ATN state.\n *\n *  Subclasses made for each rule and grammar track the parameters,\n *  return values, locals, and labels specific to that rule. These\n *  are the objects that are returned from rules.\n *\n *  Note text is not an actual field of a rule return value; it is computed\n *  from start and stop using the input stream's toString() method.  I\n *  could add a ctor to this so that we can pass in and store the input\n *  stream, but I'm not sure we want to do that.  It would seem to be undefined\n *  to get the .text property anyway if the rule matches tokens from multiple\n *  input streams.\n *\n *  I do not use getters for fields of objects that are used simply to\n *  group values such as this aggregate.  The getters/setters are there to\n *  satisfy the superclass interface.\n */\nclass ParserRuleContext extends RuleContext {\n\tconstructor(parent, invokingStateNumber) {\n\t\tparent = parent || null;\n\t\tinvokingStateNumber = invokingStateNumber || null;\n\t\tsuper(parent, invokingStateNumber);\n\t\tthis.ruleIndex = -1;\n\t\t/**\n\t\t * If we are debugging or building a parse tree for a visitor,\n\t\t * we need to track all of the tokens and rule invocations associated\n\t\t * with this rule's context. This is empty for parsing w/o tree constr.\n\t\t * operation because we don't the need to track the details about\n\t\t * how we parse this rule.\n\t\t */\n\t\tthis.children = null;\n\t\tthis.start = null;\n\t\tthis.stop = null;\n\t\t/**\n\t\t * The exception that forced this rule to return. If the rule successfully\n\t\t * completed, this is {@code null}.\n\t\t */\n\t\tthis.exception = null;\n\t}\n\n\t// COPY a ctx (I'm deliberately not using copy constructor)\n\tcopyFrom(ctx) {\n\t\t// from RuleContext\n\t\tthis.parentCtx = ctx.parentCtx;\n\t\tthis.invokingState = ctx.invokingState;\n\t\tthis.children = null;\n\t\tthis.start = ctx.start;\n\t\tthis.stop = ctx.stop;\n\t\t// copy any error nodes to alt label node\n\t\tif(ctx.children) {\n\t\t\tthis.children = [];\n\t\t\t// reset parent pointer for any error nodes\n\t\t\tctx.children.map(function(child) {\n\t\t\t\tif (child instanceof ErrorNodeImpl) {\n\t\t\t\t\tthis.children.push(child);\n\t\t\t\t\tchild.parentCtx = this;\n\t\t\t\t}\n\t\t\t}, this);\n\t\t}\n\t}\n\n\t// Double dispatch methods for listeners\n\tenterRule(listener) {\n\t}\n\n\texitRule(listener) {\n\t}\n\n\t// Does not set parent link; other add methods do that\n\taddChild(child) {\n\t\tif (this.children === null) {\n\t\t\tthis.children = [];\n\t\t}\n\t\tthis.children.push(child);\n\t\treturn child;\n\t}\n\n\t/** Used by enterOuterAlt to toss out a RuleContext previously added as\n\t * we entered a rule. If we have // label, we will need to remove\n\t * generic ruleContext object.\n\t */\n\tremoveLastChild() {\n\t\tif (this.children !== null) {\n\t\t\tthis.children.pop();\n\t\t}\n\t}\n\n\taddTokenNode(token) {\n\t\tconst node = new TerminalNodeImpl(token);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\taddErrorNode(badToken) {\n\t\tconst node = new ErrorNodeImpl(badToken);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\tgetChild(i, type) {\n\t\ttype = type || null;\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tif (type === null) {\n\t\t\treturn this.children[i];\n\t\t} else {\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif(child instanceof type) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tgetToken(ttype, i) {\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\tconst child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n\n\tgetTokens(ttype ) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst tokens = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\t\ttokens.push(child);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn tokens;\n\t\t}\n\t}\n\n\tgetTypedRuleContext(ctxType, i) {\n\t\treturn this.getChild(i, ctxType);\n\t}\n\n\tgetTypedRuleContexts(ctxType) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst contexts = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof ctxType) {\n\t\t\t\t\tcontexts.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn contexts;\n\t\t}\n\t}\n\n\tgetChildCount() {\n\t\tif (this.children=== null) {\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn this.children.length;\n\t\t}\n\t}\n\n\tgetSourceInterval() {\n\t\tif( this.start === null || this.stop === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t} else {\n\t\t\treturn new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n\t\t}\n\t}\n}\n\nRuleContext.EMPTY = new ParserRuleContext();\n\nclass InterpreterRuleContext extends ParserRuleContext {\n\tconstructor(parent, invokingStateNumber, ruleIndex) {\n\t\tsuper(parent, invokingStateNumber);\n\t\tthis.ruleIndex = ruleIndex;\n\t}\n}\n\nmodule.exports = ParserRuleContext;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst RuleContext = require('./RuleContext');\nconst {Hash, Map, equalArrays} = require('./Utils');\n\nclass PredictionContext {\n\n\tconstructor(cachedHashCode) {\n\t\tthis.cachedHashCode = cachedHashCode;\n\t}\n\n\t/**\n\t * Stores the computed hash code of this {@link PredictionContext}. The hash\n\t * code is computed in parts to match the following reference algorithm.\n\t *\n\t * <pre>\n\t * private int referenceHashCode() {\n\t * int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n\t * //INITIAL_HASH});\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n\t * getParent}(i));\n\t * }\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n\t * //getReturnState getReturnState}(i));\n\t * }\n\t *\n\t * hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n\t * //size()});\n\t * return hash;\n\t * }\n\t * </pre>\n\t * This means only the {@link //EMPTY} context is in set.\n\t */\n\tisEmpty() {\n\t\treturn this === PredictionContext.EMPTY;\n\t}\n\n\thasEmptyPath() {\n\t\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n}\n\n/**\n * Represents {@code $} in local context prediction, which means wildcard.\n * {@code//+x =//}.\n */\nPredictionContext.EMPTY = null;\n\n/**\n * Represents {@code $} in an array in full context mode, when {@code $}\n * doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n * {@code $} = {@link //EMPTY_RETURN_STATE}.\n */\nPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\n\n\n/*\nfunction calculateHashString(parent, returnState) {\n\treturn \"\" + parent + returnState;\n}\n*/\n\n/**\n * Used to cache {@link PredictionContext} objects. Its used for the shared\n * context cash associated with contexts in DFA states. This cache\n * can be used for both lexers and parsers.\n */\nclass PredictionContextCache {\n\n\tconstructor() {\n\t\tthis.cache = new Map();\n\t}\n\n\t/**\n\t * Add a context to the cache and return it. If the context already exists,\n\t * return that one instead and do not add a new context to the cache.\n\t * Protect shared cache from unsafe thread access.\n\t */\n\tadd(ctx) {\n\t\tif (ctx === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY;\n\t\t}\n\t\tconst existing = this.cache.get(ctx) || null;\n\t\tif (existing !== null) {\n\t\t\treturn existing;\n\t\t}\n\t\tthis.cache.put(ctx, ctx);\n\t\treturn ctx;\n\t}\n\n\tget(ctx) {\n\t\treturn this.cache.get(ctx) || null;\n\t}\n\n\tget length(){\n\t\treturn this.cache.length;\n\t}\n}\n\n\nclass SingletonPredictionContext extends PredictionContext {\n\n\tconstructor(parent, returnState) {\n\t\tlet hashCode = 0;\n\t\tconst hash = new Hash();\n\t\tif(parent !== null) {\n\t\t\thash.update(parent, returnState);\n\t\t} else {\n\t\t\thash.update(1);\n\t\t}\n\t\thashCode = hash.finish();\n\t\tsuper(hashCode);\n\t\tthis.parentCtx = parent;\n\t\tthis.returnState = returnState;\n\t}\n\n\tgetParent(index) {\n\t\treturn this.parentCtx;\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnState;\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof SingletonPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashCode() !== other.hashCode()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\tif(this.returnState !== other.returnState)\n\t\t\t\treturn false;\n\t\t\telse if(this.parentCtx==null)\n\t\t\t\treturn other.parentCtx==null\n\t\t\telse\n\t\t\t\treturn this.parentCtx.equals(other.parentCtx);\n\t\t}\n\t}\n\n\ttoString() {\n\t\tconst up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n\t\tif (up.length === 0) {\n\t\t\tif (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\treturn \"$\";\n\t\t\t} else {\n\t\t\t\treturn \"\" + this.returnState;\n\t\t\t}\n\t\t} else {\n\t\t\treturn \"\" + this.returnState + \" \" + up;\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn 1;\n\t}\n\n\tstatic create(parent, returnState) {\n\t\tif (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n\t\t\t// someone can pass in the bits of an array ctx that mean $\n\t\t\treturn PredictionContext.EMPTY;\n\t\t} else {\n\t\t\treturn new SingletonPredictionContext(parent, returnState);\n\t\t}\n\t}\n}\n\nclass EmptyPredictionContext extends SingletonPredictionContext {\n\n\tconstructor() {\n\t\tsuper(null, PredictionContext.EMPTY_RETURN_STATE);\n\t}\n\n\tisEmpty() {\n\t\treturn true;\n\t}\n\n\tgetParent(index) {\n\t\treturn null;\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnState;\n\t}\n\n\tequals(other) {\n\t\treturn this === other;\n\t}\n\n\ttoString() {\n\t\treturn \"$\";\n\t}\n}\n\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n\nclass ArrayPredictionContext extends PredictionContext {\n\n\tconstructor(parents, returnStates) {\n\t\t/**\n\t\t * Parent can be null only if full ctx mode and we make an array\n\t\t * from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n\t\t * null parent and\n\t\t * returnState == {@link //EMPTY_RETURN_STATE}.\n\t\t */\n\t\tconst h = new Hash();\n\t\th.update(parents, returnStates);\n\t\tconst hashCode = h.finish();\n\t\tsuper(hashCode);\n\t\tthis.parents = parents;\n\t\tthis.returnStates = returnStates;\n\t\treturn this;\n\t}\n\n\tisEmpty() {\n\t\t// since EMPTY_RETURN_STATE can only appear in the last position, we\n\t\t// don't need to verify that size==1\n\t\treturn this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\tgetParent(index) {\n\t\treturn this.parents[index];\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnStates[index];\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof ArrayPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashCode() !== other.hashCode()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\treturn equalArrays(this.returnStates, other.returnStates) &&\n\t\t\t\tequalArrays(this.parents, other.parents);\n\t\t}\n\t}\n\n\ttoString() {\n\t\tif (this.isEmpty()) {\n\t\t\treturn \"[]\";\n\t\t} else {\n\t\t\tlet s = \"[\";\n\t\t\tfor (let i = 0; i < this.returnStates.length; i++) {\n\t\t\t\tif (i > 0) {\n\t\t\t\t\ts = s + \", \";\n\t\t\t\t}\n\t\t\t\tif (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\ts = s + \"$\";\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\ts = s + this.returnStates[i];\n\t\t\t\tif (this.parents[i] !== null) {\n\t\t\t\t\ts = s + \" \" + this.parents[i];\n\t\t\t\t} else {\n\t\t\t\t\ts = s + \"null\";\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn s + \"]\";\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.returnStates.length;\n\t}\n}\n\n\n/**\n * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n * Return {@link //EMPTY} if {@code outerContext} is empty or null.\n */\nfunction predictionContextFromRuleContext(atn, outerContext) {\n\tif (outerContext === undefined || outerContext === null) {\n\t\touterContext = RuleContext.EMPTY;\n\t}\n\t// if we are in RuleContext of start rule, s, then PredictionContext\n\t// is EMPTY. Nobody called us. (if we are empty, return empty)\n\tif (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\t// If we have a parent, convert it to a PredictionContext graph\n\tconst parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n\tconst state = atn.states[outerContext.invokingState];\n\tconst transition = state.transitions[0];\n\treturn SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n/*\nfunction calculateListsHashString(parents, returnStates) {\n\tconst s = \"\";\n\tparents.map(function(p) {\n\t\ts = s + p;\n\t});\n\treturnStates.map(function(r) {\n\t\ts = s + r;\n\t});\n\treturn s;\n}\n*/\nfunction merge(a, b, rootIsWildcard, mergeCache) {\n\t// share same graph if both same\n\tif (a === b) {\n\t\treturn a;\n\t}\n\tif (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\treturn mergeSingletons(a, b, rootIsWildcard, mergeCache);\n\t}\n\t// At least one of a or b is array\n\t// If one is $ and rootIsWildcard, return $ as// wildcard\n\tif (rootIsWildcard) {\n\t\tif (a instanceof EmptyPredictionContext) {\n\t\t\treturn a;\n\t\t}\n\t\tif (b instanceof EmptyPredictionContext) {\n\t\t\treturn b;\n\t\t}\n\t}\n\t// convert singleton so both are arrays to normalize\n\tif (a instanceof SingletonPredictionContext) {\n\t\ta = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n\t}\n\tif (b instanceof SingletonPredictionContext) {\n\t\tb = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n\t}\n\treturn mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n/**\n * Merge two {@link SingletonPredictionContext} instances.\n *\n * <p>Stack tops equal, parents merge is same; return left graph.<br>\n * <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Same stack top, parents differ; merge parents giving array node, then\n * remainders of those graphs. A new root node is created to point to the\n * merged parents.<br>\n * <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to same parent. Make array node for the\n * root where both element in the root point to the same (original)\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to different parents. Make array node for\n * the root where each element points to the corresponding original\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n * @param mergeCache\n */\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tlet previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\n\tconst rootMerge = mergeRoot(a, b, rootIsWildcard);\n\tif (rootMerge !== null) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, rootMerge);\n\t\t}\n\t\treturn rootMerge;\n\t}\n\tif (a.returnState === b.returnState) {\n\t\tconst parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n\t\t// if parent is same as existing a or b parent or reduced to a parent,\n\t\t// return it\n\t\tif (parent === a.parentCtx) {\n\t\t\treturn a; // ax + bx = ax, if a=b\n\t\t}\n\t\tif (parent === b.parentCtx) {\n\t\t\treturn b; // ax + bx = bx, if a=b\n\t\t}\n\t\t// else: ax + ay = a'[x,y]\n\t\t// merge parents x and y, giving array node with x,y then remainders\n\t\t// of those graphs. dup a, a' points at merged array\n\t\t// new joined parent so create new singleton pointing to it, a'\n\t\tconst spc = SingletonPredictionContext.create(parent, a.returnState);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, spc);\n\t\t}\n\t\treturn spc;\n\t} else { // a != b payloads differ\n\t\t// see if we can collapse parents due to $+x parents if local ctx\n\t\tlet singleParent = null;\n\t\tif (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// bx =\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// [a,b]x\n\t\t\tsingleParent = a.parentCtx;\n\t\t}\n\t\tif (singleParent !== null) { // parents are same\n\t\t\t// sort payloads and use same parent\n\t\t\tconst payloads = [ a.returnState, b.returnState ];\n\t\t\tif (a.returnState > b.returnState) {\n\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t}\n\t\t\tconst parents = [ singleParent, singleParent ];\n\t\t\tconst apc = new ArrayPredictionContext(parents, payloads);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, apc);\n\t\t\t}\n\t\t\treturn apc;\n\t\t}\n\t\t// parents differ and can't merge them. Just pack together\n\t\t// into array; can't merge.\n\t\t// ax + by = [ax,by]\n\t\tconst payloads = [ a.returnState, b.returnState ];\n\t\tlet parents = [ a.parentCtx, b.parentCtx ];\n\t\tif (a.returnState > b.returnState) { // sort by payload\n\t\t\tpayloads[0] = b.returnState;\n\t\t\tpayloads[1] = a.returnState;\n\t\t\tparents = [ b.parentCtx, a.parentCtx ];\n\t\t}\n\t\tconst a_ = new ArrayPredictionContext(parents, payloads);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a_);\n\t\t}\n\t\treturn a_;\n\t}\n}\n\n/**\n * Handle case where at least one of {@code a} or {@code b} is\n * {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n * to represent {@link //EMPTY}.\n *\n * <h2>Local-Context Merges</h2>\n *\n * <p>These local-context merge operations are used when {@code rootIsWildcard}\n * is true.</p>\n *\n * <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n * <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n * {@code //EMPTY}; return left graph.<br>\n * <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Special case of last merge if local context.<br>\n * <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <h2>Full-Context Merges</h2>\n *\n * <p>These full-context merge operations are used when {@code rootIsWildcard}\n * is false.</p>\n *\n * <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n * null parent).<br>\n * <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n */\nfunction mergeRoot(a, b, rootIsWildcard) {\n\tif (rootIsWildcard) {\n\t\tif (a === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // // + b =//\n\t\t}\n\t\tif (b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // a +// =//\n\t\t}\n\t} else {\n\t\tif (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // $ + $ = $\n\t\t} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n\t\t\tconst payloads = [ b.returnState,\n\t\t\t\t\tPredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tconst parents = [ b.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n\t\t\tconst payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tconst parents = [ a.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t}\n\t}\n\treturn null;\n}\n\n/**\n * Merge two {@link ArrayPredictionContext} instances.\n *\n * <p>Different tops, different parents.<br>\n * <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, same parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, different parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, all shared parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Equal tops, merge parents and reduce top to\n * {@link SingletonPredictionContext}.<br>\n * <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n */\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tlet previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\t// merge sorted payloads a + b => M\n\tlet i = 0; // walks a\n\tlet j = 0; // walks b\n\tlet k = 0; // walks target M array\n\n\tlet mergedReturnStates = [];\n\tlet mergedParents = [];\n\t// walk and merge to yield mergedParents, mergedReturnStates\n\twhile (i < a.returnStates.length && j < b.returnStates.length) {\n\t\tconst a_parent = a.parents[i];\n\t\tconst b_parent = b.parents[j];\n\t\tif (a.returnStates[i] === b.returnStates[j]) {\n\t\t\t// same payload (stack tops are equal), must yield merged singleton\n\t\t\tconst payload = a.returnStates[i];\n\t\t\t// $+$ = $\n\t\t\tconst bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n\t\t\t\t\ta_parent === null && b_parent === null;\n\t\t\tconst ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ax\n\t\t\tif (bothDollars || ax_ax) {\n\t\t\t\tmergedParents[k] = a_parent; // choose left\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t} else { // ax+ay -> a'[x,y]\n\t\t\t\tmergedParents[k] = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t}\n\t\t\ti += 1; // hop over left one as usual\n\t\t\tj += 1; // but also skip one in right side since we merge\n\t\t} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n\t\t\tmergedParents[k] = a_parent;\n\t\t\tmergedReturnStates[k] = a.returnStates[i];\n\t\t\ti += 1;\n\t\t} else { // b > a, copy b[j] to M\n\t\t\tmergedParents[k] = b_parent;\n\t\t\tmergedReturnStates[k] = b.returnStates[j];\n\t\t\tj += 1;\n\t\t}\n\t\tk += 1;\n\t}\n\t// copy over any payloads remaining in either array\n\tif (i < a.returnStates.length) {\n\t\tfor (let p = i; p < a.returnStates.length; p++) {\n\t\t\tmergedParents[k] = a.parents[p];\n\t\t\tmergedReturnStates[k] = a.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t} else {\n\t\tfor (let p = j; p < b.returnStates.length; p++) {\n\t\t\tmergedParents[k] = b.parents[p];\n\t\t\tmergedReturnStates[k] = b.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t}\n\t// trim merged if we combined a few that had same stack tops\n\tif (k < mergedParents.length) { // write index < last position; trim\n\t\tif (k === 1) { // for just one merged element, return singleton top\n\t\t\tconst a_ = SingletonPredictionContext.create(mergedParents[0],\n\t\t\t\t\tmergedReturnStates[0]);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t}\n\t\t\treturn a_;\n\t\t}\n\t\tmergedParents = mergedParents.slice(0, k);\n\t\tmergedReturnStates = mergedReturnStates.slice(0, k);\n\t}\n\n\tconst M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n\t// if we created same array as a or b, return that instead\n\t// TODO: track whether this is possible above during merge sort for speed\n\tif (M === a) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a);\n\t\t}\n\t\treturn a;\n\t}\n\tif (M === b) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, b);\n\t\t}\n\t\treturn b;\n\t}\n\tcombineCommonParents(mergedParents);\n\n\tif (mergeCache !== null) {\n\t\tmergeCache.set(a, b, M);\n\t}\n\treturn M;\n}\n\n/**\n * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n * ones.\n */\nfunction combineCommonParents(parents) {\n\tconst uniqueParents = new Map();\n\n\tfor (let p = 0; p < parents.length; p++) {\n\t\tconst parent = parents[p];\n\t\tif (!(uniqueParents.containsKey(parent))) {\n\t\t\tuniqueParents.put(parent, parent);\n\t\t}\n\t}\n\tfor (let q = 0; q < parents.length; q++) {\n\t\tparents[q] = uniqueParents.get(parents[q]);\n\t}\n}\n\nfunction getCachedPredictionContext(context, contextCache, visited) {\n\tif (context.isEmpty()) {\n\t\treturn context;\n\t}\n\tlet existing = visited.get(context) || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\texisting = contextCache.get(context);\n\tif (existing !== null) {\n\t\tvisited.put(context, existing);\n\t\treturn existing;\n\t}\n\tlet changed = false;\n\tlet parents = [];\n\tfor (let i = 0; i < parents.length; i++) {\n\t\tconst parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n\t\tif (changed || parent !== context.getParent(i)) {\n\t\t\tif (!changed) {\n\t\t\t\tparents = [];\n\t\t\t\tfor (let j = 0; j < context.length; j++) {\n\t\t\t\t\tparents[j] = context.getParent(j);\n\t\t\t\t}\n\t\t\t\tchanged = true;\n\t\t\t}\n\t\t\tparents[i] = parent;\n\t\t}\n\t}\n\tif (!changed) {\n\t\tcontextCache.add(context);\n\t\tvisited.put(context, context);\n\t\treturn context;\n\t}\n\tlet updated = null;\n\tif (parents.length === 0) {\n\t\tupdated = PredictionContext.EMPTY;\n\t} else if (parents.length === 1) {\n\t\tupdated = SingletonPredictionContext.create(parents[0], context\n\t\t\t\t.getReturnState(0));\n\t} else {\n\t\tupdated = new ArrayPredictionContext(parents, context.returnStates);\n\t}\n\tcontextCache.add(updated);\n\tvisited.put(updated, updated);\n\tvisited.put(context, updated);\n\n\treturn updated;\n}\n\n// ter's recursive version of Sam's getAllNodes()\nfunction getAllContextNodes(context, nodes, visited) {\n\tif (nodes === null) {\n\t\tnodes = [];\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else if (visited === null) {\n\t\tvisited = new Map();\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else {\n\t\tif (context === null || visited.containsKey(context)) {\n\t\t\treturn nodes;\n\t\t}\n\t\tvisited.put(context, context);\n\t\tnodes.push(context);\n\t\tfor (let i = 0; i < context.length; i++) {\n\t\t\tgetAllContextNodes(context.getParent(i), nodes, visited);\n\t\t}\n\t\treturn nodes;\n\t}\n}\n\nmodule.exports = {\n\tmerge,\n\tPredictionContext,\n\tPredictionContextCache,\n\tSingletonPredictionContext,\n\tpredictionContextFromRuleContext,\n\tgetCachedPredictionContext\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst {ConsoleErrorListener} = require('./error/ErrorListener');\nconst {ProxyErrorListener} = require('./error/ErrorListener');\n\nclass Recognizer {\n    constructor() {\n        this._listeners = [ ConsoleErrorListener.INSTANCE ];\n        this._interp = null;\n        this._stateNumber = -1;\n    }\n\n    checkVersion(toolVersion) {\n        const runtimeVersion = \"4.9.2\";\n        if (runtimeVersion!==toolVersion) {\n            console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n        }\n    }\n\n    addErrorListener(listener) {\n        this._listeners.push(listener);\n    }\n\n    removeErrorListeners() {\n        this._listeners = [];\n    }\n\n    getTokenTypeMap() {\n        const tokenNames = this.getTokenNames();\n        if (tokenNames===null) {\n            throw(\"The current recognizer does not provide a list of token names.\");\n        }\n        let result = this.tokenTypeMapCache[tokenNames];\n        if(result===undefined) {\n            result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n            result.EOF = Token.EOF;\n            this.tokenTypeMapCache[tokenNames] = result;\n        }\n        return result;\n    }\n\n    /**\n     * Get a map from rule names to rule indexes.\n     * <p>Used for XPath and tree pattern compilation.</p>\n     */\n    getRuleIndexMap() {\n        const ruleNames = this.ruleNames;\n        if (ruleNames===null) {\n            throw(\"The current recognizer does not provide a list of rule names.\");\n        }\n        let result = this.ruleIndexMapCache[ruleNames]; // todo: should it be Recognizer.ruleIndexMapCache ?\n        if(result===undefined) {\n            result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n            this.ruleIndexMapCache[ruleNames] = result;\n        }\n        return result;\n    }\n\n    getTokenType(tokenName) {\n        const ttype = this.getTokenTypeMap()[tokenName];\n        if (ttype !==undefined) {\n            return ttype;\n        } else {\n            return Token.INVALID_TYPE;\n        }\n    }\n\n    // What is the error header, normally line/character position information?\n    getErrorHeader(e) {\n        const line = e.getOffendingToken().line;\n        const column = e.getOffendingToken().column;\n        return \"line \" + line + \":\" + column;\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out.  Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     *\n     * @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n     * implementations of {@link ANTLRErrorStrategy} may provide a similar\n     * feature when necessary. For example, see\n     * {@link DefaultErrorStrategy//getTokenErrorDisplay}.*/\n    getTokenErrorDisplay(t) {\n        if (t===null) {\n            return \"<no token>\";\n        }\n        let s = t.text;\n        if (s===null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    getErrorListenerDispatch() {\n        return new ProxyErrorListener(this._listeners);\n    }\n\n    /**\n     * subclass needs to override these if there are sempreds or actions\n     * that the ATN interp needs to execute\n     */\n    sempred(localctx, ruleIndex, actionIndex) {\n        return true;\n    }\n\n    precpred(localctx , precedence) {\n        return true;\n    }\n\n    get state(){\n        return this._stateNumber;\n    }\n\n    set state(state) {\n        this._stateNumber = state;\n    }\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n\nmodule.exports = Recognizer;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {RuleNode} = require('./tree/Tree');\nconst {INVALID_INTERVAL} = require('./tree/Tree');\nconst Trees = require('./tree/Trees');\n\nclass RuleContext extends RuleNode {\n\t/** A rule context is a record of a single rule invocation. It knows\n\t * which context invoked it, if any. If there is no parent context, then\n\t * naturally the invoking state is not valid.  The parent link\n\t * provides a chain upwards from the current rule invocation to the root\n\t * of the invocation tree, forming a stack. We actually carry no\n\t * information about the rule associated with this context (except\n\t * when parsing). We keep only the state number of the invoking state from\n\t * the ATN submachine that invoked this. Contrast this with the s\n\t * pointer inside ParserRuleContext that tracks the current state\n\t * being \"executed\" for the current rule.\n\t *\n\t * The parent contexts are useful for computing lookahead sets and\n\t * getting error information.\n\t *\n\t * These objects are used during parsing and prediction.\n\t * For the special case of parsers, we use the subclass\n\t * ParserRuleContext.\n\t *\n\t * @see ParserRuleContext\n\t */\n\tconstructor(parent, invokingState) {\n\t\t// What context invoked this rule?\n\t\tsuper();\n\t\tthis.parentCtx = parent || null;\n\t\t/**\n\t\t * What state invoked the rule associated with this context?\n\t\t * The \"return address\" is the followState of invokingState\n\t\t * If parent is null, this should be -1.\n\t\t */\n\t\tthis.invokingState = invokingState || -1;\n\t}\n\n\tdepth() {\n\t\tlet n = 0;\n\t\tlet p = this;\n\t\twhile (p !== null) {\n\t\t\tp = p.parentCtx;\n\t\t\tn += 1;\n\t\t}\n\t\treturn n;\n\t}\n\n\t/**\n\t * A context is empty if there is no invoking state; meaning nobody call\n\t * current context.\n\t */\n\tisEmpty() {\n\t\treturn this.invokingState === -1;\n\t}\n\n// satisfy the ParseTree / SyntaxTree interface\n\tgetSourceInterval() {\n\t\treturn INVALID_INTERVAL;\n\t}\n\n\tgetRuleContext() {\n\t\treturn this;\n\t}\n\n\tgetPayload() {\n\t\treturn this;\n\t}\n\n\t/**\n\t * Return the combined text of all child nodes. This method only considers\n\t * tokens which have been added to the parse tree.\n\t * <p>\n\t * Since tokens on hidden channels (e.g. whitespace or comments) are not\n\t * added to the parse trees, they will not appear in the output of this\n\t * method.\n\t */\n\tgetText() {\n\t\tif (this.getChildCount() === 0) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\treturn this.children.map(function(child) {\n\t\t\t\treturn child.getText();\n\t\t\t}).join(\"\");\n\t\t}\n\t}\n\n\t/**\n\t * For rule associated with this parse tree internal node, return\n\t * the outer alternative number used to match the input. Default\n\t * implementation does not compute nor store this alt num. Create\n\t * a subclass of ParserRuleContext with backing field and set\n\t * option contextSuperClass.\n\t * to set it.\n\t */\n\tgetAltNumber() {\n\t    // use constant value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n\t    return 0;\n    }\n\n\t/**\n\t * Set the outer alternative number for this context node. Default\n\t * implementation does nothing to avoid backing field overhead for\n\t * trees that don't need it.  Create\n\t * a subclass of ParserRuleContext with backing field and set\n\t * option contextSuperClass.\n\t */\n\tsetAltNumber(altNumber) { }\n\n\tgetChild(i) {\n\t\treturn null;\n\t}\n\n\tgetChildCount() {\n\t\treturn 0;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitChildren(this);\n\t}\n\n\t/**\n\t * Print out a whole tree, not just a node, in LISP format\n\t * (root child1 .. childN). Print just a node if this is a leaf.\n\t */\n\ttoStringTree(ruleNames, recog) {\n\t\treturn Trees.toStringTree(this, ruleNames, recog);\n\t}\n\n\ttoString(ruleNames, stop) {\n\t\truleNames = ruleNames || null;\n\t\tstop = stop || null;\n\t\tlet p = this;\n\t\tlet s = \"[\";\n\t\twhile (p !== null && p !== stop) {\n\t\t\tif (ruleNames === null) {\n\t\t\t\tif (!p.isEmpty()) {\n\t\t\t\t\ts += p.invokingState;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst ri = p.ruleIndex;\n\t\t\t\tconst ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n\t\t\t\t\t\t: \"\" + ri;\n\t\t\t\ts += ruleName;\n\t\t\t}\n\t\t\tif (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n\t\t\t\ts += \" \";\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\ts += \"]\";\n\t\treturn s;\n\t}\n}\n\nmodule.exports = RuleContext;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A token has properties: text, type, line, character position in the line\n * (so we can ignore tabs), token channel, index, and source from which\n * we obtained this token.\n */\nclass Token {\n\tconstructor() {\n\t\tthis.source = null;\n\t\tthis.type = null; // token type of the token\n\t\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\t\tthis.start = null; // optional; return -1 if not implemented.\n\t\tthis.stop = null; // optional; return -1 if not implemented.\n\t\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\t\tthis.line = null; // line=1..n of the 1st character\n\t\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\t\tthis._text = null; // text of the token.\n\t}\n\n\tgetTokenSource() {\n\t\treturn this.source[0];\n\t}\n\n\tgetInputStream() {\n\t\treturn this.source[1];\n\t}\n\n\tget text(){\n\t\treturn this._text;\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\nToken.INVALID_TYPE = 0;\n\n/**\n * During lookahead operations, this \"token\" signifies we hit rule end ATN state\n * and did not follow it despite needing to.\n */\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n/**\n * All tokens go to the parser (unless skip() is called in that rule)\n * on a particular \"channel\". The parser tunes to a particular channel\n * so that whitespace etc... can go to the parser on a \"hidden\" channel.\n */\nToken.DEFAULT_CHANNEL = 0;\n\n/**\n * Anything on different channel than DEFAULT_CHANNEL is not parsed\n * by parser.\n */\nToken.HIDDEN_CHANNEL = 1;\n\n\nclass CommonToken extends Token {\n\tconstructor(source, type, channel, start, stop) {\n\t\tsuper();\n\t\tthis.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n\t\tthis.type = type !== undefined ? type : null;\n\t\tthis.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n\t\tthis.start = start !== undefined ? start : -1;\n\t\tthis.stop = stop !== undefined ? stop : -1;\n\t\tthis.tokenIndex = -1;\n\t\tif (this.source[0] !== null) {\n\t\t\tthis.line = source[0].line;\n\t\t\tthis.column = source[0].column;\n\t\t} else {\n\t\t\tthis.column = -1;\n\t\t}\n\t}\n\n\t/**\n\t * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n\t *\n\t * <p>\n\t * If {@code oldToken} is also a {@link CommonToken} instance, the newly\n\t * constructed token will share a reference to the {@link //text} field and\n\t * the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n\t * be assigned the result of calling {@link //getText}, and {@link //source}\n\t * will be constructed from the result of {@link Token//getTokenSource} and\n\t * {@link Token//getInputStream}.</p>\n\t *\n\t * @param oldToken The token to copy.\n\t */\n\tclone() {\n\t\tconst t = new CommonToken(this.source, this.type, this.channel, this.start, this.stop);\n\t\tt.tokenIndex = this.tokenIndex;\n\t\tt.line = this.line;\n\t\tt.column = this.column;\n\t\tt.text = this.text;\n\t\treturn t;\n\t}\n\n\ttoString() {\n\t\tlet txt = this.text;\n\t\tif (txt !== null) {\n\t\t\ttxt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n\t\t} else {\n\t\t\ttxt = \"<no text>\";\n\t\t}\n\t\treturn \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n\t\t\t\ttxt + \"',<\" + this.type + \">\" +\n\t\t\t\t(this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n\t\t\t\tthis.line + \":\" + this.column + \"]\";\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t}\n\t\tconst input = this.getInputStream();\n\t\tif (input === null) {\n\t\t\treturn null;\n\t\t}\n\t\tconst n = input.size;\n\t\tif (this.start < n && this.stop < n) {\n\t\t\treturn input.getText(this.start, this.stop);\n\t\t} else {\n\t\t\treturn \"<EOF>\";\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n/**\n * An empty {@link Pair} which is used as the default value of\n * {@link //source} for tokens that do not have a source.\n */\nCommonToken.EMPTY_SOURCE = [ null, null ];\n\nmodule.exports = {\n\tToken,\n\tCommonToken\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nfunction arrayToString(a) {\n    return Array.isArray(a) ? (\"[\" + a.join(\", \") + \"]\") : \"null\";\n}\n\nString.prototype.seed = String.prototype.seed || Math.round(Math.random() * Math.pow(2, 32));\n\nString.prototype.hashCode = function () {\n    const key = this.toString();\n    let h1b, k1;\n\n    const remainder = key.length & 3; // key.length % 4\n    const bytes = key.length - remainder;\n    let h1 = String.prototype.seed;\n    const c1 = 0xcc9e2d51;\n    const c2 = 0x1b873593;\n    let i = 0;\n\n    while (i < bytes) {\n        k1 =\n            ((key.charCodeAt(i) & 0xff)) |\n            ((key.charCodeAt(++i) & 0xff) << 8) |\n            ((key.charCodeAt(++i) & 0xff) << 16) |\n            ((key.charCodeAt(++i) & 0xff) << 24);\n        ++i;\n\n        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;\n        k1 = (k1 << 15) | (k1 >>> 17);\n        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;\n\n        h1 ^= k1;\n        h1 = (h1 << 13) | (h1 >>> 19);\n        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;\n        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n        case 3:\n            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n        case 2:\n            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n        case 1:\n            k1 ^= (key.charCodeAt(i) & 0xff);\n\n            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n            h1 ^= k1;\n    }\n\n    h1 ^= key.length;\n\n    h1 ^= h1 >>> 16;\n    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= h1 >>> 13;\n    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;\n    h1 ^= h1 >>> 16;\n\n    return h1 >>> 0;\n};\n\nfunction standardEqualsFunction(a, b) {\n    return a ? a.equals(b) : a==b;\n}\n\nfunction standardHashCodeFunction(a) {\n    return a ? a.hashCode() : -1;\n}\n\nclass Set {\n    constructor(hashFunction, equalsFunction) {\n        this.data = {};\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    add(value) {\n        const hash = this.hashFunction(value);\n        const key = \"hash_\" + hash;\n        if (key in this.data) {\n            const values = this.data[key];\n            for (let i = 0; i < values.length; i++) {\n                if (this.equalsFunction(value, values[i])) {\n                    return values[i];\n                }\n            }\n            values.push(value);\n            return value;\n        } else {\n            this.data[key] = [value];\n            return value;\n        }\n    }\n\n    contains(value) {\n        return this.get(value) != null;\n    }\n\n    get(value) {\n        const hash = this.hashFunction(value);\n        const key = \"hash_\" + hash;\n        if (key in this.data) {\n            const values = this.data[key];\n            for (let i = 0; i < values.length; i++) {\n                if (this.equalsFunction(value, values[i])) {\n                    return values[i];\n                }\n            }\n        }\n        return null;\n    }\n\n    values() {\n        let l = [];\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l.concat(this.data[key]);\n            }\n        }\n        return l;\n    }\n\n    toString() {\n        return arrayToString(this.values());\n    }\n\n    get length(){\n        let l = 0;\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l + this.data[key].length;\n            }\n        }\n        return l;\n    }\n}\n\n\nclass BitSet {\n    constructor() {\n        this.data = [];\n    }\n\n    add(value) {\n        this.data[value] = true;\n    }\n\n    or(set) {\n        const bits = this;\n        Object.keys(set.data).map(function (alt) {\n            bits.add(alt);\n        });\n    }\n\n    remove(value) {\n        delete this.data[value];\n    }\n\n    contains(value) {\n        return this.data[value] === true;\n    }\n\n    values() {\n        return Object.keys(this.data);\n    }\n\n    minValue() {\n        return Math.min.apply(null, this.values());\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        hash.update(this.values());\n        return hash.finish();\n    }\n\n    equals(other) {\n        if (!(other instanceof BitSet)) {\n            return false;\n        }\n        return this.hashCode() === other.hashCode();\n    }\n\n    toString() {\n        return \"{\" + this.values().join(\", \") + \"}\";\n    }\n\n    get length(){\n        return this.values().length;\n    }\n}\n\n\nclass Map {\n    constructor(hashFunction, equalsFunction) {\n        this.data = {};\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    put(key, value) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if (hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key)) {\n                    const oldValue = entry.value;\n                    entry.value = value;\n                    return oldValue;\n                }\n            }\n            entries.push({key:key, value:value});\n            return value;\n        } else {\n            this.data[hashKey] = [{key:key, value:value}];\n            return value;\n        }\n    }\n\n    containsKey(key) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if(hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key))\n                    return true;\n            }\n        }\n        return false;\n    }\n\n    get(key) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if(hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key))\n                    return entry.value;\n            }\n        }\n        return null;\n    }\n\n    entries() {\n        let l = [];\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l.concat(this.data[key]);\n            }\n        }\n        return l;\n    }\n\n    getKeys() {\n        return this.entries().map(function(e) {\n            return e.key;\n        });\n    }\n\n    getValues() {\n        return this.entries().map(function(e) {\n                return e.value;\n        });\n    }\n\n    toString() {\n        const ss = this.entries().map(function(entry) {\n            return '{' + entry.key + ':' + entry.value + '}';\n        });\n        return '[' + ss.join(\", \") + ']';\n    }\n\n    get length(){\n        let l = 0;\n        for (const hashKey in this.data) {\n            if (hashKey.indexOf(\"hash_\") === 0) {\n                l = l + this.data[hashKey].length;\n            }\n        }\n        return l;\n    }\n}\n\n\nclass AltDict {\n    constructor() {\n        this.data = {};\n    }\n\n    get(key) {\n        key = \"k-\" + key;\n        if (key in this.data) {\n            return this.data[key];\n        } else {\n            return null;\n        }\n    }\n\n    put(key, value) {\n        key = \"k-\" + key;\n        this.data[key] = value;\n    }\n\n    values() {\n        const data = this.data;\n        const keys = Object.keys(this.data);\n        return keys.map(function (key) {\n            return data[key];\n        });\n    }\n}\n\n\nclass DoubleDict {\n    constructor(defaultMapCtor) {\n        this.defaultMapCtor = defaultMapCtor || Map;\n        this.cacheMap = new this.defaultMapCtor();\n    }\n\n    get(a, b) {\n        const d = this.cacheMap.get(a) || null;\n        return d === null ? null : (d.get(b) || null);\n    }\n\n    set(a, b, o) {\n        let d = this.cacheMap.get(a) || null;\n        if (d === null) {\n            d = new this.defaultMapCtor();\n            this.cacheMap.put(a, d);\n        }\n        d.put(b, o);\n    }\n}\n\nclass Hash {\n    constructor() {\n        this.count = 0;\n        this.hash = 0;\n    }\n\n    update() {\n        for(let i=0;i<arguments.length;i++) {\n            const value = arguments[i];\n            if (value == null)\n                continue;\n            if(Array.isArray(value))\n                this.update.apply(this, value);\n            else {\n                let k = 0;\n                switch (typeof(value)) {\n                    case 'undefined':\n                    case 'function':\n                        continue;\n                    case 'number':\n                    case 'boolean':\n                        k = value;\n                        break;\n                    case 'string':\n                        k = value.hashCode();\n                        break;\n                    default:\n                        if(value.updateHashCode)\n                            value.updateHashCode(this);\n                        else\n                            console.log(\"No updateHashCode for \" + value.toString())\n                        continue;\n                }\n                k = k * 0xCC9E2D51;\n                k = (k << 15) | (k >>> (32 - 15));\n                k = k * 0x1B873593;\n                this.count = this.count + 1;\n                let hash = this.hash ^ k;\n                hash = (hash << 13) | (hash >>> (32 - 13));\n                hash = hash * 5 + 0xE6546B64;\n                this.hash = hash;\n            }\n        }\n    }\n\n    finish() {\n        let hash = this.hash ^ (this.count * 4);\n        hash = hash ^ (hash >>> 16);\n        hash = hash * 0x85EBCA6B;\n        hash = hash ^ (hash >>> 13);\n        hash = hash * 0xC2B2AE35;\n        hash = hash ^ (hash >>> 16);\n        return hash;\n    }\n}\n\nfunction hashStuff() {\n    const hash = new Hash();\n    hash.update.apply(hash, arguments);\n    return hash.finish();\n}\n\n\nfunction escapeWhitespace(s, escapeSpaces) {\n    s = s.replace(/\\t/g, \"\\\\t\")\n         .replace(/\\n/g, \"\\\\n\")\n         .replace(/\\r/g, \"\\\\r\");\n    if (escapeSpaces) {\n        s = s.replace(/ /g, \"\\u00B7\");\n    }\n    return s;\n}\n\nfunction titleCase(str) {\n    return str.replace(/\\w\\S*/g, function (txt) {\n        return txt.charAt(0).toUpperCase() + txt.substr(1);\n    });\n}\n\nfunction equalArrays(a, b) {\n    if (!Array.isArray(a) || !Array.isArray(b))\n        return false;\n    if (a === b)\n        return true;\n    if (a.length !== b.length)\n        return false;\n    for (let i = 0; i < a.length; i++) {\n        if (a[i] === b[i])\n            continue;\n        if (!a[i].equals || !a[i].equals(b[i]))\n            return false;\n    }\n    return true;\n}\n\nmodule.exports = {\n    Hash,\n    Set,\n    Map,\n    BitSet,\n    AltDict,\n    DoubleDict,\n    hashStuff,\n    escapeWhitespace,\n    arrayToString,\n    titleCase,\n    equalArrays\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst LL1Analyzer = require('./../LL1Analyzer');\nconst {IntervalSet} = require('./../IntervalSet');\nconst {Token} = require('./../Token');\n\nclass ATN {\n\n    constructor(grammarType , maxTokenType) {\n        /**\n         * Used for runtime deserialization of ATNs from strings\n         * The type of the ATN.\n        */\n        this.grammarType = grammarType;\n        // The maximum value for any symbol recognized by a transition in the ATN.\n        this.maxTokenType = maxTokenType;\n        this.states = [];\n        /**\n         * Each subrule/rule is a decision point and we must track them so we\n         * can go back later and build DFA predictors for them.  This includes\n         * all the rules, subrules, optional blocks, ()+, ()* etc...\n         */\n        this.decisionToState = [];\n        // Maps from rule index to starting state number.\n        this.ruleToStartState = [];\n        // Maps from rule index to stop state number.\n        this.ruleToStopState = null;\n        this.modeNameToStartState = {};\n        /**\n         * For lexer ATNs, this maps the rule index to the resulting token type.\n         * For parser ATNs, this maps the rule index to the generated bypass token\n         * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n         * deserialization option was specified; otherwise, this is {@code null}\n         */\n        this.ruleToTokenType = null;\n        /**\n         * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n         * be referenced by action transitions in the ATN\n         */\n        this.lexerActions = null;\n        this.modeToStartState = [];\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in state {@code s}.\n     * If {@code ctx} is null, the set of tokens will not include what can follow\n     * the rule surrounding {@code s}. In other words, the set will be\n     * restricted to tokens reachable staying within {@code s}'s rule\n     */\n    nextTokensInContext(s, ctx) {\n        const anal = new LL1Analyzer(this);\n        return anal.LOOK(s, null, ctx);\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in {@code s} and\n     * staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n     * rule\n     */\n    nextTokensNoContext(s) {\n        if (s.nextTokenWithinRule !== null ) {\n            return s.nextTokenWithinRule;\n        }\n        s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n        s.nextTokenWithinRule.readOnly = true;\n        return s.nextTokenWithinRule;\n    }\n\n    nextTokens(s, ctx) {\n        if ( ctx===undefined ) {\n            return this.nextTokensNoContext(s);\n        } else {\n            return this.nextTokensInContext(s, ctx);\n        }\n    }\n\n    addState(state) {\n        if ( state !== null ) {\n            state.atn = this;\n            state.stateNumber = this.states.length;\n        }\n        this.states.push(state);\n    }\n\n    removeState(state) {\n        this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n    }\n\n    defineDecisionState(s) {\n        this.decisionToState.push(s);\n        s.decision = this.decisionToState.length-1;\n        return s.decision;\n    }\n\n    getDecisionState(decision) {\n        if (this.decisionToState.length===0) {\n            return null;\n        } else {\n            return this.decisionToState[decision];\n        }\n    }\n\n    /**\n     * Computes the set of input symbols which could follow ATN state number\n     * {@code stateNumber} in the specified full {@code context}. This method\n     * considers the complete parser context, but does not evaluate semantic\n     * predicates (i.e. all predicates encountered during the calculation are\n     * assumed true). If a path in the ATN exists from the starting state to the\n     * {@link RuleStopState} of the outermost context without matching any\n     * symbols, {@link Token//EOF} is added to the returned set.\n     *\n     * <p>If {@code context} is {@code null}, it is treated as\n     * {@link ParserRuleContext//EMPTY}.</p>\n     *\n     * @param stateNumber the ATN state number\n     * @param ctx the full parse context\n     *\n     * @return {IntervalSet} The set of potentially valid input symbols which could follow the\n     * specified state in the specified context.\n     *\n     * @throws IllegalArgumentException if the ATN does not contain a state with\n     * number {@code stateNumber}\n     */\n    getExpectedTokens(stateNumber, ctx ) {\n        if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n            throw(\"Invalid state number.\");\n        }\n        const s = this.states[stateNumber];\n        let following = this.nextTokens(s);\n        if (!following.contains(Token.EPSILON)) {\n            return following;\n        }\n        const expected = new IntervalSet();\n        expected.addSet(following);\n        expected.removeOne(Token.EPSILON);\n        while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n            const invokingState = this.states[ctx.invokingState];\n            const rt = invokingState.transitions[0];\n            following = this.nextTokens(rt.followState);\n            expected.addSet(following);\n            expected.removeOne(Token.EPSILON);\n            ctx = ctx.parentCtx;\n        }\n        if (following.contains(Token.EPSILON)) {\n            expected.addOne(Token.EOF);\n        }\n        return expected;\n    }\n}\n\nATN.INVALID_ALT_NUMBER = 0;\n\nmodule.exports = ATN;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {DecisionState} = require('./ATNState');\nconst {SemanticContext} = require('./SemanticContext');\nconst {Hash} = require(\"../Utils\");\n\n\nfunction checkParams(params, isCfg) {\n\tif(params===null) {\n\t\tconst result = { state:null, alt:null, context:null, semanticContext:null };\n\t\tif(isCfg) {\n\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t}\n\t\treturn result;\n\t} else {\n\t\tconst props = {};\n\t\tprops.state = params.state || null;\n\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\tprops.context = params.context || null;\n\t\tprops.semanticContext = params.semanticContext || null;\n\t\tif(isCfg) {\n\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t}\n\t\treturn props;\n\t}\n}\n\nclass ATNConfig {\n    /**\n     * @param {Object} params A tuple: (ATN state, predicted alt, syntactic, semantic context).\n     * The syntactic context is a graph-structured stack node whose\n     * path(s) to the root is the rule invocation(s)\n     * chain used to arrive at the state.  The semantic context is\n     * the tree of semantic predicates encountered before reaching\n     * an ATN state\n     */\n    constructor(params, config) {\n        this.checkContext(params, config);\n        params = checkParams(params);\n        config = checkParams(config, true);\n        // The ATN state associated with this configuration///\n        this.state = params.state!==null ? params.state : config.state;\n        // What alt (or lexer rule) is predicted by this configuration///\n        this.alt = params.alt!==null ? params.alt : config.alt;\n        /**\n         * The stack of invoking states leading to the rule/states associated\n         * with this config.  We track only those contexts pushed during\n         * execution of the ATN simulator\n         */\n        this.context = params.context!==null ? params.context : config.context;\n        this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n            (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n        // TODO: make it a boolean then\n        /**\n         * We cannot execute predicates dependent upon local context unless\n         * we know for sure we are in the correct context. Because there is\n         * no way to do this efficiently, we simply cannot evaluate\n         * dependent predicates unless we are in the rule that initially\n         * invokes the ATN simulator.\n         * closure() tracks the depth of how far we dip into the\n         * outer context: depth &gt; 0.  Note that it may not be totally\n         * accurate depth since I don't ever decrement\n         */\n        this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n        this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n    }\n\n    checkContext(params, config) {\n        if((params.context===null || params.context===undefined) &&\n                (config===null || config.context===null || config.context===undefined)) {\n            this.context = null;\n        }\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        this.updateHashCode(hash);\n        return hash.finish();\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);\n    }\n\n    /**\n     * An ATN configuration is equal to another if both have\n     * the same state, they predict the same alternative, and\n     * syntactic/semantic contexts are the same\n     */\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n                this.semanticContext.equals(other.semanticContext) &&\n                this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n        }\n    }\n\n    hashCodeForConfigSet() {\n        const hash = new Hash();\n        hash.update(this.state.stateNumber, this.alt, this.semanticContext);\n        return hash.finish();\n    }\n\n    equalsForConfigSet(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                this.semanticContext.equals(other.semanticContext);\n        }\n    }\n\n    toString() {\n        return \"(\" + this.state + \",\" + this.alt +\n            (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n            (this.semanticContext !== SemanticContext.NONE ?\n                    (\",\" + this.semanticContext.toString())\n                    : \"\") +\n            (this.reachesIntoOuterContext>0 ?\n                    (\",up=\" + this.reachesIntoOuterContext)\n                    : \"\") + \")\";\n    }\n}\n\n\nclass LexerATNConfig extends ATNConfig {\n    constructor(params, config) {\n        super(params, config);\n\n        // This is the backing field for {@link //getLexerActionExecutor}.\n        const lexerActionExecutor = params.lexerActionExecutor || null;\n        this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n        this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n        this.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;\n        this.equalsForConfigSet = LexerATNConfig.prototype.equals;\n        return this;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);\n    }\n\n    equals(other) {\n        return this === other ||\n                (other instanceof LexerATNConfig &&\n                this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision &&\n                (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&\n                super.equals(other));\n    }\n\n    checkNonGreedyDecision(source, target) {\n        return source.passedThroughNonGreedyDecision ||\n            (target instanceof DecisionState) && target.nonGreedy;\n    }\n}\n\n\nmodule.exports.ATNConfig = ATNConfig;\nmodule.exports.LexerATNConfig = LexerATNConfig;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst ATN = require('./ATN');\nconst Utils = require('./../Utils');\nconst {SemanticContext} = require('./SemanticContext');\nconst {merge} = require('./../PredictionContext');\n\nfunction hashATNConfig(c) {\n\treturn c.hashCodeForConfigSet();\n}\n\nfunction equalATNConfigs(a, b) {\n\tif ( a===b ) {\n\t\treturn true;\n\t} else if ( a===null || b===null ) {\n\t\treturn false;\n\t} else\n       return a.equalsForConfigSet(b);\n }\n\n/**\n * Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n * info about the set, with support for combining similar configurations using a\n * graph-structured stack\n */\nclass ATNConfigSet {\n\tconstructor(fullCtx) {\n\t\t/**\n\t\t * The reason that we need this is because we don't want the hash map to use\n\t\t * the standard hash code and equals. We need all configurations with the\n\t\t * same\n\t\t * {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t\t * doubles\n\t\t * the number of objects associated with ATNConfigs. The other solution is\n\t\t * to\n\t\t * use a hash table that lets us specify the equals/hashcode operation.\n\t\t * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t\t * when we go readonly as this set becomes a DFA state\n\t\t */\n\t\tthis.configLookup = new Utils.Set(hashATNConfig, equalATNConfigs);\n\t\t/**\n\t\t * Indicates that this configuration set is part of a full context\n\t\t * LL prediction. It will be used to determine how to merge $. With SLL\n\t\t * it's a wildcard whereas it is not for LL context merge\n\t\t */\n\t\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t\t/**\n\t\t * Indicates that the set of configurations is read-only. Do not\n\t\t * allow any code to manipulate the set; DFA states will point at\n\t\t * the sets and they must not change. This does not protect the other\n\t\t * fields; in particular, conflictingAlts is set after\n\t\t * we've made this readonly\n\t\t */\n\t\tthis.readOnly = false;\n\t\t// Track the elements as they are added to the set; supports get(i)///\n\t\tthis.configs = [];\n\n\t\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t\t// together, saves recomputation\n\t\t// TODO: can we track conflicts as they are added to save scanning configs\n\t\t// later?\n\t\tthis.uniqueAlt = 0;\n\t\tthis.conflictingAlts = null;\n\n\t\t/**\n\t\t * Used in parser and lexer. In lexer, it indicates we hit a pred\n\t\t * while computing a closure operation. Don't make a DFA state from this\n\t\t */\n\t\tthis.hasSemanticContext = false;\n\t\tthis.dipsIntoOuterContext = false;\n\n\t\tthis.cachedHashCode = -1;\n\t}\n\n\t/**\n\t * Adding a new config means merging contexts with existing configs for\n\t * {@code (s, i, pi, _)}, where {@code s} is the\n\t * {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n\t * {@code pi} is the {@link ATNConfig//semanticContext}. We use\n\t * {@code (s,i,pi)} as key.\n\t *\n\t * <p>This method updates {@link //dipsIntoOuterContext} and\n\t * {@link //hasSemanticContext} when necessary.</p>\n\t */\n\tadd(config, mergeCache) {\n\t\tif (mergeCache === undefined) {\n\t\t\tmergeCache = null;\n\t\t}\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\t\tthis.hasSemanticContext = true;\n\t\t}\n\t\tif (config.reachesIntoOuterContext > 0) {\n\t\t\tthis.dipsIntoOuterContext = true;\n\t\t}\n\t\tconst existing = this.configLookup.add(config);\n\t\tif (existing === config) {\n\t\t\tthis.cachedHashCode = -1;\n\t\t\tthis.configs.push(config); // track order here\n\t\t\treturn true;\n\t\t}\n\t\t// a previous (s,i,pi,_), merge with it and save result\n\t\tconst rootIsWildcard = !this.fullCtx;\n\t\tconst merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t\t/**\n\t\t * no need to check for existing.context, config.context in cache\n\t\t * since only way to create new graphs is \"call rule\" and here. We\n\t\t * cache at both places\n\t\t */\n\t\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t\t// make sure to preserve the precedence filter suppression during the merge\n\t\tif (config.precedenceFilterSuppressed) {\n\t\t\texisting.precedenceFilterSuppressed = true;\n\t\t}\n\t\texisting.context = merged; // replace context; no need to alt mapping\n\t\treturn true;\n\t}\n\n\tgetStates() {\n\t\tconst states = new Utils.Set();\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tstates.add(this.configs[i].state);\n\t\t}\n\t\treturn states;\n\t}\n\n\tgetPredicates() {\n\t\tconst preds = [];\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst c = this.configs[i].semanticContext;\n\t\t\tif (c !== SemanticContext.NONE) {\n\t\t\t\tpreds.push(c.semanticContext);\n\t\t\t}\n\t\t}\n\t\treturn preds;\n\t}\n\n\toptimizeConfigs(interpreter) {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (this.configLookup.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst config = this.configs[i];\n\t\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t\t}\n\t}\n\n\taddAll(coll) {\n\t\tfor (let i = 0; i < coll.length; i++) {\n\t\t\tthis.add(coll[i]);\n\t\t}\n\t\treturn false;\n\t}\n\n\tequals(other) {\n\t\treturn this === other ||\n\t\t\t(other instanceof ATNConfigSet &&\n\t\t\tUtils.equalArrays(this.configs, other.configs) &&\n\t\t\tthis.fullCtx === other.fullCtx &&\n\t\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext);\n\t}\n\n\thashCode() {\n\t\tconst hash = new Utils.Hash();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n\n\tupdateHashCode(hash) {\n\t\tif (this.readOnly) {\n\t\t\tif (this.cachedHashCode === -1) {\n\t\t\t\tthis.cachedHashCode = this.hashCode();\n\t\t\t}\n\t\t\thash.update(this.cachedHashCode);\n\t\t} else {\n\t\t\thash.update(this.hashCode());\n\t\t}\n\t}\n\n\tisEmpty() {\n\t\treturn this.configs.length === 0;\n\t}\n\n\tcontains(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.contains(item);\n\t}\n\n\tcontainsFast(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.containsFast(item);\n\t}\n\n\tclear() {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tthis.configs = [];\n\t\tthis.cachedHashCode = -1;\n\t\tthis.configLookup = new Utils.Set();\n\t}\n\n\tsetReadonly(readOnly) {\n\t\tthis.readOnly = readOnly;\n\t\tif (readOnly) {\n\t\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn Utils.arrayToString(this.configs) +\n\t\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n\t}\n\n\tget items(){\n\t\treturn this.configs;\n\t}\n\n\tget length(){\n\t\treturn this.configs.length;\n\t}\n}\n\n\nclass OrderedATNConfigSet extends ATNConfigSet {\n\tconstructor() {\n\t\tsuper();\n\t\tthis.configLookup = new Utils.Set();\n\t}\n}\n\nmodule.exports = {\n\tATNConfigSet,\n\tOrderedATNConfigSet\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nclass ATNDeserializationOptions {\n\tconstructor(copyFrom) {\n\t\tif(copyFrom===undefined) {\n\t\t\tcopyFrom = null;\n\t\t}\n\t\tthis.readOnly = false;\n\t\tthis.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n\t\tthis.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\t}\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n\n//    def __setattr__(self, key, value):\n//        if key!=\"readOnly\" and self.readOnly:\n//            raise Exception(\"The object is read only.\")\n//        super(type(self), self).__setattr__(key,value)\n\nmodule.exports = ATNDeserializationOptions\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst ATN = require('./ATN');\nconst ATNType = require('./ATNType');\n\nconst {\n    ATNState,\n    BasicState,\n    DecisionState,\n    BlockStartState,\n    BlockEndState,\n    LoopEndState,\n    RuleStartState,\n    RuleStopState,\n    TokensStartState,\n    PlusLoopbackState,\n    StarLoopbackState,\n    StarLoopEntryState,\n    PlusBlockStartState,\n    StarBlockStartState,\n    BasicBlockStartState\n} = require('./ATNState');\n\nconst {\n    Transition,\n    AtomTransition,\n    SetTransition,\n    NotSetTransition,\n    RuleTransition,\n    RangeTransition,\n    ActionTransition,\n    EpsilonTransition,\n    WildcardTransition,\n    PredicateTransition,\n    PrecedencePredicateTransition\n} = require('./Transition')\n\nconst {IntervalSet} = require('./../IntervalSet');\nconst ATNDeserializationOptions = require('./ATNDeserializationOptions');\n\nconst {\n    LexerActionType,\n    LexerSkipAction,\n    LexerChannelAction,\n    LexerCustomAction,\n    LexerMoreAction,\n    LexerTypeAction,\n    LexerPushModeAction,\n    LexerPopModeAction,\n    LexerModeAction,\n} = require('./LexerAction');\n\n// This is the earliest supported serialized UUID.\n// stick to serialized version for now, we don't need a UUID instance\nconst BASE_SERIALIZED_UUID = \"AADB8D7E-AEEF-4415-AD2B-8204D6CF042E\";\n\n//\n// This UUID indicates the serialized ATN contains two sets of\n// IntervalSets, where the second set's values are encoded as\n// 32-bit integers to support the full Unicode SMP range up to U+10FFFF.\n//\nconst ADDED_UNICODE_SMP = \"59627784-3BE5-417A-B9EB-8131A7286089\";\n\n// This list contains all of the currently supported UUIDs, ordered by when\n// the feature first appeared in this branch.\nconst SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID, ADDED_UNICODE_SMP ];\n\nconst SERIALIZED_VERSION = 3;\n\n// This is the current serialized UUID.\nconst SERIALIZED_UUID = ADDED_UNICODE_SMP;\n\nfunction initArray( length, value) {\n\tconst tmp = [];\n\ttmp[length-1] = value;\n\treturn tmp.map(function(i) {return value;});\n}\n\nclass ATNDeserializer {\n    constructor(options) {\n\n        if ( options=== undefined || options === null ) {\n            options = ATNDeserializationOptions.defaultOptions;\n        }\n        this.deserializationOptions = options;\n        this.stateFactories = null;\n        this.actionFactories = null;\n    }\n\n    /**\n     * Determines if a particular serialized representation of an ATN supports\n     * a particular feature, identified by the {@link UUID} used for serializing\n     * the ATN at the time the feature was first introduced.\n     *\n     * @param feature The {@link UUID} marking the first time the feature was\n     * supported in the serialized ATN.\n     * @param actualUuid The {@link UUID} of the actual serialized ATN which is\n     * currently being deserialized.\n     * @return {@code true} if the {@code actualUuid} value represents a\n     * serialized ATN at or after the feature identified by {@code feature} was\n     * introduced; otherwise, {@code false}.\n    */\n    isFeatureSupported(feature, actualUuid) {\n        const idx1 = SUPPORTED_UUIDS.indexOf(feature);\n        if (idx1<0) {\n            return false;\n        }\n        const idx2 = SUPPORTED_UUIDS.indexOf(actualUuid);\n        return idx2 >= idx1;\n    }\n\n    deserialize(data) {\n        this.reset(data);\n        this.checkVersion();\n        this.checkUUID();\n        const atn = this.readATN();\n        this.readStates(atn);\n        this.readRules(atn);\n        this.readModes(atn);\n        const sets = [];\n        // First, deserialize sets with 16-bit arguments <= U+FFFF.\n        this.readSets(atn, sets, this.readInt.bind(this));\n        // Next, if the ATN was serialized with the Unicode SMP feature,\n        // deserialize sets with 32-bit arguments <= U+10FFFF.\n        if (this.isFeatureSupported(ADDED_UNICODE_SMP, this.uuid)) {\n            this.readSets(atn, sets, this.readInt32.bind(this));\n        }\n        this.readEdges(atn, sets);\n        this.readDecisions(atn);\n        this.readLexerActions(atn);\n        this.markPrecedenceDecisions(atn);\n        this.verifyATN(atn);\n        if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n            this.generateRuleBypassTransitions(atn);\n            // re-verify after modification\n            this.verifyATN(atn);\n        }\n        return atn;\n    }\n\n    reset(data) {\n        const adjust = function(c) {\n            const v = c.charCodeAt(0);\n            return v>1  ? v-2 : v + 65534;\n        };\n        const temp = data.split(\"\").map(adjust);\n        // don't adjust the first value since that's the version number\n        temp[0] = data.charCodeAt(0);\n        this.data = temp;\n        this.pos = 0;\n    }\n\n    checkVersion() {\n        const version = this.readInt();\n        if ( version !== SERIALIZED_VERSION ) {\n            throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n        }\n    }\n\n    checkUUID() {\n        const uuid = this.readUUID();\n        if (SUPPORTED_UUIDS.indexOf(uuid)<0) {\n            throw (\"Could not deserialize ATN with UUID: \" + uuid +\n                            \" (expected \" + SERIALIZED_UUID + \" or a legacy UUID).\", uuid, SERIALIZED_UUID);\n        }\n        this.uuid = uuid;\n    }\n\n    readATN() {\n        const grammarType = this.readInt();\n        const maxTokenType = this.readInt();\n        return new ATN(grammarType, maxTokenType);\n    }\n\n    readStates(atn) {\n        let j, pair, stateNumber;\n        const  loopBackStateNumbers = [];\n        const  endStateNumbers = [];\n        const  nstates = this.readInt();\n        for(let i=0; i<nstates; i++) {\n            const  stype = this.readInt();\n            // ignore bad type of states\n            if (stype===ATNState.INVALID_TYPE) {\n                atn.addState(null);\n                continue;\n            }\n            let ruleIndex = this.readInt();\n            if (ruleIndex === 0xFFFF) {\n                ruleIndex = -1;\n            }\n            const  s = this.stateFactory(stype, ruleIndex);\n            if (stype === ATNState.LOOP_END) { // special case\n                const  loopBackStateNumber = this.readInt();\n                loopBackStateNumbers.push([s, loopBackStateNumber]);\n            } else if(s instanceof BlockStartState) {\n                const  endStateNumber = this.readInt();\n                endStateNumbers.push([s, endStateNumber]);\n            }\n            atn.addState(s);\n        }\n        // delay the assignment of loop back and end states until we know all the\n        // state instances have been initialized\n        for (j=0; j<loopBackStateNumbers.length; j++) {\n            pair = loopBackStateNumbers[j];\n            pair[0].loopBackState = atn.states[pair[1]];\n        }\n\n        for (j=0; j<endStateNumbers.length; j++) {\n            pair = endStateNumbers[j];\n            pair[0].endState = atn.states[pair[1]];\n        }\n\n        let numNonGreedyStates = this.readInt();\n        for (j=0; j<numNonGreedyStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].nonGreedy = true;\n        }\n\n        let numPrecedenceStates = this.readInt();\n        for (j=0; j<numPrecedenceStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].isPrecedenceRule = true;\n        }\n    }\n\n    readRules(atn) {\n        let i;\n        const nrules = this.readInt();\n        if (atn.grammarType === ATNType.LEXER ) {\n            atn.ruleToTokenType = initArray(nrules, 0);\n        }\n        atn.ruleToStartState = initArray(nrules, 0);\n        for (i=0; i<nrules; i++) {\n            const s = this.readInt();\n            atn.ruleToStartState[i] = atn.states[s];\n            if ( atn.grammarType === ATNType.LEXER ) {\n                let tokenType = this.readInt();\n                if (tokenType === 0xFFFF) {\n                    tokenType = Token.EOF;\n                }\n                atn.ruleToTokenType[i] = tokenType;\n            }\n        }\n        atn.ruleToStopState = initArray(nrules, 0);\n        for (i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!(state instanceof RuleStopState)) {\n                continue;\n            }\n            atn.ruleToStopState[state.ruleIndex] = state;\n            atn.ruleToStartState[state.ruleIndex].stopState = state;\n        }\n    }\n\n    readModes(atn) {\n        const nmodes = this.readInt();\n        for (let i=0; i<nmodes; i++) {\n            let s = this.readInt();\n            atn.modeToStartState.push(atn.states[s]);\n        }\n    }\n\n    readSets(atn, sets, readUnicode) {\n        const m = this.readInt();\n        for (let i=0; i<m; i++) {\n            const iset = new IntervalSet();\n            sets.push(iset);\n            const n = this.readInt();\n            const containsEof = this.readInt();\n            if (containsEof!==0) {\n                iset.addOne(-1);\n            }\n            for (let j=0; j<n; j++) {\n                const i1 = readUnicode();\n                const i2 = readUnicode();\n                iset.addRange(i1, i2);\n            }\n        }\n    }\n\n    readEdges(atn, sets) {\n        let i, j, state, trans, target;\n        const nedges = this.readInt();\n        for (i=0; i<nedges; i++) {\n            const src = this.readInt();\n            const trg = this.readInt();\n            const ttype = this.readInt();\n            const arg1 = this.readInt();\n            const arg2 = this.readInt();\n            const arg3 = this.readInt();\n            trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n            const srcState = atn.states[src];\n            srcState.addTransition(trans);\n        }\n        // edges for rule stop states can be derived, so they aren't serialized\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for (j=0; j<state.transitions.length; j++) {\n                const t = state.transitions[j];\n                if (!(t instanceof RuleTransition)) {\n                    continue;\n                }\n                let outermostPrecedenceReturn = -1;\n                if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n                    if (t.precedence === 0) {\n                        outermostPrecedenceReturn = t.target.ruleIndex;\n                    }\n                }\n\n                trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n                atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n            }\n        }\n\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            if (state instanceof BlockStartState) {\n                // we need to know the end state to set its start state\n                if (state.endState === null) {\n                    throw (\"IllegalState\");\n                }\n                // block end states can only be associated to a single block start\n                // state\n                if ( state.endState.startState !== null) {\n                    throw (\"IllegalState\");\n                }\n                state.endState.startState = state;\n            }\n            if (state instanceof PlusLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof PlusBlockStartState) {\n                        target.loopBackState = state;\n                    }\n                }\n            } else if (state instanceof StarLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof StarLoopEntryState) {\n                        target.loopBackState = state;\n                    }\n                }\n            }\n        }\n    }\n\n    readDecisions(atn) {\n        const ndecisions = this.readInt();\n        for (let i=0; i<ndecisions; i++) {\n            const s = this.readInt();\n            const decState = atn.states[s];\n            atn.decisionToState.push(decState);\n            decState.decision = i;\n        }\n    }\n\n    readLexerActions(atn) {\n        if (atn.grammarType === ATNType.LEXER) {\n            const count = this.readInt();\n            atn.lexerActions = initArray(count, null);\n            for (let i=0; i<count; i++) {\n                const actionType = this.readInt();\n                let data1 = this.readInt();\n                if (data1 === 0xFFFF) {\n                    data1 = -1;\n                }\n                let data2 = this.readInt();\n                if (data2 === 0xFFFF) {\n                    data2 = -1;\n                }\n\n                atn.lexerActions[i] = this.lexerActionFactory(actionType, data1, data2);\n            }\n        }\n    }\n\n    generateRuleBypassTransitions(atn) {\n        let i;\n        const count = atn.ruleToStartState.length;\n        for(i=0; i<count; i++) {\n            atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n        }\n        for(i=0; i<count; i++) {\n            this.generateRuleBypassTransition(atn, i);\n        }\n    }\n\n    generateRuleBypassTransition(atn, idx) {\n        let i, state;\n        const bypassStart = new BasicBlockStartState();\n        bypassStart.ruleIndex = idx;\n        atn.addState(bypassStart);\n\n        const bypassStop = new BlockEndState();\n        bypassStop.ruleIndex = idx;\n        atn.addState(bypassStop);\n\n        bypassStart.endState = bypassStop;\n        atn.defineDecisionState(bypassStart);\n\n        bypassStop.startState = bypassStart;\n\n        let excludeTransition = null;\n        let endState = null;\n\n        if (atn.ruleToStartState[idx].isPrecedenceRule) {\n            // wrap from the beginning of the rule to the StarLoopEntryState\n            endState = null;\n            for(i=0; i<atn.states.length; i++) {\n                state = atn.states[i];\n                if (this.stateIsEndStateFor(state, idx)) {\n                    endState = state;\n                    excludeTransition = state.loopBackState.transitions[0];\n                    break;\n                }\n            }\n            if (excludeTransition === null) {\n                throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n            }\n        } else {\n            endState = atn.ruleToStopState[idx];\n        }\n\n        // all non-excluded transitions that currently target end state need to\n        // target blockEnd instead\n        for(i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for(let j=0; j<state.transitions.length; j++) {\n                const transition = state.transitions[j];\n                if (transition === excludeTransition) {\n                    continue;\n                }\n                if (transition.target === endState) {\n                    transition.target = bypassStop;\n                }\n            }\n        }\n\n        // all transitions leaving the rule start state need to leave blockStart\n        // instead\n        const ruleToStartState = atn.ruleToStartState[idx];\n        const count = ruleToStartState.transitions.length;\n        while ( count > 0) {\n            bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n            ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n        }\n        // link the new states\n        atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n        bypassStop.addTransition(new EpsilonTransition(endState));\n\n        const matchState = new BasicState();\n        atn.addState(matchState);\n        matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n        bypassStart.addTransition(new EpsilonTransition(matchState));\n    }\n\n    stateIsEndStateFor(state, idx) {\n        if ( state.ruleIndex !== idx) {\n            return null;\n        }\n        if (!( state instanceof StarLoopEntryState)) {\n            return null;\n        }\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (!( maybeLoopEndState instanceof LoopEndState)) {\n            return null;\n        }\n        if (maybeLoopEndState.epsilonOnlyTransitions &&\n            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n            return state;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n     * the {@link StarLoopEntryState//isPrecedenceDecision} field to the\n     * correct value.\n     * @param atn The ATN.\n     */\n    markPrecedenceDecisions(atn) {\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!( state instanceof StarLoopEntryState)) {\n                continue;\n            }\n            // We analyze the ATN to determine if this ATN decision state is the\n            // decision for the closure block that determines whether a\n            // precedence rule should continue or complete.\n            if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n                const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n                if (maybeLoopEndState instanceof LoopEndState) {\n                    if ( maybeLoopEndState.epsilonOnlyTransitions &&\n                            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n                        state.isPrecedenceDecision = true;\n                    }\n                }\n            }\n        }\n    }\n\n    verifyATN(atn) {\n        if (!this.deserializationOptions.verifyATN) {\n            return;\n        }\n        // verify assumptions\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (state === null) {\n                continue;\n            }\n            this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n            if (state instanceof PlusBlockStartState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else  if (state instanceof StarLoopEntryState) {\n                this.checkCondition(state.loopBackState !== null);\n                this.checkCondition(state.transitions.length === 2);\n                if (state.transitions[0].target instanceof StarBlockStartState) {\n                    this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n                    this.checkCondition(!state.nonGreedy);\n                } else if (state.transitions[0].target instanceof LoopEndState) {\n                    this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n                    this.checkCondition(state.nonGreedy);\n                } else {\n                    throw(\"IllegalState\");\n                }\n            } else if (state instanceof StarLoopbackState) {\n                this.checkCondition(state.transitions.length === 1);\n                this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n            } else if (state instanceof LoopEndState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else if (state instanceof RuleStartState) {\n                this.checkCondition(state.stopState !== null);\n            } else if (state instanceof BlockStartState) {\n                this.checkCondition(state.endState !== null);\n            } else if (state instanceof BlockEndState) {\n                this.checkCondition(state.startState !== null);\n            } else if (state instanceof DecisionState) {\n                this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n            } else {\n                this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n            }\n        }\n    }\n\n    checkCondition(condition, message) {\n        if (!condition) {\n            if (message === undefined || message===null) {\n                message = \"IllegalState\";\n            }\n            throw (message);\n        }\n    }\n\n    readInt() {\n        return this.data[this.pos++];\n    }\n\n    readInt32() {\n        const low = this.readInt();\n        const high = this.readInt();\n        return low | (high << 16);\n    }\n\n    readLong() {\n        const low = this.readInt32();\n        const high = this.readInt32();\n        return (low & 0x00000000FFFFFFFF) | (high << 32);\n    }\n\n    readUUID() {\n        const bb = [];\n        for(let i=7;i>=0;i--) {\n            const int = this.readInt();\n            /* jshint bitwise: false */\n            bb[(2*i)+1] = int & 0xFF;\n            bb[2*i] = (int >> 8) & 0xFF;\n        }\n        return byteToHex[bb[0]] + byteToHex[bb[1]] +\n        byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +\n        byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +\n        byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +\n        byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +\n        byteToHex[bb[10]] + byteToHex[bb[11]] +\n        byteToHex[bb[12]] + byteToHex[bb[13]] +\n        byteToHex[bb[14]] + byteToHex[bb[15]];\n    }\n\n    edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets) {\n        const target = atn.states[trg];\n        switch(type) {\n        case Transition.EPSILON:\n            return new EpsilonTransition(target);\n        case Transition.RANGE:\n            return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n        case Transition.RULE:\n            return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n        case Transition.PREDICATE:\n            return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.PRECEDENCE:\n            return new PrecedencePredicateTransition(target, arg1);\n        case Transition.ATOM:\n            return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n        case Transition.ACTION:\n            return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.SET:\n            return new SetTransition(target, sets[arg1]);\n        case Transition.NOT_SET:\n            return new NotSetTransition(target, sets[arg1]);\n        case Transition.WILDCARD:\n            return new WildcardTransition(target);\n        default:\n            throw \"The specified transition type: \" + type + \" is not valid.\";\n        }\n    }\n\n    stateFactory(type, ruleIndex) {\n        if (this.stateFactories === null) {\n            const sf = [];\n            sf[ATNState.INVALID_TYPE] = null;\n            sf[ATNState.BASIC] = () => new BasicState();\n            sf[ATNState.RULE_START] = () => new RuleStartState();\n            sf[ATNState.BLOCK_START] = () => new BasicBlockStartState();\n            sf[ATNState.PLUS_BLOCK_START] = () => new PlusBlockStartState();\n            sf[ATNState.STAR_BLOCK_START] = () => new StarBlockStartState();\n            sf[ATNState.TOKEN_START] = () => new TokensStartState();\n            sf[ATNState.RULE_STOP] = () => new RuleStopState();\n            sf[ATNState.BLOCK_END] = () => new BlockEndState();\n            sf[ATNState.STAR_LOOP_BACK] = () => new StarLoopbackState();\n            sf[ATNState.STAR_LOOP_ENTRY] = () => new StarLoopEntryState();\n            sf[ATNState.PLUS_LOOP_BACK] = () => new PlusLoopbackState();\n            sf[ATNState.LOOP_END] = () => new LoopEndState();\n            this.stateFactories = sf;\n        }\n        if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n            throw(\"The specified state type \" + type + \" is not valid.\");\n        } else {\n            const s = this.stateFactories[type]();\n            if (s!==null) {\n                s.ruleIndex = ruleIndex;\n                return s;\n            }\n        }\n    }\n\n    lexerActionFactory(type, data1, data2) {\n        if (this.actionFactories === null) {\n            const af = [];\n            af[LexerActionType.CHANNEL] = (data1, data2) => new LexerChannelAction(data1);\n            af[LexerActionType.CUSTOM] = (data1, data2) => new LexerCustomAction(data1, data2);\n            af[LexerActionType.MODE] = (data1, data2) => new LexerModeAction(data1);\n            af[LexerActionType.MORE] = (data1, data2) => LexerMoreAction.INSTANCE;\n            af[LexerActionType.POP_MODE] = (data1, data2) => LexerPopModeAction.INSTANCE;\n            af[LexerActionType.PUSH_MODE] = (data1, data2) => new LexerPushModeAction(data1);\n            af[LexerActionType.SKIP] = (data1, data2) => LexerSkipAction.INSTANCE;\n            af[LexerActionType.TYPE] = (data1, data2) => new LexerTypeAction(data1);\n            this.actionFactories = af;\n        }\n        if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n            throw(\"The specified lexer action type \" + type + \" is not valid.\");\n        } else {\n            return this.actionFactories[type](data1, data2);\n        }\n    }\n}\n\nfunction createByteToHex() {\n\tconst bth = [];\n\tfor (let i = 0; i < 256; i++) {\n\t\tbth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();\n\t}\n\treturn bth;\n}\n\nconst byteToHex = createByteToHex();\n\n\nmodule.exports = ATNDeserializer;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {DFAState} = require('./../dfa/DFAState');\nconst {ATNConfigSet} = require('./ATNConfigSet');\nconst {getCachedPredictionContext} = require('./../PredictionContext');\nconst {Map} = require('./../Utils');\n\nclass ATNSimulator {\n    constructor(atn, sharedContextCache) {\n        /**\n         * The context cache maps all PredictionContext objects that are ==\n         * to a single cached copy. This cache is shared across all contexts\n         * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n         * to use only cached nodes/graphs in addDFAState(). We don't want to\n         * fill this during closure() since there are lots of contexts that\n         * pop up but are not used ever again. It also greatly slows down closure().\n         *\n         * <p>This cache makes a huge difference in memory and a little bit in speed.\n         * For the Java grammar on java.*, it dropped the memory requirements\n         * at the end from 25M to 16M. We don't store any of the full context\n         * graphs in the DFA because they are limited to local context only,\n         * but apparently there's a lot of repetition there as well. We optimize\n         * the config contexts before storing the config set in the DFA states\n         * by literally rebuilding them with cached subgraphs only.</p>\n         *\n         * <p>I tried a cache for use during closure operations, that was\n         * whacked after each adaptivePredict(). It cost a little bit\n         * more time I think and doesn't save on the overall footprint\n         * so it's not worth the complexity.</p>\n         */\n        this.atn = atn;\n        this.sharedContextCache = sharedContextCache;\n        return this;\n    }\n\n    getCachedContext(context) {\n        if (this.sharedContextCache ===null) {\n            return context;\n        }\n        const visited = new Map();\n        return getCachedPredictionContext(context, this.sharedContextCache, visited);\n    }\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\n\nmodule.exports = ATNSimulator;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst INITIAL_NUM_TRANSITIONS = 4;\n\n/**\n * The following images show the relation of states and\n * {@link ATNState//transitions} for various grammar constructs.\n *\n * <ul>\n *\n * <li>Solid edges marked with an &//0949; indicate a required\n * {@link EpsilonTransition}.</li>\n *\n * <li>Dashed edges indicate locations where any transition derived from\n * {@link Transition} might appear.</li>\n *\n * <li>Dashed nodes are place holders for either a sequence of linked\n * {@link BasicState} states or the inclusion of a block representing a nested\n * construct in one of the forms below.</li>\n *\n * <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n * any number of alternatives (one or more). Nodes without the {@code ...} only\n * support the exact number of alternatives shown in the diagram.</li>\n *\n * </ul>\n *\n * <h2>Basic Blocks</h2>\n *\n * <h3>Rule</h3>\n *\n * <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Block of 1 or more alternatives</h3>\n *\n * <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Greedy Loops</h2>\n *\n * <h3>Greedy Closure: {@code (...)*}</h3>\n *\n * <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Positive Closure: {@code (...)+}</h3>\n *\n * <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Optional: {@code (...)?}</h3>\n *\n * <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Non-Greedy Loops</h2>\n *\n * <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n *\n * <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n *\n * <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Optional: {@code (...)??}</h3>\n *\n * <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n */\nclass ATNState {\n    constructor() {\n        // Which ATN are we in?\n        this.atn = null;\n        this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n        this.stateType = null;\n        this.ruleIndex = 0; // at runtime, we don't have Rule objects\n        this.epsilonOnlyTransitions = false;\n        // Track the transitions emanating from this ATN state.\n        this.transitions = [];\n        // Used to cache lookahead during parsing, not used during construction\n        this.nextTokenWithinRule = null;\n    }\n\n    toString() {\n        return this.stateNumber;\n    }\n\n    equals(other) {\n        if (other instanceof ATNState) {\n            return this.stateNumber===other.stateNumber;\n        } else {\n            return false;\n        }\n    }\n\n    isNonGreedyExitState() {\n        return false;\n    }\n\n    addTransition(trans, index) {\n        if(index===undefined) {\n            index = -1;\n        }\n        if (this.transitions.length===0) {\n            this.epsilonOnlyTransitions = trans.isEpsilon;\n        } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n            this.epsilonOnlyTransitions = false;\n        }\n        if (index===-1) {\n            this.transitions.push(trans);\n        } else {\n            this.transitions.splice(index, 1, trans);\n        }\n    }\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n            \"INVALID\",\n            \"BASIC\",\n            \"RULE_START\",\n            \"BLOCK_START\",\n            \"PLUS_BLOCK_START\",\n            \"STAR_BLOCK_START\",\n            \"TOKEN_START\",\n            \"RULE_STOP\",\n            \"BLOCK_END\",\n            \"STAR_LOOP_BACK\",\n            \"STAR_LOOP_ENTRY\",\n            \"PLUS_LOOP_BACK\",\n            \"LOOP_END\" ];\n\nATNState.INVALID_STATE_NUMBER = -1;\n\n\nclass BasicState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BASIC;\n    }\n}\n\nclass DecisionState extends ATNState {\n    constructor() {\n        super();\n        this.decision = -1;\n        this.nonGreedy = false;\n        return this;\n    }\n}\n\n/**\n *  The start of a regular {@code (...)} block\n */\nclass BlockStartState extends DecisionState {\n    constructor() {\n        super();\n        this.endState = null;\n        return this;\n    }\n}\n\nclass BasicBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_START;\n        return this;\n    }\n}\n\n/**\n * Terminal node of a simple {@code (a|b|c)} block\n */\nclass BlockEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_END;\n        this.startState = null;\n        return this;\n    }\n}\n\n/**\n * The last node in the ATN for a rule, unless that rule is the start symbol.\n * In that case, there is one transition to EOF. Later, we might encode\n * references to all calls to this rule to compute FOLLOW sets for\n * error handling\n */\nclass RuleStopState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_STOP;\n        return this;\n    }\n}\n\nclass RuleStartState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_START;\n        this.stopState = null;\n        this.isPrecedenceRule = false;\n        return this;\n    }\n}\n\n/**\n * Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n * one to the loop back to start of the block and one to exit.\n */\nclass PlusLoopbackState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_LOOP_BACK;\n        return this;\n    }\n}\n\n/**\n * Start of {@code (A|B|...)+} loop. Technically a decision state, but\n * we don't use for code generation; somebody might need it, so I'm defining\n * it for completeness. In reality, the {@link PlusLoopbackState} node is the\n * real decision-making note for {@code A+}\n */\nclass PlusBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_BLOCK_START;\n        this.loopBackState = null;\n        return this;\n    }\n}\n\n/**\n * The block that begins a closure loop\n */\nclass StarBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_BLOCK_START;\n        return this;\n    }\n}\n\nclass StarLoopbackState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_BACK;\n        return this;\n    }\n}\n\nclass StarLoopEntryState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_ENTRY;\n        this.loopBackState = null;\n        // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n        this.isPrecedenceDecision = null;\n        return this;\n    }\n}\n\n/**\n * Mark the end of a * or + loop\n */\nclass LoopEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.LOOP_END;\n        this.loopBackState = null;\n        return this;\n    }\n}\n\n/**\n * The Tokens rule start state linking to each lexer rule start state\n */\nclass TokensStartState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.TOKEN_START;\n        return this;\n    }\n}\n\nmodule.exports = {\n    ATNState,\n    BasicState,\n    DecisionState,\n    BlockStartState,\n    BlockEndState,\n    LoopEndState,\n    RuleStartState,\n    RuleStopState,\n    TokensStartState,\n    PlusLoopbackState,\n    StarLoopbackState,\n    StarLoopEntryState,\n    PlusBlockStartState,\n    StarBlockStartState,\n    BasicBlockStartState\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Represents the type of recognizer an ATN applies to\n */\nmodule.exports = {\n    LEXER: 0,\n    PARSER: 1\n};\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst Lexer = require('./../Lexer');\nconst ATN = require('./ATN');\nconst ATNSimulator = require('./ATNSimulator');\nconst {DFAState} = require('./../dfa/DFAState');\nconst {OrderedATNConfigSet} = require('./ATNConfigSet');\nconst {PredictionContext} = require('./../PredictionContext');\nconst {SingletonPredictionContext} = require('./../PredictionContext');\nconst {RuleStopState} = require('./ATNState');\nconst {LexerATNConfig} = require('./ATNConfig');\nconst {Transition} = require('./Transition');\nconst LexerActionExecutor = require('./LexerActionExecutor');\nconst {LexerNoViableAltException} = require('./../error/Errors');\n\nfunction resetSimState(sim) {\n\tsim.index = -1;\n\tsim.line = 0;\n\tsim.column = -1;\n\tsim.dfaState = null;\n}\n\nclass SimState {\n\tconstructor() {\n\t\tresetSimState(this);\n\t}\n\n\treset() {\n\t\tresetSimState(this);\n\t}\n}\n\nclass LexerATNSimulator extends ATNSimulator {\n\t/**\n\t * When we hit an accept state in either the DFA or the ATN, we\n\t * have to notify the character stream to start buffering characters\n\t * via {@link IntStream//mark} and record the current state. The current sim state\n\t * includes the current index into the input, the current line,\n\t * and current character position in that line. Note that the Lexer is\n\t * tracking the starting line and characterization of the token. These\n\t * variables track the \"state\" of the simulator when it hits an accept state.\n\t *\n\t * <p>We track these variables separately for the DFA and ATN simulation\n\t * because the DFA simulation often has to fail over to the ATN\n\t * simulation. If the ATN simulation fails, we need the DFA to fall\n\t * back to its previously accepted state, if any. If the ATN succeeds,\n\t * then the ATN does the accept and the DFA simulator that invoked it\n\t * can simply return the predicted token type.</p>\n\t */\n\tconstructor(recog, atn, decisionToDFA, sharedContextCache) {\n\t\tsuper(atn, sharedContextCache);\n\t\tthis.decisionToDFA = decisionToDFA;\n\t\tthis.recog = recog;\n\t\t/**\n\t\t * The current token's starting index into the character stream.\n\t\t * Shared across DFA to ATN simulation in case the ATN fails and the\n\t\t * DFA did not have a previous accept state. In this case, we use the\n\t\t * ATN-generated exception object\n\t\t */\n\t\tthis.startIndex = -1;\n\t\t// line number 1..n within the input///\n\t\tthis.line = 1;\n\t\t/**\n\t\t * The index of the character relative to the beginning of the line\n\t\t * 0..n-1\n\t\t */\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t\t/**\n\t\t * Used during DFA/ATN exec to record the most recent accept configuration\n\t\t * info\n\t\t */\n\t\tthis.prevAccept = new SimState();\n\t}\n\n\tcopyState(simulator) {\n\t\tthis.column = simulator.column;\n\t\tthis.line = simulator.line;\n\t\tthis.mode = simulator.mode;\n\t\tthis.startIndex = simulator.startIndex;\n\t}\n\n\tmatch(input, mode) {\n\t\tthis.match_calls += 1;\n\t\tthis.mode = mode;\n\t\tconst mark = input.mark();\n\t\ttry {\n\t\t\tthis.startIndex = input.index;\n\t\t\tthis.prevAccept.reset();\n\t\t\tconst dfa = this.decisionToDFA[mode];\n\t\t\tif (dfa.s0 === null) {\n\t\t\t\treturn this.matchATN(input);\n\t\t\t} else {\n\t\t\t\treturn this.execATN(input, dfa.s0);\n\t\t\t}\n\t\t} finally {\n\t\t\tinput.release(mark);\n\t\t}\n\t}\n\n\treset() {\n\t\tthis.prevAccept.reset();\n\t\tthis.startIndex = -1;\n\t\tthis.line = 1;\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t}\n\n\tmatchATN(input) {\n\t\tconst startState = this.atn.modeToStartState[this.mode];\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n\t\t}\n\t\tconst old_mode = this.mode;\n\t\tconst s0_closure = this.computeStartState(input, startState);\n\t\tconst suppressEdge = s0_closure.hasSemanticContext;\n\t\ts0_closure.hasSemanticContext = false;\n\n\t\tconst next = this.addDFAState(s0_closure);\n\t\tif (!suppressEdge) {\n\t\t\tthis.decisionToDFA[this.mode].s0 = next;\n\t\t}\n\n\t\tconst predict = this.execATN(input, next);\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n\t\t}\n\t\treturn predict;\n\t}\n\n\texecATN(input, ds0) {\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"start state closure=\" + ds0.configs);\n\t\t}\n\t\tif (ds0.isAcceptState) {\n\t\t\t// allow zero-length tokens\n\t\t\tthis.captureSimState(this.prevAccept, input, ds0);\n\t\t}\n\t\tlet t = input.LA(1);\n\t\tlet s = ds0; // s is current/from DFA state\n\n\t\twhile (true) { // while more work\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"execATN loop starting closure: \" + s.configs);\n\t\t\t}\n\n\t\t\t/**\n\t\t\t * As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t\t * avoid looking up the DFA state again, which is expensive.\n\t\t\t * If the previous target was already part of the DFA, we might\n\t\t\t * be able to avoid doing a reach operation upon t. If s!=null,\n\t\t\t * it means that semantic predicates didn't prevent us from\n\t\t\t * creating a DFA state. Once we know s!=null, we check to see if\n\t\t\t * the DFA state has an edge already for t. If so, we can just reuse\n\t\t\t * it's configuration set; there's no point in re-computing it.\n\t\t\t * This is kind of like doing DFA simulation within the ATN\n\t\t\t * simulation because DFA simulation is really just a way to avoid\n\t\t\t * computing reach/closure sets. Technically, once we know that\n\t\t\t * we have a previously added DFA state, we could jump over to\n\t\t\t * the DFA simulator. But, that would mean popping back and forth\n\t\t\t * a lot and making things more complicated algorithmically.\n\t\t\t * This optimization makes a lot of sense for loops within DFA.\n\t\t\t * A character will take us back to an existing DFA state\n\t\t\t * that already has lots of edges out of it. e.g., .* in comments.\n\t\t\t * print(\"Target for:\" + str(s) + \" and:\" + str(t))\n\t\t\t */\n\t\t\tlet target = this.getExistingTargetState(s, t);\n\t\t\t// print(\"Existing:\" + str(target))\n\t\t\tif (target === null) {\n\t\t\t\ttarget = this.computeTargetState(input, s, t);\n\t\t\t\t// print(\"Computed:\" + str(target))\n\t\t\t}\n\t\t\tif (target === ATNSimulator.ERROR) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t// If this is a consumable input element, make sure to consume before\n\t\t\t// capturing the accept state so the input index, line, and char\n\t\t\t// position accurately reflect the state of the interpreter at the\n\t\t\t// end of the token.\n\t\t\tif (t !== Token.EOF) {\n\t\t\t\tthis.consume(input);\n\t\t\t}\n\t\t\tif (target.isAcceptState) {\n\t\t\t\tthis.captureSimState(this.prevAccept, input, target);\n\t\t\t\tif (t === Token.EOF) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tt = input.LA(1);\n\t\t\ts = target; // flip; current DFA target becomes new src/from state\n\t\t}\n\t\treturn this.failOrAccept(this.prevAccept, input, s.configs, t);\n\t}\n\n\t/**\n\t * Get an existing target state for an edge in the DFA. If the target state\n\t * for the edge has not yet been computed or is otherwise not available,\n\t * this method returns {@code null}.\n\t *\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t * @return The existing target DFA state for the given input symbol\n\t * {@code t}, or {@code null} if the target state for this edge is not\n\t * already cached\n\t */\n\tgetExistingTargetState(s, t) {\n\t\tif (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n\t\tif(target===undefined) {\n\t\t\ttarget = null;\n\t\t}\n\t\tif (LexerATNSimulator.debug && target !== null) {\n\t\t\tconsole.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n\t\t}\n\t\treturn target;\n\t}\n\n\t/**\n\t * Compute a target state for an edge in the DFA, and attempt to add the\n\t * computed state and corresponding edge to the DFA.\n\t *\n\t * @param input The input stream\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t *\n\t * @return The computed target DFA state for the given input symbol\n\t * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n\t * returns {@link //ERROR}.\n\t */\n\tcomputeTargetState(input, s, t) {\n\t\tconst reach = new OrderedATNConfigSet();\n\t\t// if we don't find an existing DFA state\n\t\t// Fill reach starting from closure, following t transitions\n\t\tthis.getReachableConfigSet(input, s.configs, reach, t);\n\n\t\tif (reach.items.length === 0) { // we got nowhere on t from s\n\t\t\tif (!reach.hasSemanticContext) {\n\t\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t\t// cause a failover from DFA later.\n\t\t\t\tthis.addDFAEdge(s, t, ATNSimulator.ERROR);\n\t\t\t}\n\t\t\t// stop when we can't match any more char\n\t\t\treturn ATNSimulator.ERROR;\n\t\t}\n\t\t// Add an edge from s to target DFA found/created for reach\n\t\treturn this.addDFAEdge(s, t, null, reach);\n\t}\n\n\tfailOrAccept(prevAccept, input, reach, t) {\n\t\tif (this.prevAccept.dfaState !== null) {\n\t\t\tconst lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n\t\t\tthis.accept(input, lexerActionExecutor, this.startIndex,\n\t\t\t\t\tprevAccept.index, prevAccept.line, prevAccept.column);\n\t\t\treturn prevAccept.dfaState.prediction;\n\t\t} else {\n\t\t\t// if no accept and EOF is first char, return EOF\n\t\t\tif (t === Token.EOF && input.index === this.startIndex) {\n\t\t\t\treturn Token.EOF;\n\t\t\t}\n\t\t\tthrow new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n\t\t}\n\t}\n\n\t/**\n\t * Given a starting configuration set, figure out all ATN configurations\n\t * we can reach upon input {@code t}. Parameter {@code reach} is a return\n\t * parameter.\n\t */\n\tgetReachableConfigSet(input, closure,\n\t\t\treach, t) {\n\t\t// this is used to skip processing for configs which have a lower priority\n\t\t// than a config that already reached an accept state for the same rule\n\t\tlet skipAlt = ATN.INVALID_ALT_NUMBER;\n\t\tfor (let i = 0; i < closure.items.length; i++) {\n\t\t\tconst cfg = closure.items[i];\n\t\t\tconst currentAltReachedAcceptState = (cfg.alt === skipAlt);\n\t\t\tif (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n\t\t\t\t\t\t.toString(this.recog, true));\n\t\t\t}\n\t\t\tfor (let j = 0; j < cfg.state.transitions.length; j++) {\n\t\t\t\tconst trans = cfg.state.transitions[j]; // for each transition\n\t\t\t\tconst target = this.getReachableTarget(trans, t);\n\t\t\t\tif (target !== null) {\n\t\t\t\t\tlet lexerActionExecutor = cfg.lexerActionExecutor;\n\t\t\t\t\tif (lexerActionExecutor !== null) {\n\t\t\t\t\t\tlexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n\t\t\t\t\t}\n\t\t\t\t\tconst treatEofAsEpsilon = (t === Token.EOF);\n\t\t\t\t\tconst config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);\n\t\t\t\t\tif (this.closure(input, config, reach,\n\t\t\t\t\t\t\tcurrentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n\t\t\t\t\t\t// any remaining configs for this alt have a lower priority\n\t\t\t\t\t\t// than the one that just reached an accept state.\n\t\t\t\t\t\tskipAlt = cfg.alt;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\taccept(input, lexerActionExecutor,\n\t\t\t   startIndex, index, line, charPos) {\n\t\t   if (LexerATNSimulator.debug) {\n\t\t\t   console.log(\"ACTION %s\\n\", lexerActionExecutor);\n\t\t   }\n\t\t   // seek to after last char in token\n\t\t   input.seek(index);\n\t\t   this.line = line;\n\t\t   this.column = charPos;\n\t\t   if (lexerActionExecutor !== null && this.recog !== null) {\n\t\t\t   lexerActionExecutor.execute(this.recog, input, startIndex);\n\t\t   }\n\t   }\n\n\tgetReachableTarget(trans, t) {\n\t\tif (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\treturn trans.target;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tcomputeStartState(input, p) {\n\t\tconst initialContext = PredictionContext.EMPTY;\n\t\tconst configs = new OrderedATNConfigSet();\n\t\tfor (let i = 0; i < p.transitions.length; i++) {\n\t\t\tconst target = p.transitions[i].target;\n\t\t\tconst cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);\n\t\t\tthis.closure(input, cfg, configs, false, false, false);\n\t\t}\n\t\treturn configs;\n\t}\n\n\t/**\n\t * Since the alternatives within any lexer decision are ordered by\n\t * preference, this method stops pursuing the closure as soon as an accept\n\t * state is reached. After the first accept state is reached by depth-first\n\t * search from {@code config}, all other (potentially reachable) states for\n\t * this rule would have a lower priority.\n\t *\n\t * @return {Boolean} {@code true} if an accept state is reached, otherwise\n\t * {@code false}.\n\t */\n\tclosure(input, config, configs,\n\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n\t\tlet cfg = null;\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n\t\t}\n\t\tif (config.state instanceof RuleStopState) {\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tif (this.recog !== null) {\n\t\t\t\t\tconsole.log(\"closure at %s rule stop %s\\n\", this.recog.ruleNames[config.state.ruleIndex], config);\n\t\t\t\t} else {\n\t\t\t\t\tconsole.log(\"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\tif (config.context === null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t} else {\n\t\t\t\t\tconfigs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context !== null && !config.context.isEmpty()) {\n\t\t\t\tfor (let i = 0; i < config.context.length; i++) {\n\t\t\t\t\tif (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\t\tconst newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\t\tconst returnState = this.atn.states[config.context.getReturnState(i)];\n\t\t\t\t\t\tcfg = new LexerATNConfig({ state:returnState, context:newContext }, config);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg,\n\t\t\t\t\t\t\t\tconfigs, currentAltReachedAcceptState, speculative,\n\t\t\t\t\t\t\t\ttreatEofAsEpsilon);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\t\t// optimization\n\t\tif (!config.state.epsilonOnlyTransitions) {\n\t\t\tif (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\t\tfor (let j = 0; j < config.state.transitions.length; j++) {\n\t\t\tconst trans = config.state.transitions[j];\n\t\t\tcfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n\t\t\tif (cfg !== null) {\n\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg, configs,\n\t\t\t\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\t\treturn currentAltReachedAcceptState;\n\t}\n\n\t// side-effect: can alter configs.hasSemanticContext\n\tgetEpsilonTarget(input, config, trans,\n\t\t\tconfigs, speculative, treatEofAsEpsilon) {\n\t\tlet cfg = null;\n\t\tif (trans.serializationType === Transition.RULE) {\n\t\t\tconst newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n\t\t\tcfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);\n\t\t} else if (trans.serializationType === Transition.PRECEDENCE) {\n\t\t\tthrow \"Precedence predicates are not supported in lexers.\";\n\t\t} else if (trans.serializationType === Transition.PREDICATE) {\n\t\t\t// Track traversing semantic predicates. If we traverse,\n\t\t\t// we cannot add a DFA state for this \"reach\" computation\n\t\t\t// because the DFA would not test the predicate again in the\n\t\t\t// future. Rather than creating collections of semantic predicates\n\t\t\t// like v3 and testing them on prediction, v4 will test them on the\n\t\t\t// fly all the time using the ATN not the DFA. This is slower but\n\t\t\t// semantically it's not used that often. One of the key elements to\n\t\t\t// this predicate mechanism is not adding DFA states that see\n\t\t\t// predicates immediately afterwards in the ATN. For example,\n\n\t\t\t// a : ID {p1}? | ID {p2}? ;\n\n\t\t\t// should create the start state for rule 'a' (to save start state\n\t\t\t// competition), but should not create target of ID state. The\n\t\t\t// collection of ATN states the following ID references includes\n\t\t\t// states reached by traversing predicates. Since this is when we\n\t\t\t// test them, we cannot cash the DFA state target of ID.\n\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n\t\t\t}\n\t\t\tconfigs.hasSemanticContext = true;\n\t\t\tif (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.ACTION) {\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\t// execute actions anywhere in the start rule for a token.\n\t\t\t\t//\n\t\t\t\t// TODO: if the entry rule is invoked recursively, some\n\t\t\t\t// actions may be executed during the recursive call. The\n\t\t\t\t// problem can appear when hasEmptyPath() is true but\n\t\t\t\t// isEmpty() is false. In this case, the config needs to be\n\t\t\t\t// split into two contexts - one with just the empty path\n\t\t\t\t// and another with everything but the empty path.\n\t\t\t\t// Unfortunately, the current algorithm does not allow\n\t\t\t\t// getEpsilonTarget to return two configurations, so\n\t\t\t\t// additional modifications are needed before we can support\n\t\t\t\t// the split operation.\n\t\t\t\tconst lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n\t\t\t\t\t\tthis.atn.lexerActions[trans.actionIndex]);\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);\n\t\t\t} else {\n\t\t\t\t// ignore actions in referenced rules\n\t\t\t\tcfg = new LexerATNConfig( { state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.EPSILON) {\n\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t} else if (trans.serializationType === Transition.ATOM ||\n\t\t\t\t\ttrans.serializationType === Transition.RANGE ||\n\t\t\t\t\ttrans.serializationType === Transition.SET) {\n\t\t\tif (treatEofAsEpsilon) {\n\t\t\t\tif (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\t\t\tcfg = new LexerATNConfig( { state:trans.target }, config);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn cfg;\n\t}\n\n\t/**\n\t * Evaluate a predicate specified in the lexer.\n\t *\n\t * <p>If {@code speculative} is {@code true}, this method was called before\n\t * {@link //consume} for the matched character. This method should call\n\t * {@link //consume} before evaluating the predicate to ensure position\n\t * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n\t * and {@link Lexer//getcolumn}, properly reflect the current\n\t * lexer state. This method should restore {@code input} and the simulator\n\t * to the original state before returning (i.e. undo the actions made by the\n\t * call to {@link //consume}.</p>\n\t *\n\t * @param input The input stream.\n\t * @param ruleIndex The rule containing the predicate.\n\t * @param predIndex The index of the predicate within the rule.\n\t * @param speculative {@code true} if the current index in {@code input} is\n\t * one character before the predicate's location.\n\t *\n\t * @return {@code true} if the specified predicate evaluates to\n\t * {@code true}.\n\t */\n\tevaluatePredicate(input, ruleIndex,\n\t\t\tpredIndex, speculative) {\n\t\t// assume true if no recognizer was provided\n\t\tif (this.recog === null) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!speculative) {\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t}\n\t\tconst savedcolumn = this.column;\n\t\tconst savedLine = this.line;\n\t\tconst index = input.index;\n\t\tconst marker = input.mark();\n\t\ttry {\n\t\t\tthis.consume(input);\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t} finally {\n\t\t\tthis.column = savedcolumn;\n\t\t\tthis.line = savedLine;\n\t\t\tinput.seek(index);\n\t\t\tinput.release(marker);\n\t\t}\n\t}\n\n\tcaptureSimState(settings, input, dfaState) {\n\t\tsettings.index = input.index;\n\t\tsettings.line = this.line;\n\t\tsettings.column = this.column;\n\t\tsettings.dfaState = dfaState;\n\t}\n\n\taddDFAEdge(from_, tk, to, cfgs) {\n\t\tif (to === undefined) {\n\t\t\tto = null;\n\t\t}\n\t\tif (cfgs === undefined) {\n\t\t\tcfgs = null;\n\t\t}\n\t\tif (to === null && cfgs !== null) {\n\t\t\t// leading to this call, ATNConfigSet.hasSemanticContext is used as a\n\t\t\t// marker indicating dynamic predicate evaluation makes this edge\n\t\t\t// dependent on the specific input sequence, so the static edge in the\n\t\t\t// DFA should be omitted. The target DFAState is still created since\n\t\t\t// execATN has the ability to resynchronize with the DFA state cache\n\t\t\t// following the predicate evaluation step.\n\t\t\t//\n\t\t\t// TJP notes: next time through the DFA, we see a pred again and eval.\n\t\t\t// If that gets us to a previously created (but dangling) DFA\n\t\t\t// state, we can continue in pure DFA mode from there.\n\t\t\t// /\n\t\t\tconst suppressEdge = cfgs.hasSemanticContext;\n\t\t\tcfgs.hasSemanticContext = false;\n\n\t\t\tto = this.addDFAState(cfgs);\n\n\t\t\tif (suppressEdge) {\n\t\t\t\treturn to;\n\t\t\t}\n\t\t}\n\t\t// add the edge\n\t\tif (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\t// Only track edges within the DFA bounds\n\t\t\treturn to;\n\t\t}\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n\t\t}\n\t\tif (from_.edges === null) {\n\t\t\t// make room for tokens 1..n and -1 masquerading as index 0\n\t\t\tfrom_.edges = [];\n\t\t}\n\t\tfrom_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n\t\treturn to;\n\t}\n\n\t/**\n\t * Add a new DFA state if there isn't one with this set of\n\t * configurations already. This method also detects the first\n\t * configuration containing an ATN rule stop state. Later, when\n\t * traversing the DFA, we will know which rule to accept.\n\t */\n\taddDFAState(configs) {\n\t\tconst proposed = new DFAState(null, configs);\n\t\tlet firstConfigWithRuleStopState = null;\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tconst cfg = configs.items[i];\n\t\t\tif (cfg.state instanceof RuleStopState) {\n\t\t\t\tfirstConfigWithRuleStopState = cfg;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (firstConfigWithRuleStopState !== null) {\n\t\t\tproposed.isAcceptState = true;\n\t\t\tproposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n\t\t\tproposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n\t\t}\n\t\tconst dfa = this.decisionToDFA[this.mode];\n\t\tconst existing = dfa.states.get(proposed);\n\t\tif (existing!==null) {\n\t\t\treturn existing;\n\t\t}\n\t\tconst newState = proposed;\n\t\tnewState.stateNumber = dfa.states.length;\n\t\tconfigs.setReadonly(true);\n\t\tnewState.configs = configs;\n\t\tdfa.states.add(newState);\n\t\treturn newState;\n\t}\n\n\tgetDFA(mode) {\n\t\treturn this.decisionToDFA[mode];\n\t}\n\n// Get the text matched so far for the current token.\n\tgetText(input) {\n\t\t// index is first lookahead char, don't include.\n\t\treturn input.getText(this.startIndex, input.index - 1);\n\t}\n\n\tconsume(input) {\n\t\tconst curChar = input.LA(1);\n\t\tif (curChar === \"\\n\".charCodeAt(0)) {\n\t\t\tthis.line += 1;\n\t\t\tthis.column = 0;\n\t\t} else {\n\t\t\tthis.column += 1;\n\t\t}\n\t\tinput.consume();\n\t}\n\n\tgetTokenName(tt) {\n\t\tif (tt === -1) {\n\t\t\treturn \"EOF\";\n\t\t} else {\n\t\t\treturn \"'\" + String.fromCharCode(tt) + \"'\";\n\t\t}\n\t}\n}\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n\nLexerATNSimulator.match_calls = 0;\n\nmodule.exports = LexerATNSimulator;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst LexerActionType = {\n    // The type of a {@link LexerChannelAction} action.\n    CHANNEL: 0,\n    // The type of a {@link LexerCustomAction} action\n    CUSTOM: 1,\n    // The type of a {@link LexerModeAction} action.\n    MODE: 2,\n    //The type of a {@link LexerMoreAction} action.\n    MORE: 3,\n    //The type of a {@link LexerPopModeAction} action.\n    POP_MODE: 4,\n    //The type of a {@link LexerPushModeAction} action.\n    PUSH_MODE: 5,\n    //The type of a {@link LexerSkipAction} action.\n    SKIP: 6,\n    //The type of a {@link LexerTypeAction} action.\n    TYPE: 7\n}\n\nclass LexerAction {\n    constructor(action) {\n        this.actionType = action;\n        this.isPositionDependent = false;\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        this.updateHashCode(hash);\n        return hash.finish()\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType);\n    }\n\n    equals(other) {\n        return this === other;\n    }\n}\n\n\n/**\n * Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n *\n * <p>The {@code skip} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerSkipAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.SKIP);\n    }\n\n    execute(lexer) {\n        lexer.skip();\n    }\n\n    toString() {\n        return \"skip\";\n    }\n}\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n\n/**\n * Implements the {@code type} lexer action by calling {@link Lexer//setType}\n * with the assigned type\n */\nclass LexerTypeAction extends LexerAction {\n    constructor(type) {\n        super(LexerActionType.TYPE);\n        this.type = type;\n    }\n\n    execute(lexer) {\n        lexer.type = this.type;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.type);\n    }\n\n    equals(other) {\n        if(this === other) {\n            return true;\n        } else if (! (other instanceof LexerTypeAction)) {\n            return false;\n        } else {\n            return this.type === other.type;\n        }\n    }\n\n    toString() {\n        return \"type(\" + this.type + \")\";\n    }\n}\n\n\n/**\n * Implements the {@code pushMode} lexer action by calling\n * {@link Lexer//pushMode} with the assigned mode\n */\nclass LexerPushModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.PUSH_MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//pushMode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.pushMode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerPushModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"pushMode(\" + this.mode + \")\";\n    }\n}\n\n/**\n * Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n *\n * <p>The {@code popMode} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerPopModeAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.POP_MODE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.popMode();\n    }\n\n    toString() {\n        return \"popMode\";\n    }\n}\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n\n/**\n * Implements the {@code more} lexer action by calling {@link Lexer//more}.\n *\n * <p>The {@code more} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerMoreAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.MORE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.more();\n    }\n\n    toString() {\n        return \"more\";\n    }\n}\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n\n\n/**\n * Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n * the assigned mode\n */\nclass LexerModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//mode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.mode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"mode(\" + this.mode + \")\";\n    }\n}\n\n/**\n * Executes a custom lexer action by calling {@link Recognizer//action} with the\n * rule and action indexes assigned to the custom action. The implementation of\n * a custom action is added to the generated code for the lexer in an override\n * of {@link Recognizer//action} when the grammar is compiled.\n *\n * <p>This class may represent embedded actions created with the <code>{...}</code>\n * syntax in ANTLR 4, as well as actions created for lexer commands where the\n * command argument could not be evaluated when the grammar was compiled.</p>\n */\nclass LexerCustomAction extends LexerAction {\n    /**\n     * Constructs a custom lexer action with the specified rule and action\n     * indexes.\n     *\n     * @param ruleIndex The rule index to use for calls to\n     * {@link Recognizer//action}.\n     * @param actionIndex The action index to use for calls to\n     * {@link Recognizer//action}.\n     */\n    constructor(ruleIndex, actionIndex) {\n        super(LexerActionType.CUSTOM);\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>Custom actions are implemented by calling {@link Lexer//action} with the\n     * appropriate rule and action indexes.</p>\n     */\n    execute(lexer) {\n        lexer.action(null, this.ruleIndex, this.actionIndex);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.ruleIndex, this.actionIndex);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerCustomAction)) {\n            return false;\n        } else {\n            return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n        }\n    }\n}\n\n/**\n * Implements the {@code channel} lexer action by calling\n * {@link Lexer//setChannel} with the assigned channel.\n * Constructs a new {@code channel} action with the specified channel value.\n * @param channel The channel value to pass to {@link Lexer//setChannel}\n */\nclass LexerChannelAction extends LexerAction {\n    constructor(channel) {\n        super(LexerActionType.CHANNEL);\n        this.channel = channel;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//setChannel} with the\n     * value provided by {@link //getChannel}.</p>\n     */\n    execute(lexer) {\n        lexer._channel = this.channel;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.channel);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerChannelAction)) {\n            return false;\n        } else {\n            return this.channel === other.channel;\n        }\n    }\n\n    toString() {\n        return \"channel(\" + this.channel + \")\";\n    }\n}\n\n\n/**\n * This implementation of {@link LexerAction} is used for tracking input offsets\n * for position-dependent actions within a {@link LexerActionExecutor}.\n *\n * <p>This action is not serialized as part of the ATN, and is only required for\n * position-dependent lexer actions which appear at a location other than the\n * end of a rule. For more information about DFA optimizations employed for\n * lexer actions, see {@link LexerActionExecutor//append} and\n * {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n *\n * Constructs a new indexed custom action by associating a character offset\n * with a {@link LexerAction}.\n *\n * <p>Note: This class is only required for lexer actions for which\n * {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n *\n * @param offset The offset into the input {@link CharStream}, relative to\n * the token start index, at which the specified lexer action should be\n * executed.\n * @param action The lexer action to execute at a particular offset in the\n * input {@link CharStream}.\n */\nclass LexerIndexedCustomAction extends LexerAction {\n    constructor(offset, action) {\n        super(action.actionType);\n        this.offset = offset;\n        this.action = action;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>This method calls {@link //execute} on the result of {@link //getAction}\n     * using the provided {@code lexer}.</p>\n     */\n    execute(lexer) {\n        // assume the input stream position was properly set by the calling code\n        this.action.execute(lexer);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.offset, this.action);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerIndexedCustomAction)) {\n            return false;\n        } else {\n            return this.offset === other.offset && this.action === other.action;\n        }\n    }\n}\n\nmodule.exports = {\n    LexerActionType,\n    LexerSkipAction,\n    LexerChannelAction,\n    LexerCustomAction,\n    LexerIndexedCustomAction,\n    LexerMoreAction,\n    LexerTypeAction,\n    LexerPushModeAction,\n    LexerPopModeAction,\n    LexerModeAction\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {hashStuff} = require(\"../Utils\");\nconst {LexerIndexedCustomAction} = require('./LexerAction');\n\nclass LexerActionExecutor {\n\t/**\n\t * Represents an executor for a sequence of lexer actions which traversed during\n\t * the matching operation of a lexer rule (token).\n\t *\n\t * <p>The executor tracks position information for position-dependent lexer actions\n\t * efficiently, ensuring that actions appearing only at the end of the rule do\n\t * not cause bloating of the {@link DFA} created for the lexer.</p>\n\t */\n\tconstructor(lexerActions) {\n\t\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t\t/**\n\t\t * Caches the result of {@link //hashCode} since the hash code is an element\n\t\t * of the performance-critical {@link LexerATNConfig//hashCode} operation\n\t\t */\n\t\tthis.cachedHashCode = hashStuff(lexerActions); // \"\".join([str(la) for la in\n\t\t// lexerActions]))\n\t\treturn this;\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which encodes the current offset\n\t * for position-dependent lexer actions.\n\t *\n\t * <p>Normally, when the executor encounters lexer actions where\n\t * {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n\t * {@link IntStream//seek} on the input {@link CharStream} to set the input\n\t * position to the <em>end</em> of the current token. This behavior provides\n\t * for efficient DFA representation of lexer actions which appear at the end\n\t * of a lexer rule, even when the lexer rule matches a variable number of\n\t * characters.</p>\n\t *\n\t * <p>Prior to traversing a match transition in the ATN, the current offset\n\t * from the token start index is assigned to all position-dependent lexer\n\t * actions which have not already been assigned a fixed offset. By storing\n\t * the offsets relative to the token start index, the DFA representation of\n\t * lexer actions which appear in the middle of tokens remains efficient due\n\t * to sharing among tokens of the same length, regardless of their absolute\n\t * position in the input stream.</p>\n\t *\n\t * <p>If the current executor already has offsets assigned to all\n\t * position-dependent lexer actions, the method returns {@code this}.</p>\n\t *\n\t * @param offset The current offset to assign to all position-dependent\n\t * lexer actions which do not already have offsets assigned.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n\t * for all position-dependent lexer actions.\n\t */\n\tfixOffsetBeforeMatch(offset) {\n\t\tlet updatedLexerActions = null;\n\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\t\tif (updatedLexerActions === null) {\n\t\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t\t}\n\t\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\t\tthis.lexerActions[i]);\n\t\t\t}\n\t\t}\n\t\tif (updatedLexerActions === null) {\n\t\t\treturn this;\n\t\t} else {\n\t\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t\t}\n\t}\n\n\t/**\n\t * Execute the actions encapsulated by this executor within the context of a\n\t * particular {@link Lexer}.\n\t *\n\t * <p>This method calls {@link IntStream//seek} to set the position of the\n\t * {@code input} {@link CharStream} prior to calling\n\t * {@link LexerAction//execute} on a position-dependent action. Before the\n\t * method returns, the input position will be restored to the same position\n\t * it was in when the method was invoked.</p>\n\t *\n\t * @param lexer The lexer instance.\n\t * @param input The input stream which is the source for the current token.\n\t * When this method is called, the current {@link IntStream//index} for\n\t * {@code input} should be the start of the following token, i.e. 1\n\t * character past the end of the current token.\n\t * @param startIndex The token start index. This value may be passed to\n\t * {@link IntStream//seek} to set the {@code input} position to the beginning\n\t * of the token.\n\t */\n\texecute(lexer, input, startIndex) {\n\t\tlet requiresSeek = false;\n\t\tconst stopIndex = input.index;\n\t\ttry {\n\t\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\t\tlet lexerAction = this.lexerActions[i];\n\t\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\t\tconst offset = lexerAction.offset;\n\t\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\t\tinput.seek(stopIndex);\n\t\t\t\t\trequiresSeek = false;\n\t\t\t\t}\n\t\t\t\tlexerAction.execute(lexer);\n\t\t\t}\n\t\t} finally {\n\t\t\tif (requiresSeek) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t}\n\t\t}\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\t\treturn false;\n\t\t} else if (this.cachedHashCode != other.cachedHashCode) {\n\t\t\treturn false;\n\t\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tconst numActions = this.lexerActions.length\n\t\t\tfor (let idx = 0; idx < numActions; ++idx) {\n\t\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which executes the actions for\n\t * the input {@code lexerActionExecutor} followed by a specified\n\t * {@code lexerAction}.\n\t *\n\t * @param lexerActionExecutor The executor for actions already traversed by\n\t * the lexer while matching a token within a particular\n\t * {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n\t * though it were an empty executor.\n\t * @param lexerAction The lexer action to execute after the actions\n\t * specified in {@code lexerActionExecutor}.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n\t * of {@code lexerActionExecutor} and {@code lexerAction}.\n\t */\n\tstatic append(lexerActionExecutor, lexerAction) {\n\t\tif (lexerActionExecutor === null) {\n\t\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t\t}\n\t\tconst lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\t\treturn new LexerActionExecutor(lexerActions);\n\t}\n}\n\n\nmodule.exports = LexerActionExecutor;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Utils = require('./../Utils');\nconst {Set, BitSet, DoubleDict} = Utils;\n\nconst ATN = require('./ATN');\nconst {ATNState, RuleStopState} = require('./ATNState');\n\nconst {ATNConfig} = require('./ATNConfig');\nconst {ATNConfigSet} = require('./ATNConfigSet');\nconst {Token} = require('./../Token');\nconst {DFAState, PredPrediction} = require('./../dfa/DFAState');\nconst ATNSimulator = require('./ATNSimulator');\nconst PredictionMode = require('./PredictionMode');\nconst RuleContext = require('./../RuleContext');\nconst ParserRuleContext = require('./../ParserRuleContext');\nconst {SemanticContext} = require('./SemanticContext');\nconst {PredictionContext} = require('./../PredictionContext');\nconst {Interval} = require('./../IntervalSet');\nconst {Transition, SetTransition, NotSetTransition, RuleTransition, ActionTransition} = require('./Transition');\nconst {NoViableAltException} = require('./../error/Errors');\nconst {SingletonPredictionContext, predictionContextFromRuleContext} = require('./../PredictionContext');\n\n\n/**\n * The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n *\n * <p>\n * The basic complexity of the adaptive strategy makes it harder to understand.\n * We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n * requests go through the DFA first. If they reach a state without an edge for\n * the current symbol, the algorithm fails over to the ATN simulation to\n * complete the DFA path for the current input (until it finds a conflict state\n * or uniquely predicting state).</p>\n *\n * <p>\n * All of that is done without using the outer context because we want to create\n * a DFA that is not dependent upon the rule invocation stack when we do a\n * prediction. One DFA works in all contexts. We avoid using context not\n * necessarily because it's slower, although it can be, but because of the DFA\n * caching problem. The closure routine only considers the rule invocation stack\n * created during prediction beginning in the decision rule. For example, if\n * prediction occurs without invoking another rule's ATN, there are no context\n * stacks in the configurations. When lack of context leads to a conflict, we\n * don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n * strategy (versus full LL(*)).</p>\n *\n * <p>\n * When SLL yields a configuration set with conflict, we rewind the input and\n * retry the ATN simulation, this time using full outer context without adding\n * to the DFA. Configuration context stacks will be the full invocation stacks\n * from the start rule. If we get a conflict using full context, then we can\n * definitively say we have a true ambiguity for that input sequence. If we\n * don't get a conflict, it implies that the decision is sensitive to the outer\n * context. (It is not context-sensitive in the sense of context-sensitive\n * grammars.)</p>\n *\n * <p>\n * The next time we reach this DFA state with an SLL conflict, through DFA\n * simulation, we will again retry the ATN simulation using full context mode.\n * This is slow because we can't save the results and have to \"interpret\" the\n * ATN each time we get that input.</p>\n *\n * <p>\n * <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n *\n * <p>\n * We could cache results from full context to predicted alternative easily and\n * that saves a lot of time but doesn't work in presence of predicates. The set\n * of visible predicates from the ATN start state changes depending on the\n * context, because closure can fall off the end of a rule. I tried to cache\n * tuples (stack context, semantic context, predicted alt) but it was slower\n * than interpreting and much more complicated. Also required a huge amount of\n * memory. The goal is not to create the world's fastest parser anyway. I'd like\n * to keep this algorithm simple. By launching multiple threads, we can improve\n * the speed of parsing across a large number of files.</p>\n *\n * <p>\n * There is no strict ordering between the amount of input used by SLL vs LL,\n * which makes it really hard to build a cache for full context. Let's say that\n * we have input A B C that leads to an SLL conflict with full context X. That\n * implies that using X we might only use A B but we could also use A B C D to\n * resolve conflict. Input A B C D could predict alternative 1 in one position\n * in the input and A B C E could predict alternative 2 in another position in\n * input. The conflicting SLL configurations could still be non-unique in the\n * full context prediction, which would lead us to requiring more input than the\n * original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n * input\tused during the previous prediction. That amounts to a cache that maps\n * X to a specific DFA for that context.</p>\n *\n * <p>\n * Something should be done for left-recursive expression predictions. They are\n * likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n * with full LL thing Sam does.</p>\n *\n * <p>\n * <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n *\n * <p>\n * We avoid doing full context retry when the outer context is empty, we did not\n * dip into the outer context by falling off the end of the decision state rule,\n * or when we force SLL mode.</p>\n *\n * <p>\n * As an example of the not dip into outer context case, consider as super\n * constructor calls versus function calls. One grammar might look like\n * this:</p>\n *\n * <pre>\n * ctorBody\n *   : '{' superCall? stat* '}'\n *   ;\n * </pre>\n *\n * <p>\n * Or, you might see something like</p>\n *\n * <pre>\n * stat\n *   : superCall ';'\n *   | expression ';'\n *   | ...\n *   ;\n * </pre>\n *\n * <p>\n * In both cases I believe that no closure operations will dip into the outer\n * context. In the first case ctorBody in the worst case will stop at the '}'.\n * In the 2nd case it should stop at the ';'. Both cases should stay within the\n * entry rule and not dip into the outer context.</p>\n *\n * <p>\n * <strong>PREDICATES</strong></p>\n *\n * <p>\n * Predicates are always evaluated if present in either SLL or LL both. SLL and\n * LL simulation deals with predicates differently. SLL collects predicates as\n * it performs closure operations like ANTLR v3 did. It delays predicate\n * evaluation until it reaches and accept state. This allows us to cache the SLL\n * ATN simulation whereas, if we had evaluated predicates on-the-fly during\n * closure, the DFA state configuration sets would be different and we couldn't\n * build up a suitable DFA.</p>\n *\n * <p>\n * When building a DFA accept state during ATN simulation, we evaluate any\n * predicates and return the sole semantically valid alternative. If there is\n * more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n * we throw an exception. Alternatives without predicates act like they have\n * true predicates. The simple way to think about it is to strip away all\n * alternatives with false predicates and choose the minimum alternative that\n * remains.</p>\n *\n * <p>\n * When we start in the DFA and reach an accept state that's predicated, we test\n * those and return the minimum semantically viable alternative. If no\n * alternatives are viable, we throw an exception.</p>\n *\n * <p>\n * During full LL ATN simulation, closure always evaluates predicates and\n * on-the-fly. This is crucial to reducing the configuration set size during\n * closure. It hits a landmine when parsing with the Java grammar, for example,\n * without this on-the-fly evaluation.</p>\n *\n * <p>\n * <strong>SHARING DFA</strong></p>\n *\n * <p>\n * All instances of the same parser share the same decision DFAs through a\n * static field. Each instance gets its own ATN simulator but they share the\n * same {@link //decisionToDFA} field. They also share a\n * {@link PredictionContextCache} object that makes sure that all\n * {@link PredictionContext} objects are shared among the DFA states. This makes\n * a big size difference.</p>\n *\n * <p>\n * <strong>THREAD SAFETY</strong></p>\n *\n * <p>\n * The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n * it adds a new DFA object to that array. {@link //addDFAEdge}\n * locks on the DFA for the current decision when setting the\n * {@link DFAState//edges} field. {@link //addDFAState} locks on\n * the DFA for the current decision when looking up a DFA state to see if it\n * already exists. We must make sure that all requests to add DFA states that\n * are equivalent result in the same shared DFA object. This is because lots of\n * threads will be trying to update the DFA at once. The\n * {@link //addDFAState} method also locks inside the DFA lock\n * but this time on the shared context cache when it rebuilds the\n * configurations' {@link PredictionContext} objects using cached\n * subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n * safe as long as we can guarantee that all threads referencing\n * {@code s.edge[t]} get the same physical target {@link DFAState}, or\n * {@code null}. Once into the DFA, the DFA simulation does not reference the\n * {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n * targets. The DFA simulator will either find {@link DFAState//edges} to be\n * {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n * {@code dfa.edges[t]} to be non-null. The\n * {@link //addDFAEdge} method could be racing to set the field\n * but in either case the DFA simulator works; if {@code null}, and requests ATN\n * simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n * way it will work because it's not doing a test and set operation.</p>\n *\n * <p>\n * <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n * Parsing)</strong></p>\n *\n * <p>\n * Sam pointed out that if SLL does not give a syntax error, then there is no\n * point in doing full LL, which is slower. We only have to try LL if we get a\n * syntax error. For maximum speed, Sam starts the parser set to pure SLL\n * mode with the {@link BailErrorStrategy}:</p>\n *\n * <pre>\n * parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n * parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n * </pre>\n *\n * <p>\n * If it does not get a syntax error, then we're done. If it does get a syntax\n * error, we need to retry with the combined SLL/LL strategy.</p>\n *\n * <p>\n * The reason this works is as follows. If there are no SLL conflicts, then the\n * grammar is SLL (at least for that input set). If there is an SLL conflict,\n * the full LL analysis must yield a set of viable alternatives which is a\n * subset of the alternatives reported by SLL. If the LL set is a singleton,\n * then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n * set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n * is truly ambiguous on the current input. If the LL set is smaller, then the\n * SLL conflict resolution might choose an alternative that the full LL would\n * rule out as a possibility based upon better context information. If that's\n * the case, then the SLL parse will definitely get an error because the full LL\n * analysis says it's not viable. If SLL conflict resolution chooses an\n * alternative within the LL set, them both SLL and LL would choose the same\n * alternative because they both choose the minimum of multiple conflicting\n * alternatives.</p>\n *\n * <p>\n * Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n * a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n * parsing will get an error because SLL will pursue alternative 1. If\n * <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n * choose the same alternative because alternative one is the minimum of either\n * set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n * error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n *\n * <p>\n * Of course, if the input is invalid, then we will get an error for sure in\n * both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n * the input.</p>\n */\nclass ParserATNSimulator extends ATNSimulator {\n    constructor(parser, atn, decisionToDFA, sharedContextCache) {\n        super(atn, sharedContextCache);\n        this.parser = parser;\n        this.decisionToDFA = decisionToDFA;\n        // SLL, LL, or LL + exact ambig detection?//\n        this.predictionMode = PredictionMode.LL;\n        // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n        this._input = null;\n        this._startIndex = 0;\n        this._outerContext = null;\n        this._dfa = null;\n        /**\n         * Each prediction operation uses a cache for merge of prediction contexts.\n         *  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n         *  isn't synchronized but we're ok since two threads shouldn't reuse same\n         *  parser/atnsim object because it can only handle one input at a time.\n         *  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n         *  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n         *  also be examined during cache lookup.\n         */\n        this.mergeCache = null;\n        this.debug = false;\n        this.debug_closure = false;\n        this.debug_add = false;\n        this.debug_list_atn_decisions = false;\n        this.dfa_debug = false;\n        this.retry_debug = false;\n    }\n\n    reset() {}\n\n    adaptivePredict(input, decision, outerContext) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"adaptivePredict decision \" + decision +\n                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                   \" line \" + input.LT(1).line + \":\" +\n                                   input.LT(1).column);\n        }\n        this._input = input;\n        this._startIndex = input.index;\n        this._outerContext = outerContext;\n\n        const dfa = this.decisionToDFA[decision];\n        this._dfa = dfa;\n        const m = input.mark();\n        const index = input.index;\n\n        // Now we are certain to have a specific decision's DFA\n        // But, do we still need an initial state?\n        try {\n            let s0;\n            if (dfa.precedenceDfa) {\n                // the start state for a precedence DFA depends on the current\n                // parser precedence, and is provided by a DFA method.\n                s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n            } else {\n                // the start state for a \"regular\" DFA is just s0\n                s0 = dfa.s0;\n            }\n            if (s0===null) {\n                if (outerContext===null) {\n                    outerContext = RuleContext.EMPTY;\n                }\n                if (this.debug || this.debug_list_atn_decisions) {\n                    console.log(\"predictATN decision \" + dfa.decision +\n                                       \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                       \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n                }\n\n                const fullCtx = false;\n                let s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n                if( dfa.precedenceDfa) {\n                    // If this is a precedence DFA, we use applyPrecedenceFilter\n                    // to convert the computed start state to a precedence start\n                    // state. We then use DFA.setPrecedenceStartState to set the\n                    // appropriate start state for the precedence level rather\n                    // than simply setting DFA.s0.\n                    //\n                    dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway\n                    s0_closure = this.applyPrecedenceFilter(s0_closure);\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n                } else {\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.s0 = s0;\n                }\n            }\n            const alt = this.execATN(dfa, s0, input, index, outerContext);\n            if (this.debug) {\n                console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames));\n            }\n            return alt;\n        } finally {\n            this._dfa = null;\n            this.mergeCache = null; // wack cache after each prediction\n            input.seek(index);\n            input.release(m);\n        }\n    }\n\n    /**\n     * Performs ATN simulation to compute a predicted alternative based\n     *  upon the remaining input, but also updates the DFA cache to avoid\n     *  having to traverse the ATN again for the same input sequence.\n     *\n     * There are some key conditions we're looking for after computing a new\n     * set of ATN configs (proposed DFA state):\n     *       if the set is empty, there is no viable alternative for current symbol\n     *       does the state uniquely predict an alternative?\n     *       does the state have a conflict that would prevent us from\n     *         putting it on the work list?\n     *\n     * We also have some key operations to do:\n     *       add an edge from previous DFA state to potentially new DFA state, D,\n     *         upon current symbol but only if adding to work list, which means in all\n     *         cases except no viable alternative (and possibly non-greedy decisions?)\n     *       collecting predicates and adding semantic context to DFA accept states\n     *       adding rule context to context-sensitive DFA accept states\n     *       consuming an input symbol\n     *       reporting a conflict\n     *       reporting an ambiguity\n     *       reporting a context sensitivity\n     *       reporting insufficient predicates\n     *\n     * cover these cases:\n     *    dead end\n     *    single alt\n     *    single alt + preds\n     *    conflict\n     *    conflict + preds\n     *\n     */\n    execATN(dfa, s0, input, startIndex, outerContext ) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"execATN decision \" + dfa.decision +\n                    \" exec LA(1)==\" + this.getLookaheadName(input) +\n                    \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n        }\n        let alt;\n        let previousD = s0;\n\n        if (this.debug) {\n            console.log(\"s0 = \" + s0);\n        }\n        let t = input.LA(1);\n        while(true) { // while more work\n            let D = this.getExistingTargetState(previousD, t);\n            if(D===null) {\n                D = this.computeTargetState(dfa, previousD, t);\n            }\n            if(D===ATNSimulator.ERROR) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for SLL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n                input.seek(startIndex);\n                alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n                // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n                let conflictingAlts = null;\n                if (D.predicates!==null) {\n                    if (this.debug) {\n                        console.log(\"DFA state has preds in DFA sim LL failover\");\n                    }\n                    const conflictIndex = input.index;\n                    if(conflictIndex !== startIndex) {\n                        input.seek(startIndex);\n                    }\n                    conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n                    if (conflictingAlts.length===1) {\n                        if(this.debug) {\n                            console.log(\"Full LL avoided\");\n                        }\n                        return conflictingAlts.minValue();\n                    }\n                    if (conflictIndex !== startIndex) {\n                        // restore the index so reporting the fallback to full\n                        // context occurs with the index at the correct spot\n                        input.seek(conflictIndex);\n                    }\n                }\n                if (this.dfa_debug) {\n                    console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n                }\n                const fullCtx = true;\n                const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n                this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n                alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n                return alt;\n            }\n            if (D.isAcceptState) {\n                if (D.predicates===null) {\n                    return D.prediction;\n                }\n                const stopIndex = input.index;\n                input.seek(startIndex);\n                const alts = this.evalSemanticContext(D.predicates, outerContext, true);\n                if (alts.length===0) {\n                    throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n                } else if (alts.length===1) {\n                    return alts.minValue();\n                } else {\n                    // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n                    this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n                    return alts.minValue();\n                }\n            }\n            previousD = D;\n\n            if (t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n    }\n\n    /**\n     * Get an existing target state for an edge in the DFA. If the target state\n     * for the edge has not yet been computed or is otherwise not available,\n     * this method returns {@code null}.\n     *\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     * @return The existing target DFA state for the given input symbol\n     * {@code t}, or {@code null} if the target state for this edge is not\n     * already cached\n     */\n    getExistingTargetState(previousD, t) {\n        const edges = previousD.edges;\n        if (edges===null) {\n            return null;\n        } else {\n            return edges[t + 1] || null;\n        }\n    }\n\n    /**\n     * Compute a target state for an edge in the DFA, and attempt to add the\n     * computed state and corresponding edge to the DFA.\n     *\n     * @param dfa The DFA\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     *\n     * @return The computed target DFA state for the given input symbol\n     * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n     * returns {@link //ERROR\n     */\n    computeTargetState(dfa, previousD, t) {\n       const reach = this.computeReachSet(previousD.configs, t, false);\n        if(reach===null) {\n            this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n            return ATNSimulator.ERROR;\n        }\n        // create new target state; we'll add to DFA after it's complete\n        let D = new DFAState(null, reach);\n\n        const predictedAlt = this.getUniqueAlt(reach);\n\n        if (this.debug) {\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            console.log(\"SLL altSubSets=\" + Utils.arrayToString(altSubSets) +\n                        \", previous=\" + previousD.configs +\n                        \", configs=\" + reach +\n                        \", predict=\" + predictedAlt +\n                        \", allSubsetsConflict=\" +\n                        PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n                        this.getConflictingAlts(reach));\n        }\n        if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n            // NO CONFLICT, UNIQUELY PREDICTED ALT\n            D.isAcceptState = true;\n            D.configs.uniqueAlt = predictedAlt;\n            D.prediction = predictedAlt;\n        } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n            // MORE THAN ONE VIABLE ALTERNATIVE\n            D.configs.conflictingAlts = this.getConflictingAlts(reach);\n            D.requiresFullContext = true;\n            // in SLL-only mode, we will stop at this state and return the minimum alt\n            D.isAcceptState = true;\n            D.prediction = D.configs.conflictingAlts.minValue();\n        }\n        if (D.isAcceptState && D.configs.hasSemanticContext) {\n            this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n            if( D.predicates!==null) {\n                D.prediction = ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        // all adds to dfa are done after we've created full D state\n        D = this.addDFAEdge(dfa, previousD, t, D);\n        return D;\n    }\n\n    predicateDFAState(dfaState, decisionState) {\n        // We need to test all predicates, even in DFA states that\n        // uniquely predict alternative.\n        const nalts = decisionState.transitions.length;\n        // Update DFA so reach becomes accept state with (predicate,alt)\n        // pairs if preds found for conflicting alts\n        const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n        const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n        if (altToPred!==null) {\n            dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n            dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n        } else {\n            // There are preds in configs but they might go away\n            // when OR'd together like {p}? || NONE == NONE. If neither\n            // alt has preds, resolve to min alt\n            dfaState.prediction = altsToCollectPredsFrom.minValue();\n        }\n    }\n\n// comes back with reach.uniqueAlt set to a valid alt\n    execATNWithFullContext(dfa, D, // how far we got before failing over\n                                         s0,\n                                         input,\n                                         startIndex,\n                                         outerContext) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"execATNWithFullContext \"+s0);\n        }\n        const fullCtx = true;\n        let foundExactAmbig = false;\n        let reach;\n        let previous = s0;\n        input.seek(startIndex);\n        let t = input.LA(1);\n        let predictedAlt = -1;\n        while (true) { // while more work\n            reach = this.computeReachSet(previous, t, fullCtx);\n            if (reach===null) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for LL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previous, startIndex);\n                input.seek(startIndex);\n                const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            if(this.debug) {\n                console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n                      PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n                      PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n            }\n            reach.uniqueAlt = this.getUniqueAlt(reach);\n            // unique prediction?\n            if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n                predictedAlt = reach.uniqueAlt;\n                break;\n            } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n                predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n                if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n                    break;\n                }\n            } else {\n                // In exact ambiguity mode, we never try to terminate early.\n                // Just keeps scarfing until we know what the conflict is\n                if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n                    foundExactAmbig = true;\n                    predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n                    break;\n                }\n                // else there are multiple non-conflicting subsets or\n                // we're not sure what the ambiguity is yet.\n                // So, keep going.\n            }\n            previous = reach;\n            if( t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n        // If the configuration set uniquely predicts an alternative,\n        // without conflict, then we know that it's a full LL decision\n        // not SLL.\n        if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n            this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n            return predictedAlt;\n        }\n        // We do not check predicates here because we have checked them\n        // on-the-fly when doing full context prediction.\n\n        //\n        // In non-exact ambiguity detection mode, we might\tactually be able to\n        // detect an exact ambiguity, but I'm not going to spend the cycles\n        // needed to check. We only emit ambiguity warnings in exact ambiguity\n        // mode.\n        //\n        // For example, we might know that we have conflicting configurations.\n        // But, that does not mean that there is no way forward without a\n        // conflict. It's possible to have nonconflicting alt subsets as in:\n\n        // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n        // from\n        //\n        //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n        //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n        //\n        // In this case, (17,1,[5 $]) indicates there is some next sequence that\n        // would resolve this without conflict to alternative 1. Any other viable\n        // next sequence, however, is associated with a conflict.  We stop\n        // looking for input because no amount of further lookahead will alter\n        // the fact that we should predict alternative 1.  We just can't say for\n        // sure that there is an ambiguity without looking further.\n\n        this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n        return predictedAlt;\n    }\n\n    computeReachSet(closure, t, fullCtx) {\n        if (this.debug) {\n            console.log(\"in computeReachSet, starting closure: \" + closure);\n        }\n        if( this.mergeCache===null) {\n            this.mergeCache = new DoubleDict();\n        }\n        const intermediate = new ATNConfigSet(fullCtx);\n\n        // Configurations already in a rule stop state indicate reaching the end\n        // of the decision rule (local context) or end of the start rule (full\n        // context). Once reached, these configurations are never updated by a\n        // closure operation, so they are handled separately for the performance\n        // advantage of having a smaller intermediate set when calling closure.\n        //\n        // For full-context reach operations, separate handling is required to\n        // ensure that the alternative matching the longest overall sequence is\n        // chosen when multiple such configurations can match the input.\n\n        let skippedStopStates = null;\n\n        // First figure out where we can reach on input t\n        for (let i=0; i<closure.items.length;i++) {\n            const c = closure.items[i];\n            if(this.debug) {\n                console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n            }\n            if (c.state instanceof RuleStopState) {\n                if (fullCtx || t === Token.EOF) {\n                    if (skippedStopStates===null) {\n                        skippedStopStates = [];\n                    }\n                    skippedStopStates.push(c);\n                    if(this.debug_add) {\n                        console.log(\"added \" + c + \" to skippedStopStates\");\n                    }\n                }\n                continue;\n            }\n            for(let j=0;j<c.state.transitions.length;j++) {\n                const trans = c.state.transitions[j];\n                const target = this.getReachableTarget(trans, t);\n                if (target!==null) {\n                    const cfg = new ATNConfig({state:target}, c);\n                    intermediate.add(cfg, this.mergeCache);\n                    if(this.debug_add) {\n                        console.log(\"added \" + cfg + \" to intermediate\");\n                    }\n                }\n            }\n        }\n        // Now figure out where the reach operation can take us...\n        let reach = null;\n\n        // This block optimizes the reach operation for intermediate sets which\n        // trivially indicate a termination state for the overall\n        // adaptivePredict operation.\n        //\n        // The conditions assume that intermediate\n        // contains all configurations relevant to the reach set, but this\n        // condition is not true when one or more configurations have been\n        // withheld in skippedStopStates, or when the current symbol is EOF.\n        //\n        if (skippedStopStates===null && t!==Token.EOF) {\n            if (intermediate.items.length===1) {\n                // Don't pursue the closure if there is just one state.\n                // It can only have one alternative; just add to result\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            }\n        }\n        // If the reach set could not be trivially determined, perform a closure\n        // operation on the intermediate set to compute its initial value.\n        //\n        if (reach===null) {\n            reach = new ATNConfigSet(fullCtx);\n            const closureBusy = new Set();\n            const treatEofAsEpsilon = t === Token.EOF;\n            for (let k=0; k<intermediate.items.length;k++) {\n                this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n            }\n        }\n        if (t === Token.EOF) {\n            // After consuming EOF no additional input is possible, so we are\n            // only interested in configurations which reached the end of the\n            // decision rule (local context) or end of the start rule (full\n            // context). Update reach to contain only these configurations. This\n            // handles both explicit EOF transitions in the grammar and implicit\n            // EOF transitions following the end of the decision or start rule.\n            //\n            // When reach==intermediate, no closure operation was performed. In\n            // this case, removeAllConfigsNotInRuleStopState needs to check for\n            // reachable rule stop states as well as configurations already in\n            // a rule stop state.\n            //\n            // This is handled before the configurations in skippedStopStates,\n            // because any configurations potentially added from that list are\n            // already guaranteed to meet this condition whether or not it's\n            // required.\n            //\n            reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n        }\n        // If skippedStopStates!==null, then it contains at least one\n        // configuration. For full-context reach operations, these\n        // configurations reached the end of the start rule, in which case we\n        // only add them back to reach if no configuration during the current\n        // closure operation reached such a state. This ensures adaptivePredict\n        // chooses an alternative matching the longest overall sequence when\n        // multiple alternatives are viable.\n        //\n        if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n            for (let l=0; l<skippedStopStates.length;l++) {\n                reach.add(skippedStopStates[l], this.mergeCache);\n            }\n        }\n        if (reach.items.length===0) {\n            return null;\n        } else {\n            return reach;\n        }\n    }\n\n    /**\n     * Return a configuration set containing only the configurations from\n     * {@code configs} which are in a {@link RuleStopState}. If all\n     * configurations in {@code configs} are already in a rule stop state, this\n     * method simply returns {@code configs}.\n     *\n     * <p>When {@code lookToEndOfRule} is true, this method uses\n     * {@link ATN//nextTokens} for each configuration in {@code configs} which is\n     * not already in a rule stop state to see if a rule stop state is reachable\n     * from the configuration via epsilon-only transitions.</p>\n     *\n     * @param configs the configuration set to update\n     * @param lookToEndOfRule when true, this method checks for rule stop states\n     * reachable by epsilon-only transitions from each configuration in\n     * {@code configs}.\n     *\n     * @return {@code configs} if all configurations in {@code configs} are in a\n     * rule stop state, otherwise return a new configuration set containing only\n     * the configurations from {@code configs} which are in a rule stop state\n     */\n    removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return configs;\n        }\n        const result = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length;i++) {\n            const config = configs.items[i];\n            if (config.state instanceof RuleStopState) {\n                result.add(config, this.mergeCache);\n                continue;\n            }\n            if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n                const nextTokens = this.atn.nextTokens(config.state);\n                if (nextTokens.contains(Token.EPSILON)) {\n                    const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n                    result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n                }\n            }\n        }\n        return result;\n    }\n\n    computeStartState(p, ctx, fullCtx) {\n        // always at least the implicit call to start rule\n        const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n        const configs = new ATNConfigSet(fullCtx);\n        for(let i=0;i<p.transitions.length;i++) {\n            const target = p.transitions[i].target;\n            const c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n            const closureBusy = new Set();\n            this.closure(c, configs, closureBusy, true, fullCtx, false);\n        }\n        return configs;\n    }\n\n    /**\n     * This method transforms the start state computed by\n     * {@link //computeStartState} to the special start state used by a\n     * precedence DFA for a particular precedence value. The transformation\n     * process applies the following changes to the start state's configuration\n     * set.\n     *\n     * <ol>\n     * <li>Evaluate the precedence predicates for each configuration using\n     * {@link SemanticContext//evalPrecedence}.</li>\n     * <li>Remove all configurations which predict an alternative greater than\n     * 1, for which another configuration that predicts alternative 1 is in the\n     * same ATN state with the same prediction context. This transformation is\n     * valid for the following reasons:\n     * <ul>\n     * <li>The closure block cannot contain any epsilon transitions which bypass\n     * the body of the closure, so all states reachable via alternative 1 are\n     * part of the precedence alternatives of the transformed left-recursive\n     * rule.</li>\n     * <li>The \"primary\" portion of a left recursive rule cannot contain an\n     * epsilon transition, so the only way an alternative other than 1 can exist\n     * in a state that is also reachable via alternative 1 is by nesting calls\n     * to the left-recursive rule, with the outer calls not being at the\n     * preferred precedence level.</li>\n     * </ul>\n     * </li>\n     * </ol>\n     *\n     * <p>\n     * The prediction context must be considered by this filter to address\n     * situations like the following.\n     * </p>\n     * <code>\n     * <pre>\n     * grammar TA;\n     * prog: statement* EOF;\n     * statement: letterA | statement letterA 'b' ;\n     * letterA: 'a';\n     * </pre>\n     * </code>\n     * <p>\n     * If the above grammar, the ATN state immediately before the token\n     * reference {@code 'a'} in {@code letterA} is reachable from the left edge\n     * of both the primary and closure blocks of the left-recursive rule\n     * {@code statement}. The prediction context associated with each of these\n     * configurations distinguishes between them, and prevents the alternative\n     * which stepped out to {@code prog} (and then back in to {@code statement}\n     * from being eliminated by the filter.\n     * </p>\n     *\n     * @param configs The configuration set computed by\n     * {@link //computeStartState} as the start state for the DFA.\n     * @return The transformed configuration set representing the start state\n     * for a precedence DFA at a particular precedence level (determined by\n     * calling {@link Parser//getPrecedence})\n     */\n    applyPrecedenceFilter(configs) {\n        let config;\n        const statesFromAlt1 = [];\n        const configSet = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            // handle alt 1 first\n            if (config.alt !== 1) {\n                continue;\n            }\n            const updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n            if (updatedContext===null) {\n                // the configuration was eliminated\n                continue;\n            }\n            statesFromAlt1[config.state.stateNumber] = config.context;\n            if (updatedContext !== config.semanticContext) {\n                configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n            } else {\n                configSet.add(config, this.mergeCache);\n            }\n        }\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            if (config.alt === 1) {\n                // already handled\n                continue;\n            }\n            // In the future, this elimination step could be updated to also\n            // filter the prediction context for alternatives predicting alt>1\n            // (basically a graph subtraction algorithm).\n            if (!config.precedenceFilterSuppressed) {\n                const context = statesFromAlt1[config.state.stateNumber] || null;\n                if (context!==null && context.equals(config.context)) {\n                    // eliminated\n                    continue;\n                }\n            }\n            configSet.add(config, this.mergeCache);\n        }\n        return configSet;\n    }\n\n    getReachableTarget(trans, ttype) {\n        if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n            return trans.target;\n        } else {\n            return null;\n        }\n    }\n\n    getPredsForAmbigAlts(ambigAlts, configs, nalts) {\n        // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n        // altToPred starts as an array of all null contexts. The entry at index i\n        // corresponds to alternative i. altToPred[i] may have one of three values:\n        //   1. null: no ATNConfig c is found such that c.alt==i\n        //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n        //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n        //      alt i has at least one unpredicated config.\n        //   3. Non-NONE Semantic Context: There exists at least one, and for all\n        //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n        //\n        // From this, it is clear that NONE||anything==NONE.\n        //\n        let altToPred = [];\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if(ambigAlts.contains( c.alt )) {\n                altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n            }\n        }\n        let nPredAlts = 0;\n        for (let i =1;i< nalts+1;i++) {\n            const pred = altToPred[i] || null;\n            if (pred===null) {\n                altToPred[i] = SemanticContext.NONE;\n            } else if (pred !== SemanticContext.NONE) {\n                nPredAlts += 1;\n            }\n        }\n        // nonambig alts are null in altToPred\n        if (nPredAlts===0) {\n            altToPred = null;\n        }\n        if (this.debug) {\n            console.log(\"getPredsForAmbigAlts result \" + Utils.arrayToString(altToPred));\n        }\n        return altToPred;\n    }\n\n    getPredicatePredictions(ambigAlts, altToPred) {\n        const pairs = [];\n        let containsPredicate = false;\n        for (let i=1; i<altToPred.length;i++) {\n            const pred = altToPred[i];\n            // unpredicated is indicated by SemanticContext.NONE\n            if( ambigAlts!==null && ambigAlts.contains( i )) {\n                pairs.push(new PredPrediction(pred, i));\n            }\n            if (pred !== SemanticContext.NONE) {\n                containsPredicate = true;\n            }\n        }\n        if (! containsPredicate) {\n            return null;\n        }\n        return pairs;\n    }\n\n    /**\n     * This method is used to improve the localization of error messages by\n     * choosing an alternative rather than throwing a\n     * {@link NoViableAltException} in particular prediction scenarios where the\n     * {@link //ERROR} state was reached during ATN simulation.\n     *\n     * <p>\n     * The default implementation of this method uses the following\n     * algorithm to identify an ATN configuration which successfully parsed the\n     * decision entry rule. Choosing such an alternative ensures that the\n     * {@link ParserRuleContext} returned by the calling rule will be complete\n     * and valid, and the syntax error will be reported later at a more\n     * localized location.</p>\n     *\n     * <ul>\n     * <li>If a syntactically valid path or paths reach the end of the decision rule and\n     * they are semantically valid if predicated, return the min associated alt.</li>\n     * <li>Else, if a semantically invalid but syntactically valid path exist\n     * or paths exist, return the minimum associated alt.\n     * </li>\n     * <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n     * </ul>\n     *\n     * <p>\n     * In some scenarios, the algorithm described above could predict an\n     * alternative which will result in a {@link FailedPredicateException} in\n     * the parser. Specifically, this could occur if the <em>only</em> configuration\n     * capable of successfully parsing to the end of the decision rule is\n     * blocked by a semantic predicate. By choosing this alternative within\n     * {@link //adaptivePredict} instead of throwing a\n     * {@link NoViableAltException}, the resulting\n     * {@link FailedPredicateException} in the parser will identify the specific\n     * predicate which is preventing the parser from successfully parsing the\n     * decision rule, which helps developers identify and correct logic errors\n     * in semantic predicates.\n     * </p>\n     *\n     * @param configs The ATN configurations which were valid immediately before\n     * the {@link //ERROR} state was reached\n     * @param outerContext The is the \\gamma_0 initial parser context from the paper\n     * or the parser stack at the instant before prediction commences.\n     *\n     * @return The value to return from {@link //adaptivePredict}, or\n     * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n     * identified and {@link //adaptivePredict} should report an error instead\n     */\n    getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n        const cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n        const semValidConfigs = cfgs[0];\n        const semInvalidConfigs = cfgs[1];\n        let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n        if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n            return alt;\n        }\n        // Is there a syntactically valid path with a failed pred?\n        if (semInvalidConfigs.items.length>0) {\n            alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n            if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n                return alt;\n            }\n        }\n        return ATN.INVALID_ALT_NUMBER;\n    }\n\n    getAltThatFinishedDecisionEntryRule(configs) {\n        const alts = [];\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n                if(alts.indexOf(c.alt)<0) {\n                    alts.push(c.alt);\n                }\n            }\n        }\n        if (alts.length===0) {\n            return ATN.INVALID_ALT_NUMBER;\n        } else {\n            return Math.min.apply(null, alts);\n        }\n    }\n\n    /**\n     * Walk the list of configurations and split them according to\n     * those that have preds evaluating to true/false.  If no pred, assume\n     * true pred and include in succeeded set.  Returns Pair of sets.\n     *\n     * Create a new set so as not to alter the incoming parameter.\n     *\n     * Assumption: the input stream has been restored to the starting point\n     * prediction, which is where predicates need to evaluate.*/\n    splitAccordingToSemanticValidity( configs, outerContext) {\n        const succeeded = new ATNConfigSet(configs.fullCtx);\n        const failed = new ATNConfigSet(configs.fullCtx);\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.semanticContext !== SemanticContext.NONE) {\n                const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n                if (predicateEvaluationResult) {\n                    succeeded.add(c);\n                } else {\n                    failed.add(c);\n                }\n            } else {\n                succeeded.add(c);\n            }\n        }\n        return [succeeded, failed];\n    }\n\n    /**\n     * Look through a list of predicate/alt pairs, returning alts for the\n     * pairs that win. A {@code NONE} predicate indicates an alt containing an\n     * unpredicated config which behaves as \"always true.\" If !complete\n     * then we stop at the first predicate that evaluates to true. This\n     * includes pairs with null predicates.\n     */\n    evalSemanticContext(predPredictions, outerContext, complete) {\n        const predictions = new BitSet();\n        for(let i=0;i<predPredictions.length;i++) {\n            const pair = predPredictions[i];\n            if (pair.pred === SemanticContext.NONE) {\n                predictions.add(pair.alt);\n                if (! complete) {\n                    break;\n                }\n                continue;\n            }\n            const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n            if (this.debug || this.dfa_debug) {\n                console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n            }\n            if (predicateEvaluationResult) {\n                if (this.debug || this.dfa_debug) {\n                    console.log(\"PREDICT \" + pair.alt);\n                }\n                predictions.add(pair.alt);\n                if (! complete) {\n                    break;\n                }\n            }\n        }\n        return predictions;\n    }\n\n// TODO: If we are doing predicates, there is no point in pursuing\n//     closure operations if we reach a DFA state that uniquely predicts\n//     alternative. We will not be caching that DFA state and it is a\n//     waste to pursue the closure. Might have to advance when we do\n//     ambig detection thought :(\n//\n    closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n        const initialDepth = 0;\n        this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n                                 fullCtx, initialDepth, treatEofAsEpsilon);\n    }\n\n    closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        if (this.debug || this.debug_closure) {\n            console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n            // console.log(\"configs(\" + configs.toString() + \")\");\n            if(config.reachesIntoOuterContext>50) {\n                throw \"problem\";\n            }\n        }\n        if (config.state instanceof RuleStopState) {\n            // We hit rule end. If we have context info, use it\n            // run thru all possible stack tops in ctx\n            if (! config.context.isEmpty()) {\n                for (let i =0; i<config.context.length; i++) {\n                    if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n                        if (fullCtx) {\n                            configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n                            continue;\n                        } else {\n                            // we have no context info, just chase follow links (if greedy)\n                            if (this.debug) {\n                                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                            }\n                            this.closure_(config, configs, closureBusy, collectPredicates,\n                                     fullCtx, depth, treatEofAsEpsilon);\n                        }\n                        continue;\n                    }\n                    const returnState = this.atn.states[config.context.getReturnState(i)];\n                    const newContext = config.context.getParent(i); // \"pop\" return state\n                    const parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n                    const c = new ATNConfig(parms, null);\n                    // While we have context to pop back from, we may have\n                    // gotten that context AFTER having falling off a rule.\n                    // Make sure we track that we are now out of context.\n                    c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n                    this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n                }\n                return;\n            } else if( fullCtx) {\n                // reached end of start rule\n                configs.add(config, this.mergeCache);\n                return;\n            } else {\n                // else if we have no context info, just chase follow links (if greedy)\n                if (this.debug) {\n                    console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                }\n            }\n        }\n        this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n    }\n\n    // Do the actual work of walking epsilon edges//\n    closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        const p = config.state;\n        // optimization\n        if (! p.epsilonOnlyTransitions) {\n            configs.add(config, this.mergeCache);\n            // make sure to not return here, because EOF transitions can act as\n            // both epsilon transitions and non-epsilon transitions.\n        }\n        for(let i = 0;i<p.transitions.length; i++) {\n            if(i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))\n                continue;\n\n            const t = p.transitions[i];\n            const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n            const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n            if (c!==null) {\n                let newDepth = depth;\n                if ( config.state instanceof RuleStopState) {\n                    // target fell off end of rule; mark resulting c as having dipped into outer context\n                    // We can't get here if incoming config was rule stop and we had context\n                    // track how far we dip into outer context.  Might\n                    // come in handy and we avoid evaluating context dependent\n                    // preds if this is > 0.\n                    if (this._dfa !== null && this._dfa.precedenceDfa) {\n                        if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n                            c.precedenceFilterSuppressed = true;\n                        }\n                    }\n\n                    c.reachesIntoOuterContext += 1;\n                    if (closureBusy.add(c)!==c) {\n                        // avoid infinite recursion for right-recursive rules\n                        continue;\n                    }\n                    configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n                    newDepth -= 1;\n                    if (this.debug) {\n                        console.log(\"dips into outer ctx: \" + c);\n                    }\n                } else {\n                    if (!t.isEpsilon && closureBusy.add(c)!==c){\n                        // avoid infinite recursion for EOF* and EOF+\n                        continue;\n                    }\n                    if (t instanceof RuleTransition) {\n                        // latch when newDepth goes negative - once we step out of the entry context we can't return\n                        if (newDepth >= 0) {\n                            newDepth += 1;\n                        }\n                    }\n                }\n                this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n            }\n        }\n    }\n\n    canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n        // return False\n        const p = config.state;\n        // First check to see if we are in StarLoopEntryState generated during\n        // left-recursion elimination. For efficiency, also check if\n        // the context has an empty stack case. If so, it would mean\n        // global FOLLOW so we can't perform optimization\n        // Are we the special loop entry/exit state? or SLL wildcard\n        if(p.stateType !== ATNState.STAR_LOOP_ENTRY)\n            return false;\n        if(p.stateType !== ATNState.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||\n               config.context.isEmpty() || config.context.hasEmptyPath())\n            return false;\n\n        // Require all return states to return back to the same rule that p is in.\n        const numCtxs = config.context.length;\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            if (returnState.ruleIndex !== p.ruleIndex)\n                return false;\n        }\n\n        const decisionStartState = p.transitions[0].target;\n        const blockEndStateNum = decisionStartState.endState.stateNumber;\n        const blockEndState = this.atn.states[blockEndStateNum];\n\n        // Verify that the top of each stack context leads to loop entry/exit\n        // state through epsilon edges and w/o leaving rule.\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnStateNumber = config.context.getReturnState(i);\n            const returnState = this.atn.states[returnStateNumber];\n            // all states must have single outgoing epsilon edge\n            if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon)\n                return false;\n\n            // Look for prefix op case like 'not expr', (' type ')' expr\n            const returnStateTarget = returnState.transitions[0].target;\n            if ( returnState.stateType === ATNState.BLOCK_END && returnStateTarget === p )\n                continue;\n\n            // Look for 'expr op expr' or case where expr's return state is block end\n            // of (...)* internal block; the block end points to loop back\n            // which points to p but we don't need to check that\n            if ( returnState === blockEndState )\n                continue;\n\n            // Look for ternary expr ? expr : expr. The return state points at block end,\n            // which points at loop entry state\n            if ( returnStateTarget === blockEndState )\n                continue;\n\n            // Look for complex prefix 'between expr and expr' case where 2nd expr's\n            // return state points at block end state of (...)* internal block\n            if (returnStateTarget.stateType === ATNState.BLOCK_END && returnStateTarget.transitions.length === 1\n                    && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target === p)\n                continue;\n\n            // anything else ain't conforming\n            return false;\n        }\n        return true;\n    }\n\n    getRuleName(index) {\n        if (this.parser!==null && index>=0) {\n            return this.parser.ruleNames[index];\n        } else {\n            return \"<rule \" + index + \">\";\n        }\n    }\n\n    getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n        switch(t.serializationType) {\n        case Transition.RULE:\n            return this.ruleTransition(config, t);\n        case Transition.PRECEDENCE:\n            return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.PREDICATE:\n            return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.ACTION:\n            return this.actionTransition(config, t);\n        case Transition.EPSILON:\n            return new ATNConfig({state:t.target}, config);\n        case Transition.ATOM:\n        case Transition.RANGE:\n        case Transition.SET:\n            // EOF transitions act like epsilon transitions after the first EOF\n            // transition is traversed\n            if (treatEofAsEpsilon) {\n                if (t.matches(Token.EOF, 0, 1)) {\n                    return new ATNConfig({state: t.target}, config);\n                }\n            }\n            return null;\n        default:\n            return null;\n        }\n    }\n\n    actionTransition(config, t) {\n        if (this.debug) {\n            const index = t.actionIndex === -1 ? 65535 : t.actionIndex;\n            console.log(\"ACTION edge \" + t.ruleIndex + \":\" + index);\n        }\n        return new ATNConfig({state:t.target}, config);\n    }\n\n    precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n                    pt.precedence + \">=_p, ctx dependent=true\");\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && inContext) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n                    \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    ruleTransition(config, t) {\n        if (this.debug) {\n            console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n        }\n        const returnState = t.followState;\n        const newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n        return new ATNConfig({state:t.target, context:newContext}, config );\n    }\n\n    getConflictingAlts(configs) {\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.getAlts(altsets);\n    }\n\n    /**\n     * Sam pointed out a problem with the previous definition, v3, of\n     * ambiguous states. If we have another state associated with conflicting\n     * alternatives, we should keep going. For example, the following grammar\n     *\n     * s : (ID | ID ID?) ';' ;\n     *\n     * When the ATN simulation reaches the state before ';', it has a DFA\n     * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n     * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n     * because alternative to has another way to continue, via [6|2|[]].\n     * The key is that we have a single state that has config's only associated\n     * with a single alternative, 2, and crucially the state transitions\n     * among the configurations are all non-epsilon transitions. That means\n     * we don't consider any conflicts that include alternative 2. So, we\n     * ignore the conflict between alts 1 and 2. We ignore a set of\n     * conflicting alts when there is an intersection with an alternative\n     * associated with a single alt state in the state&rarr;config-list map.\n     *\n     * It's also the case that we might have two conflicting configurations but\n     * also a 3rd nonconflicting configuration for a different alternative:\n     * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n     *\n     * a : A | A | A B ;\n     *\n     * After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not\n     * stop working on this state. In the previous example, we're concerned\n     * with states associated with the conflicting alternatives. Here alt\n     * 3 is not associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, I don't declare the state done. We\n     * ignore a set of conflicting alts when we have an alternative\n     * that we still need to pursue\n     */\n    getConflictingAltsOrUniqueAlt(configs) {\n        let conflictingAlts = null;\n        if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n            conflictingAlts = new BitSet();\n            conflictingAlts.add(configs.uniqueAlt);\n        } else {\n            conflictingAlts = configs.conflictingAlts;\n        }\n        return conflictingAlts;\n    }\n\n    getTokenName(t) {\n        if (t===Token.EOF) {\n            return \"EOF\";\n        }\n        if( this.parser!==null && this.parser.literalNames!==null) {\n            if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {\n                console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n                console.log(\"\" + this.parser.getInputStream().getTokens());\n            } else {\n                const name = this.parser.literalNames[t] || this.parser.symbolicNames[t];\n                return name + \"<\" + t + \">\";\n            }\n        }\n        return \"\" + t;\n    }\n\n    getLookaheadName(input) {\n        return this.getTokenName(input.LA(1));\n    }\n\n    /**\n     * Used for debugging in adaptivePredict around execATN but I cut\n     * it out for clarity now that alg. works well. We can leave this\n     * \"dead\" code for a bit\n     */\n    dumpDeadEndConfigs(nvae) {\n        console.log(\"dead end configs: \");\n        const decs = nvae.getDeadEndConfigs();\n        for(let i=0; i<decs.length; i++) {\n            const c = decs[i];\n            let trans = \"no edges\";\n            if (c.state.transitions.length>0) {\n                const t = c.state.transitions[0];\n                if (t instanceof AtomTransition) {\n                    trans = \"Atom \"+ this.getTokenName(t.label);\n                } else if (t instanceof SetTransition) {\n                    const neg = (t instanceof NotSetTransition);\n                    trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n                }\n            }\n            console.error(c.toString(this.parser, true) + \":\" + trans);\n        }\n    }\n\n    noViableAlt(input, outerContext, configs, startIndex) {\n        return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n    }\n\n    getUniqueAlt(configs) {\n        let alt = ATN.INVALID_ALT_NUMBER;\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (alt === ATN.INVALID_ALT_NUMBER) {\n                alt = c.alt // found first alt\n            } else if( c.alt!==alt) {\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return alt;\n    }\n\n    /**\n     * Add an edge to the DFA, if possible. This method calls\n     * {@link //addDFAState} to ensure the {@code to} state is present in the\n     * DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n     * range of edges that can be represented in the DFA tables, this method\n     * returns without adding the edge to the DFA.\n     *\n     * <p>If {@code to} is {@code null}, this method returns {@code null}.\n     * Otherwise, this method returns the {@link DFAState} returned by calling\n     * {@link //addDFAState} for the {@code to} state.</p>\n     *\n     * @param dfa The DFA\n     * @param from_ The source state for the edge\n     * @param t The input symbol\n     * @param to The target state for the edge\n     *\n     * @return If {@code to} is {@code null}, this method returns {@code null};\n     * otherwise this method returns the result of calling {@link //addDFAState}\n     * on {@code to}\n     */\n    addDFAEdge(dfa, from_, t, to) {\n        if( this.debug) {\n            console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n        }\n        if (to===null) {\n            return null;\n        }\n        to = this.addDFAState(dfa, to); // used existing if possible not incoming\n        if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n            return to;\n        }\n        if (from_.edges===null) {\n            from_.edges = [];\n        }\n        from_.edges[t+1] = to; // connect\n\n        if (this.debug) {\n            const literalNames = this.parser===null ? null : this.parser.literalNames;\n            const symbolicNames = this.parser===null ? null : this.parser.symbolicNames;\n            console.log(\"DFA=\\n\" + dfa.toString(literalNames, symbolicNames));\n        }\n        return to;\n    }\n\n    /**\n     * Add state {@code D} to the DFA if it is not already present, and return\n     * the actual instance stored in the DFA. If a state equivalent to {@code D}\n     * is already in the DFA, the existing state is returned. Otherwise this\n     * method returns {@code D} after adding it to the DFA.\n     *\n     * <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n     * does not change the DFA.</p>\n     *\n     * @param dfa The dfa\n     * @param D The DFA state to add\n     * @return The state stored in the DFA. This will be either the existing\n     * state if {@code D} is already in the DFA, or {@code D} itself if the\n     * state was not already present\n     */\n    addDFAState(dfa, D) {\n        if (D === ATNSimulator.ERROR) {\n            return D;\n        }\n        const existing = dfa.states.get(D);\n        if(existing!==null) {\n            return existing;\n        }\n        D.stateNumber = dfa.states.length;\n        if (! D.configs.readOnly) {\n            D.configs.optimizeConfigs(this);\n            D.configs.setReadonly(true);\n        }\n        dfa.states.add(D);\n        if (this.debug) {\n            console.log(\"adding new DFA state: \" + D);\n        }\n        return D;\n    }\n\n    reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n        }\n    }\n\n    reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n        }\n    }\n\n    // If context sensitive parsing, we know it's ambiguity not conflict//\n    reportAmbiguity(dfa, D, startIndex, stopIndex,\n                                   exact, ambigAlts, configs ) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n        }\n    }\n}\n\nmodule.exports = ParserATNSimulator;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Map, BitSet, AltDict, hashStuff} = require('./../Utils');\nconst ATN = require('./ATN');\nconst {RuleStopState} = require('./ATNState');\nconst {ATNConfigSet} = require('./ATNConfigSet');\nconst {ATNConfig} = require('./ATNConfig');\nconst {SemanticContext} = require('./SemanticContext');\n\n/**\n * This enumeration defines the prediction modes available in ANTLR 4 along with\n * utility methods for analyzing configuration sets for conflicts and/or\n * ambiguities.\n */\nconst PredictionMode = {\n    /**\n     * The SLL(*) prediction mode. This prediction mode ignores the current\n     * parser context when making predictions. This is the fastest prediction\n     * mode, and provides correct results for many grammars. This prediction\n     * mode is more powerful than the prediction mode provided by ANTLR 3, but\n     * may result in syntax errors for grammar and input combinations which are\n     * not SLL.\n     *\n     * <p>\n     * When using this prediction mode, the parser will either return a correct\n     * parse tree (i.e. the same parse tree that would be returned with the\n     * {@link //LL} prediction mode), or it will report a syntax error. If a\n     * syntax error is encountered when using the {@link //SLL} prediction mode,\n     * it may be due to either an actual syntax error in the input or indicate\n     * that the particular combination of grammar and input requires the more\n     * powerful {@link //LL} prediction abilities to complete successfully.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    SLL: 0,\n\n    /**\n     * The LL(*) prediction mode. This prediction mode allows the current parser\n     * context to be used for resolving SLL conflicts that occur during\n     * prediction. This is the fastest prediction mode that guarantees correct\n     * parse results for all combinations of grammars with syntactically correct\n     * inputs.\n     *\n     * <p>\n     * When using this prediction mode, the parser will make correct decisions\n     * for all syntactically-correct grammar and input combinations. However, in\n     * cases where the grammar is truly ambiguous this prediction mode might not\n     * report a precise answer for <em>exactly which</em> alternatives are\n     * ambiguous.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL: 1,\n\n    /**\n     *\n     * The LL(*) prediction mode with exact ambiguity detection. In addition to\n     * the correctness guarantees provided by the {@link //LL} prediction mode,\n     * this prediction mode instructs the prediction algorithm to determine the\n     * complete and exact set of ambiguous alternatives for every ambiguous\n     * decision encountered while parsing.\n     *\n     * <p>\n     * This prediction mode may be used for diagnosing ambiguities during\n     * grammar development. Due to the performance overhead of calculating sets\n     * of ambiguous alternatives, this prediction mode should be avoided when\n     * the exact results are not necessary.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL_EXACT_AMBIG_DETECTION: 2,\n\n    /**\n     *\n     * Computes the SLL prediction termination condition.\n     *\n     * <p>\n     * This method computes the SLL prediction termination condition for both of\n     * the following cases.</p>\n     *\n     * <ul>\n     * <li>The usual SLL+LL fallback upon SLL conflict</li>\n     * <li>Pure SLL without LL fallback</li>\n     * </ul>\n     *\n     * <p><strong>COMBINED SLL+LL PARSING</strong></p>\n     *\n     * <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n     * ensured regardless of how the termination condition is computed by this\n     * method. Due to the substantially higher cost of LL prediction, the\n     * prediction should only fall back to LL when the additional lookahead\n     * cannot lead to a unique SLL prediction.</p>\n     *\n     * <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n     * conflicting subsets should fall back to full LL, even if the\n     * configuration sets don't resolve to the same alternative (e.g.\n     * {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n     * configuration, SLL could continue with the hopes that more lookahead will\n     * resolve via one of those non-conflicting configurations.</p>\n     *\n     * <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n     * stops when it sees only conflicting configuration subsets. In contrast,\n     * full LL keeps going when there is uncertainty.</p>\n     *\n     * <p><strong>HEURISTIC</strong></p>\n     *\n     * <p>As a heuristic, we stop prediction when we see any conflicting subset\n     * unless we see a state that only has one alternative associated with it.\n     * The single-alt-state thing lets prediction continue upon rules like\n     * (otherwise, it would admit defeat too soon):</p>\n     *\n     * <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n     *\n     * <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n     * DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n     * {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n     * processing this node because alternative to has another way to continue,\n     * via {@code [6|2|[]]}.</p>\n     *\n     * <p>It also let's us continue for this rule:</p>\n     *\n     * <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n     *\n     * <p>After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not stop\n     * working on this state. In the previous example, we're concerned with\n     * states associated with the conflicting alternatives. Here alt 3 is not\n     * associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, don't declare the state done.</p>\n     *\n     * <p><strong>PURE SLL PARSING</strong></p>\n     *\n     * <p>To handle pure SLL parsing, all we have to do is make sure that we\n     * combine stack contexts for configurations that differ only by semantic\n     * predicate. From there, we can do the usual SLL termination heuristic.</p>\n     *\n     * <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n     *\n     * <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n     * states because they need to create the DFA cache that works in all\n     * semantic situations. In contrast, full LL evaluates predicates collected\n     * during start state computation so it can ignore predicates thereafter.\n     * This means that SLL termination detection can totally ignore semantic\n     * predicates.</p>\n     *\n     * <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n     * semantic predicate contexts so we might see two configurations like the\n     * following.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n     *\n     * <p>Before testing these configurations against others, we have to merge\n     * {@code x} and {@code x'} (without modifying the existing configurations).\n     * For example, we test {@code (x+x')==x''} when looking for conflicts in\n     * the following configurations.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n     *\n     * <p>If the configuration set has predicates (as indicated by\n     * {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n     * the configurations to strip out all of the predicates so that a standard\n     * {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n     */\n    hasSLLConflictTerminatingPrediction: function( mode, configs) {\n        // Configs in rule stop states indicate reaching the end of the decision\n        // rule (local context) or end of start rule (full context). If all\n        // configs meet this condition, then none of the configurations is able\n        // to match additional input so we terminate prediction.\n        //\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return true;\n        }\n        // pure SLL mode parsing\n        if (mode === PredictionMode.SLL) {\n            // Don't bother with combining configs from different semantic\n            // contexts if we can fail over to full LL; costs more time\n            // since we'll often fail over anyway.\n            if (configs.hasSemanticContext) {\n                // dup configs, tossing out semantic predicates\n                const dup = new ATNConfigSet();\n                for(let i=0;i<configs.items.length;i++) {\n                    let c = configs.items[i];\n                    c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n                    dup.add(c);\n                }\n                configs = dup;\n            }\n            // now we have combined contexts for configs with dissimilar preds\n        }\n        // pure SLL or combined SLL+LL mode parsing\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n    },\n\n    /**\n     * Checks if any configuration in {@code configs} is in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if any configuration in {@code configs} is in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    hasConfigInRuleStopState: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (c.state instanceof RuleStopState) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    /**\n     * Checks if all configurations in {@code configs} are in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if all configurations in {@code configs} are in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    allConfigsInRuleStopStates: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (!(c.state instanceof RuleStopState)) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n    /**\n     *\n     * Full LL prediction termination.\n     *\n     * <p>Can we stop looking ahead during ATN simulation or is there some\n     * uncertainty as to which alternative we will ultimately pick, after\n     * consuming more input? Even if there are partial conflicts, we might know\n     * that everything is going to resolve to the same minimum alternative. That\n     * means we can stop since no more lookahead will change that fact. On the\n     * other hand, there might be multiple conflicts that resolve to different\n     * minimums. That means we need more look ahead to decide which of those\n     * alternatives we should predict.</p>\n     *\n     * <p>The basic idea is to split the set of configurations {@code C}, into\n     * conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n     * non-conflicting configurations. Two configurations conflict if they have\n     * identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n     * but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n     * and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n     *\n     * <p>Reduce these configuration subsets to the set of possible alternatives.\n     * You can compute the alternative subsets in one pass as follows:</p>\n     *\n     * <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n     * {@code C} holding {@code s} and {@code ctx} fixed.</p>\n     *\n     * <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     *\n     * <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n     *\n     * <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n     * {@code s} and {@code ctx}.</p>\n     *\n     * <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n     * the union of these alternative subsets is a singleton, then no amount of\n     * more lookahead will help us. We will always pick that alternative. If,\n     * however, there is more than one alternative, then we are uncertain which\n     * alternative to predict and must continue looking for resolution. We may\n     * or may not discover an ambiguity in the future, even if there are no\n     * conflicting subsets this round.</p>\n     *\n     * <p>The biggest sin is to terminate early because it means we've made a\n     * decision but were uncertain as to the eventual outcome. We haven't used\n     * enough lookahead. On the other hand, announcing a conflict too late is no\n     * big deal; you will still have the conflict. It's just inefficient. It\n     * might even look until the end of file.</p>\n     *\n     * <p>No special consideration for semantic predicates is required because\n     * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n     * no configuration contains a semantic context during the termination\n     * check.</p>\n     *\n     * <p><strong>CONFLICTING CONFIGS</strong></p>\n     *\n     * <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n     * when {@code i!=j} but {@code x=x'}. Because we merge all\n     * {@code (s, i, _)} configurations together, that means that there are at\n     * most {@code n} configurations associated with state {@code s} for\n     * {@code n} possible alternatives in the decision. The merged stacks\n     * complicate the comparison of configuration contexts {@code x} and\n     * {@code x'}. Sam checks to see if one is a subset of the other by calling\n     * merge and checking to see if the merged result is either {@code x} or\n     * {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n     * is the superset, then {@code i} is the only possible prediction since the\n     * others resolve to {@code min(i)} as well. However, if {@code x} is\n     * associated with {@code j>i} then at least one stack configuration for\n     * {@code j} is not in conflict with alternative {@code i}. The algorithm\n     * should keep going, looking for more lookahead due to the uncertainty.</p>\n     *\n     * <p>For simplicity, I'm doing a equality check between {@code x} and\n     * {@code x'} that lets the algorithm continue to consume lookahead longer\n     * than necessary. The reason I like the equality is of course the\n     * simplicity but also because that is the test you need to detect the\n     * alternatives that are actually in conflict.</p>\n     *\n     * <p><strong>CONTINUE/STOP RULE</strong></p>\n     *\n     * <p>Continue if union of resolved alternative sets from non-conflicting and\n     * conflicting alternative subsets has more than one alternative. We are\n     * uncertain about which alternative to predict.</p>\n     *\n     * <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n     * alternatives are still in the running for the amount of input we've\n     * consumed at this point. The conflicting sets let us to strip away\n     * configurations that won't lead to more states because we resolve\n     * conflicts to the configuration with a minimum alternate for the\n     * conflicting set.</p>\n     *\n     * <p><strong>CASES</strong></p>\n     *\n     * <ul>\n     *\n     * <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n     *\n     * <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n     * {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n     * {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1,3}} =&gt; continue\n     * </li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n     * {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1}} =&gt; stop and predict 1</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n     * ambiguity {@code {1,2}}</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n     * {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {2}} = {@code {1,2}} =&gt; continue</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n     * {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {3}} = {@code {1,3}} =&gt; continue</li>\n     *\n     * </ul>\n     *\n     * <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n     *\n     * <p>If all states report the same conflicting set of alternatives, then we\n     * know we have the exact ambiguity set.</p>\n     *\n     * <p><code>|A_<em>i</em>|&gt;1</code> and\n     * <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n     *\n     * <p>In other words, we continue examining lookahead until all {@code A_i}\n     * have more than one alternative and all {@code A_i} are the same. If\n     * {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n     * because the resolved set is {@code {1}}. To determine what the real\n     * ambiguity is, we have to know whether the ambiguity is between one and\n     * two or one and three so we keep going. We can only stop prediction when\n     * we need exact ambiguity detection when the sets look like\n     * {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n     */\n    resolvesToJustOneViableAlt: function(altsets) {\n        return PredictionMode.getSingleViableAlt(altsets);\n    },\n\n    /**\n     * Determines if every alternative subset in {@code altsets} contains more\n     * than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every {@link BitSet} in {@code altsets} has\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    allSubsetsConflict: function(altsets) {\n        return ! PredictionMode.hasNonConflictingAltSet(altsets);\n    },\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * exactly one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n     */\n    hasNonConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * more than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    hasConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length>1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if every alternative subset in {@code altsets} is equivalent.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every member of {@code altsets} is equal to the\n     * others, otherwise {@code false}\n     */\n    allSubsetsEqual: function(altsets) {\n        let first = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (first === null) {\n                first = alts;\n            } else if (alts!==first) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n\n    /**\n     * Returns the unique alternative predicted by all alternative subsets in\n     * {@code altsets}. If no such alternative exists, this method returns\n     * {@link ATN//INVALID_ALT_NUMBER}.\n     *\n     * @param altsets a collection of alternative subsets\n     */\n    getUniqueAlt: function(altsets) {\n        const all = PredictionMode.getAlts(altsets);\n        if (all.length===1) {\n            return all.minValue();\n        } else {\n            return ATN.INVALID_ALT_NUMBER;\n        }\n    },\n\n    /**\n     * Gets the complete set of represented alternatives for a collection of\n     * alternative subsets. This method returns the union of each {@link BitSet}\n     * in {@code altsets}.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return the set of represented alternatives in {@code altsets}\n     */\n    getAlts: function(altsets) {\n        const all = new BitSet();\n        altsets.map( function(alts) { all.or(alts); });\n        return all;\n    },\n\n    /**\n     * This function gets the conflicting alt subsets from a configuration set.\n     * For each configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     */\n    getConflictingAltSubsets: function(configs) {\n        const configToAlts = new Map();\n        configToAlts.hashFunction = function(cfg) { hashStuff(cfg.state.stateNumber, cfg.context); };\n        configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber === c2.state.stateNumber && c1.context.equals(c2.context);};\n        configs.items.map(function(cfg) {\n            let alts = configToAlts.get(cfg);\n            if (alts === null) {\n                alts = new BitSet();\n                configToAlts.put(cfg, alts);\n            }\n            alts.add(cfg.alt);\n        });\n        return configToAlts.getValues();\n    },\n\n    /**\n     * Get a map from state to alt subset from a configuration set. For each\n     * configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n     * </pre>\n     */\n    getStateToAltMap: function(configs) {\n        const m = new AltDict();\n        configs.items.map(function(c) {\n            let alts = m.get(c.state);\n            if (alts === null) {\n                alts = new BitSet();\n                m.put(c.state, alts);\n            }\n            alts.add(c.alt);\n        });\n        return m;\n    },\n\n    hasStateAssociatedWithOneAlt: function(configs) {\n        const values = PredictionMode.getStateToAltMap(configs).values();\n        for(let i=0;i<values.length;i++) {\n            if (values[i].length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    getSingleViableAlt: function(altsets) {\n        let result = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            const minAlt = alts.minValue();\n            if(result===null) {\n                result = minAlt;\n            } else if(result!==minAlt) { // more than 1 viable alt\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return result;\n    }\n};\n\nmodule.exports = PredictionMode;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst { Set, Hash, equalArrays } = require('./../Utils');\n\n/**\n * A tree structure used to record the semantic context in which\n * an ATN configuration is valid.  It's either a single predicate,\n * a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n *\n * <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n * {@link SemanticContext} within the scope of this outer class.</p>\n */\nclass SemanticContext {\n\n\thashCode() {\n\t\tconst hash = new Hash();\n\t\tthis.updateHashCode(hash);\n\t\treturn hash.finish();\n\t}\n\n\t/**\n\t * For context independent predicates, we evaluate them without a local\n\t * context (i.e., null context). That way, we can evaluate them without\n\t * having to create proper rule-specific context during prediction (as\n\t * opposed to the parser, which creates them naturally). In a practical\n\t * sense, this avoids a cast exception from RuleContext to myruleContext.\n\t *\n\t * <p>For context dependent predicates, we must pass in a local context so that\n\t * references such as $arg evaluate properly as _localctx.arg. We only\n\t * capture context dependent predicates in the context in which we begin\n\t * prediction, so we passed in the outer context here in case of context\n\t * dependent predicate evaluation.</p>\n\t */\n\tevaluate(parser, outerContext) {}\n\n\t/**\n\t * Evaluate the precedence predicates for the context and reduce the result.\n\t *\n\t * @param parser The parser instance.\n\t * @param outerContext The current parser context object.\n\t * @return The simplified semantic context after precedence predicates are\n\t * evaluated, which will be one of the following values.\n\t * <ul>\n\t * <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code null}: if the predicate simplifies to {@code false} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code this}: if the semantic context is not changed as a result of\n\t * precedence predicate evaluation.</li>\n\t * <li>A non-{@code null} {@link SemanticContext}: the new simplified\n\t * semantic context after precedence predicates are evaluated.</li>\n\t * </ul>\n\t */\n\tevalPrecedence(parser, outerContext) {\n\t\treturn this;\n\t}\n\n\tstatic andContext(a, b) {\n\t\tif (a === null || a === SemanticContext.NONE) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null || b === SemanticContext.NONE) {\n\t\t\treturn a;\n\t\t}\n\t\tconst result = new AND(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n\n\tstatic orContext(a, b) {\n\t\tif (a === null) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null) {\n\t\t\treturn a;\n\t\t}\n\t\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tconst result = new OR(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\n\nclass Predicate extends SemanticContext {\n\n\tconstructor(ruleIndex, predIndex, isCtxDependent) {\n\t\tsuper();\n\t\tthis.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n\t\tthis.predIndex = predIndex === undefined ? -1 : predIndex;\n\t\tthis.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\t}\n\n\tevaluate(parser, outerContext) {\n\t\tconst localctx = this.isCtxDependent ? outerContext : null;\n\t\treturn parser.sempred(localctx, this.ruleIndex, this.predIndex);\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof Predicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.ruleIndex === other.ruleIndex &&\n\t\t\t\t\tthis.predIndex === other.predIndex &&\n\t\t\t\t\tthis.isCtxDependent === other.isCtxDependent;\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n\t}\n}\n\n/**\n * The default {@link SemanticContext}, which is semantically equivalent to\n * a predicate of the form {@code {true}?}\n */\nSemanticContext.NONE = new Predicate();\n\n\nclass PrecedencePredicate extends SemanticContext {\n\n\tconstructor(precedence) {\n\t\tsuper();\n\t\tthis.precedence = precedence === undefined ? 0 : precedence;\n\t}\n\n\tevaluate(parser, outerContext) {\n\t\treturn parser.precpred(outerContext, this.precedence);\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tif (parser.precpred(outerContext, this.precedence)) {\n\t\t\treturn SemanticContext.NONE;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tcompareTo(other) {\n\t\treturn this.precedence - other.precedence;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.precedence);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof PrecedencePredicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.precedence === other.precedence;\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn \"{\" + this.precedence + \">=prec}?\";\n\t}\n\n\tstatic filterPrecedencePredicates(set) {\n\t\tconst result = [];\n\t\tset.values().map( function(context) {\n\t\t\tif (context instanceof PrecedencePredicate) {\n\t\t\t\tresult.push(context);\n\t\t\t}\n\t\t});\n\t\treturn result;\n\t}\n}\n\nclass AND extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever none of the contained contexts\n\t * is false\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new Set();\n\t\tif (a instanceof AND) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof AND) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\t\tconst precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the lowest precedence\n\t\t\tlet reduced = null;\n\t\t\tprecedencePredicates.map( function(p) {\n\t\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\t\treduced = p;\n\t\t\t\t}\n\t\t\t});\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = Array.from(operands.values());\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof AND)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn equalArrays(this.opnds, other.opnds);\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"AND\");\n\t}\n\n\t/**\n\t * {@inheritDoc}\n\t *\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === null) {\n\t\t\t\t// The AND context is false if any element is false\n\t\t\t\treturn null;\n\t\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t\t// Reduce the result by skipping true elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were true, so the AND context is true\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tlet result = null;\n\t\toperands.map(function(o) {\n\t\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tconst s = this.opnds.map(o => o.toString());\n\t\treturn (s.length > 3 ? s.slice(3) : s).join(\"&&\");\n\t}\n}\n\n\nclass OR extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever at least one of the contained\n\t * contexts is true\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new Set();\n\t\tif (a instanceof OR) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof OR) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\n\t\tconst precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the highest precedence\n\t\t\tconst s = precedencePredicates.sort(function(a, b) {\n\t\t\t\treturn a.compareTo(b);\n\t\t\t});\n\t\t\tconst reduced = s[s.length-1];\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = Array.from(operands.values());\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof OR)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn equalArrays(this.opnds, other.opnds);\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"OR\");\n\t}\n\n\t/**\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t\t// The OR context is true if any element is true\n\t\t\t\treturn SemanticContext.NONE;\n\t\t\t} else if (evaluated !== null) {\n\t\t\t\t// Reduce the result by skipping false elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were false, so the OR context is false\n\t\t\treturn null;\n\t\t}\n\t\tconst result = null;\n\t\toperands.map(function(o) {\n\t\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tconst s = this.opnds.map(o => o.toString());\n\t\treturn (s.length > 3 ? s.slice(3) : s).join(\"||\");\n\t}\n}\n\nmodule.exports = {\n\tSemanticContext,\n\tPrecedencePredicate,\n\tPredicate\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst {IntervalSet} = require('./../IntervalSet');\nconst {Predicate, PrecedencePredicate} = require('./SemanticContext');\n\n/**\n * An ATN transition between any two ATN states.  Subclasses define\n * atom, set, epsilon, action, predicate, rule transitions.\n *\n * <p>This is a one way link.  It emanates from a state (usually via a list of\n * transitions) and has a target state.</p>\n *\n * <p>Since we never have to change the ATN transitions once we construct it,\n * we can fix these transitions as specific classes. The DFA transitions\n * on the other hand need to update the labels as it adds transitions to\n * the states. We'll use the term Edge for the DFA to distinguish them from\n * ATN transitions.</p>\n */\nclass Transition {\n    constructor(target) {\n        // The target of this transition.\n        if (target===undefined || target===null) {\n            throw \"target cannot be null.\";\n        }\n        this.target = target;\n        // Are we epsilon, action, sempred?\n        this.isEpsilon = false;\n        this.label = null;\n    }\n}\n\n// constants for serialization\n\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\n// e.g., {isType(input.LT(1))}?\nTransition.PREDICATE = 4;\nTransition.ATOM = 5;\nTransition.ACTION = 6;\n// ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.SET = 7;\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n            \"INVALID\",\n            \"EPSILON\",\n            \"RANGE\",\n            \"RULE\",\n            \"PREDICATE\",\n            \"ATOM\",\n            \"ACTION\",\n            \"SET\",\n            \"NOT_SET\",\n            \"WILDCARD\",\n            \"PRECEDENCE\"\n        ];\n\nTransition.serializationTypes = {\n        EpsilonTransition: Transition.EPSILON,\n        RangeTransition: Transition.RANGE,\n        RuleTransition: Transition.RULE,\n        PredicateTransition: Transition.PREDICATE,\n        AtomTransition: Transition.ATOM,\n        ActionTransition: Transition.ACTION,\n        SetTransition: Transition.SET,\n        NotSetTransition: Transition.NOT_SET,\n        WildcardTransition: Transition.WILDCARD,\n        PrecedencePredicateTransition: Transition.PRECEDENCE\n    };\n\n\n// TODO: make all transitions sets? no, should remove set edges\n\nclass AtomTransition extends Transition {\n    constructor(target, label) {\n        super(target);\n        // The token type or character value; or, signifies special label.\n        this.label_ = label;\n        this.label = this.makeLabel();\n        this.serializationType = Transition.ATOM;\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addOne(this.label_);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label_ === symbol;\n    }\n\n    toString() {\n        return this.label_;\n    }\n}\n\n\nclass RuleTransition extends Transition {\n    constructor(ruleStart, ruleIndex, precedence, followState) {\n        super(ruleStart);\n        // ptr to the rule definition object for this rule ref\n        this.ruleIndex = ruleIndex;\n        this.precedence = precedence;\n        // what node to begin computations following ref to rule\n        this.followState = followState;\n        this.serializationType = Transition.RULE;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n}\n\nclass EpsilonTransition extends Transition {\n    constructor(target, outermostPrecedenceReturn) {\n        super(target);\n        this.serializationType = Transition.EPSILON;\n        this.isEpsilon = true;\n        this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"epsilon\";\n    }\n}\n\n\nclass RangeTransition extends Transition {\n    constructor(target, start, stop) {\n        super(target);\n        this.serializationType = Transition.RANGE;\n        this.start = start;\n        this.stop = stop;\n        this.label = this.makeLabel();\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addRange(this.start, this.stop);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= this.start && symbol <= this.stop;\n    }\n\n    toString() {\n        return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n    }\n}\n\n\nclass AbstractPredicateTransition extends Transition {\n    constructor(target) {\n        super(target);\n    }\n}\n\nclass PredicateTransition extends AbstractPredicateTransition {\n    constructor(target, ruleIndex, predIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.PREDICATE;\n        this.ruleIndex = ruleIndex;\n        this.predIndex = predIndex;\n        this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n    }\n\n    toString() {\n        return \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n    }\n}\n\n\nclass ActionTransition extends Transition {\n    constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.ACTION;\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n        this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n    }\n}\n\n\n// A transition containing a set of values.\nclass SetTransition extends Transition {\n    constructor(target, set) {\n        super(target);\n        this.serializationType = Transition.SET;\n        if (set !==undefined && set !==null) {\n            this.label = set;\n        } else {\n            this.label = new IntervalSet();\n            this.label.addOne(Token.INVALID_TYPE);\n        }\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label.contains(symbol);\n    }\n\n    toString() {\n        return this.label.toString();\n    }\n}\n\nclass NotSetTransition extends SetTransition {\n    constructor(target, set) {\n        super(target, set);\n        this.serializationType = Transition.NOT_SET;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n                !super.matches(symbol, minVocabSymbol, maxVocabSymbol);\n    }\n\n    toString() {\n        return '~' + super.toString();\n    }\n}\n\nclass WildcardTransition extends Transition {\n    constructor(target) {\n        super(target);\n        this.serializationType = Transition.WILDCARD;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n    }\n\n    toString() {\n        return \".\";\n    }\n}\n\nclass PrecedencePredicateTransition extends AbstractPredicateTransition {\n    constructor(target, precedence) {\n        super(target);\n        this.serializationType = Transition.PRECEDENCE;\n        this.precedence = precedence;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new PrecedencePredicate(this.precedence);\n    }\n\n    toString() {\n        return this.precedence + \" >= _p\";\n    }\n}\n\nmodule.exports = {\n    Transition,\n    AtomTransition,\n    SetTransition,\n    NotSetTransition,\n    RuleTransition,\n    ActionTransition,\n    EpsilonTransition,\n    RangeTransition,\n    WildcardTransition,\n    PredicateTransition,\n    PrecedencePredicateTransition,\n    AbstractPredicateTransition\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.ATN = require('./ATN');\nexports.ATNDeserializer = require('./ATNDeserializer');\nexports.LexerATNSimulator = require('./LexerATNSimulator');\nexports.ParserATNSimulator = require('./ParserATNSimulator');\nexports.PredictionMode = require('./PredictionMode');\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set} = require(\"../Utils\");\nconst {DFAState} = require('./DFAState');\nconst {StarLoopEntryState} = require('../atn/ATNState');\nconst {ATNConfigSet} = require('./../atn/ATNConfigSet');\nconst {DFASerializer} = require('./DFASerializer');\nconst {LexerDFASerializer} = require('./DFASerializer');\n\nclass DFA {\n\tconstructor(atnStartState, decision) {\n\t\tif (decision === undefined) {\n\t\t\tdecision = 0;\n\t\t}\n\t\t/**\n\t\t * From which ATN state did we create this DFA?\n\t\t */\n\t\tthis.atnStartState = atnStartState;\n\t\tthis.decision = decision;\n\t\t/**\n\t\t * A set of all DFA states. Use {@link Map} so we can get old state back\n\t\t * ({@link Set} only allows you to see if it's there).\n\t\t */\n\t\tthis._states = new Set();\n\t\tthis.s0 = null;\n\t\t/**\n\t\t * {@code true} if this DFA is for a precedence decision; otherwise,\n\t\t * {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t\t * {@link //setPrecedenceDfa}\n\t\t */\n\t\tthis.precedenceDfa = false;\n\t\tif (atnStartState instanceof StarLoopEntryState)\n\t\t{\n\t\t\tif (atnStartState.isPrecedenceDecision) {\n\t\t\t\tthis.precedenceDfa = true;\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Get the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @return The start state corresponding to the specified precedence, or\n\t * {@code null} if no start state exists for the specified precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tgetPrecedenceStartState(precedence) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\t// s0.edges is never null for a precedence DFA\n\t\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.s0.edges[precedence] || null;\n\t}\n\n\t/**\n\t * Set the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @param startState The start state corresponding to the specified\n\t * precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tsetPrecedenceStartState(precedence, startState) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\tif (precedence < 0) {\n\t\t\treturn;\n\t\t}\n\n\t\t/**\n\t\t * synchronization on s0 here is ok. when the DFA is turned into a\n\t\t * precedence DFA, s0 will be initialized once and not updated again\n\t\t * s0.edges is never null for a precedence DFA\n\t\t */\n\t\tthis.s0.edges[precedence] = startState;\n\t}\n\n\t/**\n\t * Sets whether this is a precedence DFA. If the specified value differs\n\t * from the current DFA configuration, the following actions are taken;\n\t * otherwise no changes are made to the current DFA.\n\t *\n\t * <ul>\n\t * <li>The {@link //states} map is cleared</li>\n\t * <li>If {@code precedenceDfa} is {@code false}, the initial state\n\t * {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n\t * {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n\t * store the start states for individual precedence values.</li>\n\t * <li>The {@link //precedenceDfa} field is updated</li>\n\t * </ul>\n\t *\n\t * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n\t * {@code false}\n\t */\n\tsetPrecedenceDfa(precedenceDfa) {\n\t\tif (this.precedenceDfa!==precedenceDfa) {\n\t\t\tthis._states = new Set();\n\t\t\tif (precedenceDfa) {\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t} else {\n\t\t\t\tthis.s0 = null;\n\t\t\t}\n\t\t\tthis.precedenceDfa = precedenceDfa;\n\t\t}\n\t}\n\n\t/**\n\t * Return a list of all states in this DFA, ordered by state number.\n\t */\n\tsortedStates() {\n\t\tconst list = this._states.values();\n\t\treturn list.sort(function(a, b) {\n\t\t\treturn a.stateNumber - b.stateNumber;\n\t\t});\n\t}\n\n\ttoString(literalNames, symbolicNames) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new DFASerializer(this, literalNames, symbolicNames);\n\t\treturn serializer.toString();\n\t}\n\n\ttoLexerString() {\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new LexerDFASerializer(this);\n\t\treturn serializer.toString();\n\t}\n\n\tget states(){\n\t\treturn this._states;\n\t}\n}\n\n\nmodule.exports = DFA;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A DFA walker that knows how to dump them to serialized strings.\n */\nclass DFASerializer {\n    constructor(dfa, literalNames, symbolicNames) {\n        this.dfa = dfa;\n        this.literalNames = literalNames || [];\n        this.symbolicNames = symbolicNames || [];\n    }\n\n    toString() {\n       if(this.dfa.s0 === null) {\n           return null;\n       }\n       let buf = \"\";\n       const states = this.dfa.sortedStates();\n       for(let i=0; i<states.length; i++) {\n           const s = states[i];\n           if(s.edges!==null) {\n                const n = s.edges.length;\n                for(let j=0;j<n;j++) {\n                    const t = s.edges[j] || null;\n                    if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n                        buf = buf.concat(this.getStateString(s));\n                        buf = buf.concat(\"-\");\n                        buf = buf.concat(this.getEdgeLabel(j));\n                        buf = buf.concat(\"->\");\n                        buf = buf.concat(this.getStateString(t));\n                        buf = buf.concat('\\n');\n                    }\n                }\n           }\n       }\n       return buf.length===0 ? null : buf;\n    }\n\n    getEdgeLabel(i) {\n        if (i===0) {\n            return \"EOF\";\n        } else if(this.literalNames !==null || this.symbolicNames!==null) {\n            return this.literalNames[i-1] || this.symbolicNames[i-1];\n        } else {\n            return String.fromCharCode(i-1);\n        }\n    }\n\n    getStateString(s) {\n        const baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n        if(s.isAcceptState) {\n            if (s.predicates !== null) {\n                return baseStateStr + \"=>\" + s.predicates.toString();\n            } else {\n                return baseStateStr + \"=>\" + s.prediction.toString();\n            }\n        } else {\n            return baseStateStr;\n        }\n    }\n}\n\nclass LexerDFASerializer extends DFASerializer {\n    constructor(dfa) {\n        super(dfa, null);\n    }\n\n    getEdgeLabel(i) {\n        return \"'\" + String.fromCharCode(i) + \"'\";\n    }\n}\n\nmodule.exports = { DFASerializer , LexerDFASerializer };\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {ATNConfigSet} = require('./../atn/ATNConfigSet');\nconst {Hash, Set} = require('./../Utils');\n\n/**\n * Map a predicate to a predicted alternative.\n */\nclass PredPrediction {\n\tconstructor(pred, alt) {\n\t\tthis.alt = alt;\n\t\tthis.pred = pred;\n\t}\n\n\ttoString() {\n\t\treturn \"(\" + this.pred + \", \" + this.alt + \")\";\n\t}\n}\n\n/**\n * A DFA state represents a set of possible ATN configurations.\n * As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n * to keep track of all possible states the ATN can be in after\n * reading each input symbol. That is to say, after reading\n * input a1a2..an, the DFA is in a state that represents the\n * subset T of the states of the ATN that are reachable from the\n * ATN's start state along some path labeled a1a2..an.\"\n * In conventional NFA&rarr;DFA conversion, therefore, the subset T\n * would be a bitset representing the set of states the\n * ATN could be in. We need to track the alt predicted by each\n * state as well, however. More importantly, we need to maintain\n * a stack of states, tracking the closure operations as they\n * jump from rule to rule, emulating rule invocations (method calls).\n * I have to add a stack to simulate the proper lookahead sequences for\n * the underlying LL grammar from which the ATN was derived.\n *\n * <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n * is both a state (ala normal conversion) and a RuleContext describing\n * the chain of rules (if any) followed to arrive at that state.</p>\n *\n * <p>A DFA state may have multiple references to a particular state,\n * but with different ATN contexts (with same or different alts)\n * meaning that state was reached via a different set of rule invocations.</p>\n */\nclass DFAState {\n\tconstructor(stateNumber, configs) {\n\t\tif (stateNumber === null) {\n\t\t\tstateNumber = -1;\n\t\t}\n\t\tif (configs === null) {\n\t\t\tconfigs = new ATNConfigSet();\n\t\t}\n\t\tthis.stateNumber = stateNumber;\n\t\tthis.configs = configs;\n\t\t/**\n\t\t * {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t\t * {@link Token//EOF} maps to {@code edges[0]}.\n\t\t */\n\t\tthis.edges = null;\n\t\tthis.isAcceptState = false;\n\t\t/**\n\t\t * if accept state, what ttype do we match or alt do we predict?\n\t\t * This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link//predicates}\n\t\t * {@code !=null} or {@link //requiresFullContext}.\n\t\t */\n\t\tthis.prediction = 0;\n\t\tthis.lexerActionExecutor = null;\n\t\t/**\n\t\t * Indicates that this state was created during SLL prediction that\n\t\t * discovered a conflict between the configurations in the state. Future\n\t\t * {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t\t * full context prediction if this field is true.\n\t\t */\n\t\tthis.requiresFullContext = false;\n\t\t/**\n\t\t * During SLL parsing, this is a list of predicates associated with the\n\t\t * ATN configurations of the DFA state. When we have predicates,\n\t\t * {@link //requiresFullContext} is {@code false} since full context\n\t\t * prediction evaluates predicates\n\t\t * on-the-fly. If this is not null, then {@link //prediction} is\n\t\t * {@link ATN//INVALID_ALT_NUMBER}.\n\t\t *\n\t\t * <p>We only use these for non-{@link //requiresFullContext} but\n\t\t * conflicting states. That\n\t\t * means we know from the context (it's $ or we don't dip into outer\n\t\t * context) that it's an ambiguity not a conflict.</p>\n\t\t *\n\t\t * <p>This list is computed by {@link\n\t\t * ParserATNSimulator//predicateDFAState}.</p>\n\t\t */\n\t\tthis.predicates = null;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get the set of all alts mentioned by all ATN configurations in this\n\t * DFA state.\n\t */\n\tgetAltSet() {\n\t\tconst alts = new Set();\n\t\tif (this.configs !== null) {\n\t\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\t\tconst c = this.configs[i];\n\t\t\t\talts.add(c.alt);\n\t\t\t}\n\t\t}\n\t\tif (alts.length === 0) {\n\t\t\treturn null;\n\t\t} else {\n\t\t\treturn alts;\n\t\t}\n\t}\n\n\t/**\n\t * Two {@link DFAState} instances are equal if their ATN configuration sets\n\t * are the same. This method is used to see if a state already exists.\n\t *\n\t * <p>Because the number of alternatives and number of ATN configurations are\n\t * finite, there is a finite number of DFA states that can be processed.\n\t * This is necessary to show that the algorithm terminates.</p>\n\t *\n\t * <p>Cannot test the DFA state numbers here because in\n\t * {@link ParserATNSimulator//addDFAState} we need to know if any other state\n\t * exists that has this exact set of ATN configurations. The\n\t * {@link //stateNumber} is irrelevant.</p>\n\t */\n\tequals(other) {\n\t\t// compare set of ATN configurations in this set with other\n\t\treturn this === other ||\n\t\t\t\t(other instanceof DFAState &&\n\t\t\t\t\tthis.configs.equals(other.configs));\n\t}\n\n\ttoString() {\n\t\tlet s = \"\" + this.stateNumber + \":\" + this.configs;\n\t\tif(this.isAcceptState) {\n\t\t\ts = s + \"=>\";\n\t\t\tif (this.predicates !== null)\n\t\t\t\ts = s + this.predicates;\n\t\t\telse\n\t\t\t\ts = s + this.prediction;\n\t\t}\n\t\treturn s;\n\t}\n\n\thashCode() {\n\t\tconst hash = new Hash();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n}\n\nmodule.exports = { DFAState, PredPrediction };\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.DFA = require('./DFA');\nexports.DFASerializer = require('./DFASerializer').DFASerializer;\nexports.LexerDFASerializer = require('./DFASerializer').LexerDFASerializer;\nexports.PredPrediction = require('./DFAState').PredPrediction;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {BitSet} = require('./../Utils');\nconst {ErrorListener} = require('./ErrorListener')\nconst {Interval} = require('./../IntervalSet')\n\n\n/**\n * This implementation of {@link ANTLRErrorListener} can be used to identify\n *  certain potential correctness and performance problems in grammars. \"Reports\"\n *  are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n *  message.\n *\n *  <ul>\n *  <li><b>Ambiguities</b>: These are cases where more than one path through the\n *  grammar can match the input.</li>\n *  <li><b>Weak context sensitivity</b>: These are cases where full-context\n *  prediction resolved an SLL conflict to a unique alternative which equaled the\n *  minimum alternative of the SLL conflict.</li>\n *  <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n *  full-context prediction resolved an SLL conflict to a unique alternative,\n *  <em>and</em> the minimum alternative of the SLL conflict was found to not be\n *  a truly viable alternative. Two-stage parsing cannot be used for inputs where\n *  this situation occurs.</li>\n *  </ul>\n */\nclass DiagnosticErrorListener extends ErrorListener {\n\tconstructor(exactOnly) {\n\t\tsuper();\n\t\texactOnly = exactOnly || true;\n\t\t// whether all ambiguities or only exact ambiguities are reported.\n\t\tthis.exactOnly = exactOnly;\n\t}\n\n\treportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n\t\tif (this.exactOnly && !exact) {\n\t\t\treturn;\n\t\t}\n\t\tconst msg = \"reportAmbiguity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\": ambigAlts=\" +\n\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t\tconst msg = \"reportAttemptingFullContext d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t\tconst msg = \"reportContextSensitivity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\tgetDecisionDescription(recognizer, dfa) {\n\t\tconst decision = dfa.decision\n\t\tconst ruleIndex = dfa.atnStartState.ruleIndex\n\n\t\tconst ruleNames = recognizer.ruleNames\n\t\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\tconst ruleName = ruleNames[ruleIndex] || null\n\t\tif (ruleName === null || ruleName.length === 0) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\treturn `${decision} (${ruleName})`;\n\t}\n\n\t/**\n\t * Computes the set of conflicting or ambiguous alternatives from a\n\t * configuration set, if that information was not already provided by the\n\t * parser.\n\t *\n\t * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n\t * reported by the parser.\n\t * @param configs The conflicting or ambiguous configuration set.\n\t * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n\t * returns the set of alternatives represented in {@code configs}.\n     */\n\tgetConflictingAlts(reportedAlts, configs) {\n\t\tif (reportedAlts !== null) {\n\t\t\treturn reportedAlts;\n\t\t}\n\t\tconst result = new BitSet()\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tresult.add(configs.items[i].alt);\n\t\t}\n\t\treturn `{${result.values().join(\", \")}}`;\n\t}\n}\n\nmodule.exports = DiagnosticErrorListener\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Provides an empty default implementation of {@link ANTLRErrorListener}. The\n * default implementation of each method does nothing, but can be overridden as\n * necessary.\n */\nclass ErrorListener {\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    }\n}\n\n/**\n * {@inheritDoc}\n *\n * <p>\n * This implementation prints messages to {@link System//err} containing the\n * values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n * the following format.</p>\n *\n * <pre>\n * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n * </pre>\n *\n */\nclass ConsoleErrorListener extends ErrorListener {\n    constructor() {\n        super();\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        console.error(\"line \" + line + \":\" + column + \" \" + msg);\n    }\n}\n\n\n/**\n * Provides a default instance of {@link ConsoleErrorListener}.\n */\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n\nclass ProxyErrorListener extends ErrorListener {\n    constructor(delegates) {\n        super();\n        if (delegates===null) {\n            throw \"delegates\";\n        }\n        this.delegates = delegates;\n        return this;\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        this.delegates.map(d => d.syntaxError(recognizer, offendingSymbol, line, column, msg, e));\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n        this.delegates.map(d => d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs));\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n        this.delegates.map(d => d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs));\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n        this.delegates.map(d => d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs));\n    }\n}\n\nmodule.exports = {ErrorListener, ConsoleErrorListener, ProxyErrorListener}\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token')\nconst {NoViableAltException, InputMismatchException, FailedPredicateException, ParseCancellationException} = require('./Errors')\nconst {ATNState} = require('./../atn/ATNState')\nconst {Interval, IntervalSet} = require('./../IntervalSet')\n\nclass ErrorStrategy {\n\n    reset(recognizer) {\n    }\n\n    recoverInline(recognizer) {\n    }\n\n    recover(recognizer, e) {\n    }\n\n    sync(recognizer) {\n    }\n\n    inErrorRecoveryMode(recognizer) {\n    }\n\n    reportError(recognizer) {\n    }\n}\n\n\n/**\n * This is the default implementation of {@link ANTLRErrorStrategy} used for\n * error reporting and recovery in ANTLR parsers.\n*/\nclass DefaultErrorStrategy extends ErrorStrategy {\n    constructor() {\n        super();\n        /**\n         * Indicates whether the error strategy is currently \"recovering from an\n         * error\". This is used to suppress reporting multiple error messages while\n         * attempting to recover from a detected syntax error.\n         *\n         * @see //inErrorRecoveryMode\n         */\n        this.errorRecoveryMode = false;\n\n        /**\n         * The index into the input stream where the last error occurred.\n         * This is used to prevent infinite loops where an error is found\n         * but no token is consumed during recovery...another error is found,\n         * ad nauseum. This is a failsafe mechanism to guarantee that at least\n         * one token/tree node is consumed for two errors.\n         */\n        this.lastErrorIndex = -1;\n        this.lastErrorStates = null;\n        this.nextTokensContext = null;\n        this.nextTokenState = 0;\n    }\n\n    /**\n     * <p>The default implementation simply calls {@link //endErrorCondition} to\n     * ensure that the handler is not in error recovery mode.</p>\n    */\n    reset(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * This method is called to enter error recovery mode when a recognition\n     * exception is reported.\n     *\n     * @param recognizer the parser instance\n    */\n    beginErrorCondition(recognizer) {\n        this.errorRecoveryMode = true;\n    }\n\n    inErrorRecoveryMode(recognizer) {\n        return this.errorRecoveryMode;\n    }\n\n    /**\n     * This method is called to leave error recovery mode after recovering from\n     * a recognition exception.\n     * @param recognizer\n     */\n    endErrorCondition(recognizer) {\n        this.errorRecoveryMode = false;\n        this.lastErrorStates = null;\n        this.lastErrorIndex = -1;\n    }\n\n    /**\n     * {@inheritDoc}\n     * <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n     */\n    reportMatch(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * <p>The default implementation returns immediately if the handler is already\n     * in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n     * and dispatches the reporting task based on the runtime type of {@code e}\n     * according to the following table.</p>\n     *\n     * <ul>\n     * <li>{@link NoViableAltException}: Dispatches the call to\n     * {@link //reportNoViableAlternative}</li>\n     * <li>{@link InputMismatchException}: Dispatches the call to\n     * {@link //reportInputMismatch}</li>\n     * <li>{@link FailedPredicateException}: Dispatches the call to\n     * {@link //reportFailedPredicate}</li>\n     * <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n     * the exception</li>\n     * </ul>\n     */\n    reportError(recognizer, e) {\n       // if we've already reported an error and have not matched a token\n       // yet successfully, don't report any errors.\n        if(this.inErrorRecoveryMode(recognizer)) {\n            return; // don't report spurious errors\n        }\n        this.beginErrorCondition(recognizer);\n        if ( e instanceof NoViableAltException ) {\n            this.reportNoViableAlternative(recognizer, e);\n        } else if ( e instanceof InputMismatchException ) {\n            this.reportInputMismatch(recognizer, e);\n        } else if ( e instanceof FailedPredicateException ) {\n            this.reportFailedPredicate(recognizer, e);\n        } else {\n            console.log(\"unknown recognition error type: \" + e.constructor.name);\n            console.log(e.stack);\n            recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n        }\n    }\n\n    /**\n     *\n     * {@inheritDoc}\n     *\n     * <p>The default implementation resynchronizes the parser by consuming tokens\n     * until we find one in the resynchronization set--loosely the set of tokens\n     * that can follow the current rule.</p>\n     *\n     */\n    recover(recognizer, e) {\n        if (this.lastErrorIndex===recognizer.getInputStream().index &&\n            this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n            // uh oh, another error at same token index and previously-visited\n            // state in ATN; must be a case where LT(1) is in the recovery\n            // token set so nothing got consumed. Consume a single token\n            // at least to prevent an infinite loop; this is a failsafe.\n            recognizer.consume();\n        }\n        this.lastErrorIndex = recognizer._input.index;\n        if (this.lastErrorStates === null) {\n            this.lastErrorStates = [];\n        }\n        this.lastErrorStates.push(recognizer.state);\n        const followSet = this.getErrorRecoverySet(recognizer)\n        this.consumeUntil(recognizer, followSet);\n    }\n\n    /**\n     * The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n     * that the current lookahead symbol is consistent with what were expecting\n     * at this point in the ATN. You can call this anytime but ANTLR only\n     * generates code to check before subrules/loops and each iteration.\n     *\n     * <p>Implements Jim Idle's magic sync mechanism in closures and optional\n     * subrules. E.g.,</p>\n     *\n     * <pre>\n     * a : sync ( stuff sync )* ;\n     * sync : {consume to what can follow sync} ;\n     * </pre>\n     *\n     * At the start of a sub rule upon error, {@link //sync} performs single\n     * token deletion, if possible. If it can't do that, it bails on the current\n     * rule and uses the default error recovery, which consumes until the\n     * resynchronization set of the current rule.\n     *\n     * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n     * with an empty alternative), then the expected set includes what follows\n     * the subrule.</p>\n     *\n     * <p>During loop iteration, it consumes until it sees a token that can start a\n     * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n     * stay in the loop as long as possible.</p>\n     *\n     * <p><strong>ORIGINS</strong></p>\n     *\n     * <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n     * A single mismatch token or missing token would force the parser to bail\n     * out of the entire rules surrounding the loop. So, for rule</p>\n     *\n     * <pre>\n     * classDef : 'class' ID '{' member* '}'\n     * </pre>\n     *\n     * input with an extra token between members would force the parser to\n     * consume until it found the next class definition rather than the next\n     * member definition of the current class.\n     *\n     * <p>This functionality cost a little bit of effort because the parser has to\n     * compare token set at the start of the loop and at each iteration. If for\n     * some reason speed is suffering for you, you can turn off this\n     * functionality by simply overriding this method as a blank { }.</p>\n     *\n     */\n    sync(recognizer) {\n        // If already recovering, don't try to sync\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        const s = recognizer._interp.atn.states[recognizer.state];\n        const la = recognizer.getTokenStream().LA(1);\n        // try cheaper subset first; might get lucky. seems to shave a wee bit off\n        const nextTokens = recognizer.atn.nextTokens(s);\n        if(nextTokens.contains(la)) {\n            this.nextTokensContext = null;\n            this.nextTokenState = ATNState.INVALID_STATE_NUMBER;\n            return;\n        } else if (nextTokens.contains(Token.EPSILON)) {\n            if(this.nextTokensContext === null) {\n                // It's possible the next token won't match information tracked\n                // by sync is restricted for performance.\n                this.nextTokensContext = recognizer._ctx;\n                this.nextTokensState = recognizer._stateNumber;\n            }\n            return;\n        }\n        switch (s.stateType) {\n        case ATNState.BLOCK_START:\n        case ATNState.STAR_BLOCK_START:\n        case ATNState.PLUS_BLOCK_START:\n        case ATNState.STAR_LOOP_ENTRY:\n           // report error and recover if possible\n            if( this.singleTokenDeletion(recognizer) !== null) {\n                return;\n            } else {\n                throw new InputMismatchException(recognizer);\n            }\n        case ATNState.PLUS_LOOP_BACK:\n        case ATNState.STAR_LOOP_BACK:\n            this.reportUnwantedToken(recognizer);\n            const expecting = new IntervalSet()\n            expecting.addSet(recognizer.getExpectedTokens());\n            const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer))\n            this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n            break;\n        default:\n            // do nothing if we can't identify the exact kind of ATN state\n        }\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link NoViableAltException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportNoViableAlternative(recognizer, e) {\n        const tokens = recognizer.getTokenStream()\n        let input\n        if(tokens !== null) {\n            if (e.startToken.type===Token.EOF) {\n                input = \"<EOF>\";\n            } else {\n                input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));\n            }\n        } else {\n            input = \"<unknown input>\";\n        }\n        const msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is an\n     * {@link InputMismatchException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportInputMismatch(recognizer, e) {\n        const msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n            \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link FailedPredicateException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportFailedPredicate(recognizer, e) {\n        const ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex]\n        const msg = \"rule \" + ruleName + \" \" + e.message\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the removal\n     * of a token from the input stream. At the time this method is called, the\n     * erroneous symbol is current {@code LT(1)} symbol and has not yet been\n     * removed from the input stream. When this method returns,\n     * {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenDeletion} identifies\n     * single-token deletion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     *\n     */\n    reportUnwantedToken(recognizer) {\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const tokenName = this.getTokenErrorDisplay(t)\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"extraneous input \" + tokenName + \" expecting \" +\n            expecting.toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the\n     * insertion of a missing token into the input stream. At the time this\n     * method is called, the missing token has not yet been inserted. When this\n     * method returns, {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenInsertion} identifies\n     * single-token insertion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     */\n    reportMissingToken(recognizer) {\n        if ( this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n            \" at \" + this.getTokenErrorDisplay(t)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * <p>The default implementation attempts to recover from the mismatched input\n     * by using single token insertion and deletion as described below. If the\n     * recovery attempt fails, this method throws an\n     * {@link InputMismatchException}.</p>\n     *\n     * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n     *\n     * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n     * right token, however, then assume {@code LA(1)} is some extra spurious\n     * token and delete it. Then consume and return the next token (which was\n     * the {@code LA(2)} token) as the successful result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n     * //singleTokenDeletion}.</p>\n     *\n     * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n     *\n     * <p>If current token (at {@code LA(1)}) is consistent with what could come\n     * after the expected {@code LA(1)} token, then assume the token is missing\n     * and use the parser's {@link TokenFactory} to create it on the fly. The\n     * \"insertion\" is performed by returning the created token as the successful\n     * result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n     * //singleTokenInsertion}.</p>\n     *\n     * <p><strong>EXAMPLE</strong></p>\n     *\n     * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n     * the parser returns from the nested call to {@code expr}, it will have\n     * call chain:</p>\n     *\n     * <pre>\n     * stat &rarr; expr &rarr; atom\n     * </pre>\n     *\n     * and it will be trying to match the {@code ')'} at this point in the\n     * derivation:\n     *\n     * <pre>\n     * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n     * ^\n     * </pre>\n     *\n     * The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n     * call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n     * is in the set of tokens that can follow the {@code ')'} token reference\n     * in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n     */\n    recoverInline(recognizer) {\n        // SINGLE TOKEN DELETION\n        const matchedSymbol = this.singleTokenDeletion(recognizer)\n        if (matchedSymbol !== null) {\n            // we have deleted the extra token.\n            // now, move past ttype token as if all were ok\n            recognizer.consume();\n            return matchedSymbol;\n        }\n        // SINGLE TOKEN INSERTION\n        if (this.singleTokenInsertion(recognizer)) {\n            return this.getMissingSymbol(recognizer);\n        }\n        // even that didn't work; must throw the exception\n        throw new InputMismatchException(recognizer);\n    }\n\n    /**\n     * This method implements the single-token insertion inline error recovery\n     * strategy. It is called by {@link //recoverInline} if the single-token\n     * deletion strategy fails to recover from the mismatched input. If this\n     * method returns {@code true}, {@code recognizer} will be in error recovery\n     * mode.\n     *\n     * <p>This method determines whether or not single-token insertion is viable by\n     * checking if the {@code LA(1)} input symbol could be successfully matched\n     * if it were instead the {@code LA(2)} symbol. If this method returns\n     * {@code true}, the caller is responsible for creating and inserting a\n     * token with the correct type to produce this behavior.</p>\n     *\n     * @param recognizer the parser instance\n     * @return {@code true} if single-token insertion is a viable recovery\n     * strategy for the current mismatched input, otherwise {@code false}\n     */\n    singleTokenInsertion(recognizer) {\n        const currentSymbolType = recognizer.getTokenStream().LA(1)\n        // if current token is consistent with what could come after current\n        // ATN state, then we know we're missing a token; error recovery\n        // is free to conjure up and insert the missing token\n        const atn = recognizer._interp.atn\n        const currentState = atn.states[recognizer.state]\n        const next = currentState.transitions[0].target\n        const expectingAtLL2 = atn.nextTokens(next, recognizer._ctx)\n        if (expectingAtLL2.contains(currentSymbolType) ){\n            this.reportMissingToken(recognizer);\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    /**\n     * This method implements the single-token deletion inline error recovery\n     * strategy. It is called by {@link //recoverInline} to attempt to recover\n     * from mismatched input. If this method returns null, the parser and error\n     * handler state will not have changed. If this method returns non-null,\n     * {@code recognizer} will <em>not</em> be in error recovery mode since the\n     * returned token was a successful match.\n     *\n     * <p>If the single-token deletion is successful, this method calls\n     * {@link //reportUnwantedToken} to report the error, followed by\n     * {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n     * before returning {@link //reportMatch} is called to signal a successful\n     * match.</p>\n     *\n     * @param recognizer the parser instance\n     * @return the successfully matched {@link Token} instance if single-token\n     * deletion successfully recovers from the mismatched input, otherwise\n     * {@code null}\n     */\n    singleTokenDeletion(recognizer) {\n        const nextTokenType = recognizer.getTokenStream().LA(2)\n        const expecting = this.getExpectedTokens(recognizer)\n        if (expecting.contains(nextTokenType)) {\n            this.reportUnwantedToken(recognizer);\n            // print(\"recoverFromMismatchedToken deleting \" \\\n            // + str(recognizer.getTokenStream().LT(1)) \\\n            // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n            // + \" is what we want\", file=sys.stderr)\n            recognizer.consume(); // simply delete extra token\n            // we want to return the token we're actually matching\n            const matchedSymbol = recognizer.getCurrentToken()\n            this.reportMatch(recognizer); // we know current token is correct\n            return matchedSymbol;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Conjure up a missing token during error recovery.\n     *\n     * The recognizer attempts to recover from single missing\n     * symbols. But, actions might refer to that missing symbol.\n     * For example, x=ID {f($x);}. The action clearly assumes\n     * that there has been an identifier matched previously and that\n     * $x points at that token. If that token is missing, but\n     * the next token in the stream is what we want we assume that\n     * this token is missing and we keep going. Because we\n     * have to return some token to replace the missing token,\n     * we have to conjure one up. This method gives the user control\n     * over the tokens returned for missing tokens. Mostly,\n     * you will want to create something special for identifier\n     * tokens. For literals such as '{' and ',', the default\n     * action in the parser or tree parser works. It simply creates\n     * a CommonToken of the appropriate type. The text will be the token.\n     * If you change what tokens must be created by the lexer,\n     * override this method to create the appropriate tokens.\n     *\n     */\n    getMissingSymbol(recognizer) {\n        const currentSymbol = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const expectedTokenType = expecting.first() // get any element\n        let tokenText\n        if (expectedTokenType===Token.EOF) {\n            tokenText = \"<missing EOF>\";\n        } else {\n            tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n        }\n        let current = currentSymbol\n        const lookback = recognizer.getTokenStream().LT(-1)\n        if (current.type===Token.EOF && lookback !== null) {\n            current = lookback;\n        }\n        return recognizer.getTokenFactory().create(current.source,\n            expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n            -1, -1, current.line, current.column);\n    }\n\n    getExpectedTokens(recognizer) {\n        return recognizer.getExpectedTokens();\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out. Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     */\n    getTokenErrorDisplay(t) {\n        if (t === null) {\n            return \"<no token>\";\n        }\n        let s = t.text\n        if (s === null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        return this.escapeWSAndQuote(s);\n    }\n\n    escapeWSAndQuote(s) {\n        s = s.replace(/\\n/g,\"\\\\n\");\n        s = s.replace(/\\r/g,\"\\\\r\");\n        s = s.replace(/\\t/g,\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    /**\n     * Compute the error recovery set for the current rule. During\n     * rule invocation, the parser pushes the set of tokens that can\n     * follow that rule reference on the stack; this amounts to\n     * computing FIRST of what follows the rule reference in the\n     * enclosing rule. See LinearApproximator.FIRST().\n     * This local follow set only includes tokens\n     * from within the rule; i.e., the FIRST computation done by\n     * ANTLR stops at the end of a rule.\n     *\n     * EXAMPLE\n     *\n     * When you find a \"no viable alt exception\", the input is not\n     * consistent with any of the alternatives for rule r. The best\n     * thing to do is to consume tokens until you see something that\n     * can legally follow a call to r//or* any rule that called r.\n     * You don't want the exact set of viable next tokens because the\n     * input might just be missing a token--you might consume the\n     * rest of the input looking for one of the missing tokens.\n     *\n     * Consider grammar:\n     *\n     * a : '[' b ']'\n     * | '(' b ')'\n     * ;\n     * b : c '^' INT ;\n     * c : ID\n     * | INT\n     * ;\n     *\n     * At each rule invocation, the set of tokens that could follow\n     * that rule is pushed on a stack. Here are the various\n     * context-sensitive follow sets:\n     *\n     * FOLLOW(b1_in_a) = FIRST(']') = ']'\n     * FOLLOW(b2_in_a) = FIRST(')') = ')'\n     * FOLLOW(c_in_b) = FIRST('^') = '^'\n     *\n     * Upon erroneous input \"[]\", the call chain is\n     *\n     * a -> b -> c\n     *\n     * and, hence, the follow context stack is:\n     *\n     * depth follow set start of rule execution\n     * 0 <EOF> a (from main())\n     * 1 ']' b\n     * 2 '^' c\n     *\n     * Notice that ')' is not included, because b would have to have\n     * been called from a different context in rule a for ')' to be\n     * included.\n     *\n     * For error recovery, we cannot consider FOLLOW(c)\n     * (context-sensitive or otherwise). We need the combined set of\n     * all context-sensitive FOLLOW sets--the set of all tokens that\n     * could follow any reference in the call chain. We need to\n     * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n     * we resync'd to that token, we'd consume until EOF. We need to\n     * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n     * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n     * not consume anything. After printing an error, rule c would\n     * return normally. Rule b would not find the required '^' though.\n     * At this point, it gets a mismatched token error and throws an\n     * exception (since LA(1) is not in the viable following token\n     * set). The rule exception handler tries to recover, but finds\n     * the same recovery set and doesn't consume anything. Rule b\n     * exits normally returning to rule a. Now it finds the ']' (and\n     * with the successful match exits errorRecovery mode).\n     *\n     * So, you can see that the parser walks up the call chain looking\n     * for the token that was a member of the recovery set.\n     *\n     * Errors are not generated in errorRecovery mode.\n     *\n     * ANTLR's error recovery mechanism is based upon original ideas:\n     *\n     * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n     *\n     * and\n     *\n     * \"A note on error recovery in recursive descent parsers\":\n     * http://portal.acm.org/citation.cfm?id=947902.947905\n     *\n     * Later, Josef Grosch had some good ideas:\n     *\n     * \"Efficient and Comfortable Error Recovery in Recursive Descent\n     * Parsers\":\n     * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n     *\n     * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n     * at run-time upon error to avoid overhead during parsing.\n     */\n    getErrorRecoverySet(recognizer) {\n        const atn = recognizer._interp.atn\n        let ctx = recognizer._ctx\n        const recoverSet = new IntervalSet()\n        while (ctx !== null && ctx.invokingState>=0) {\n            // compute what follows who invoked us\n            const invokingState = atn.states[ctx.invokingState]\n            const rt = invokingState.transitions[0]\n            const follow = atn.nextTokens(rt.followState)\n            recoverSet.addSet(follow);\n            ctx = ctx.parentCtx;\n        }\n        recoverSet.removeOne(Token.EPSILON);\n        return recoverSet;\n    }\n\n// Consume tokens until one matches the given token set.//\n    consumeUntil(recognizer, set) {\n        let ttype = recognizer.getTokenStream().LA(1)\n        while( ttype !== Token.EOF && !set.contains(ttype)) {\n            recognizer.consume();\n            ttype = recognizer.getTokenStream().LA(1);\n        }\n    }\n}\n\n\n/**\n * This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n * by immediately canceling the parse operation with a\n * {@link ParseCancellationException}. The implementation ensures that the\n * {@link ParserRuleContext//exception} field is set for all parse tree nodes\n * that were not completed prior to encountering the error.\n *\n * <p>\n * This error strategy is useful in the following scenarios.</p>\n *\n * <ul>\n * <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n * stage of two-stage parsing to immediately terminate if an error is\n * encountered, and immediately fall back to the second stage. In addition to\n * avoiding wasted work by attempting to recover from errors here, the empty\n * implementation of {@link BailErrorStrategy//sync} improves the performance of\n * the first stage.</li>\n * <li><strong>Silent validation:</strong> When syntax errors are not being\n * reported or logged, and the parse result is simply ignored if errors occur,\n * the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n * when the result will be ignored either way.</li>\n * </ul>\n *\n * <p>\n * {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n *\n * @see Parser//setErrorHandler(ANTLRErrorStrategy)\n * */\nclass BailErrorStrategy extends DefaultErrorStrategy {\n    constructor() {\n        super();\n    }\n\n    /**\n     * Instead of recovering from exception {@code e}, re-throw it wrapped\n     * in a {@link ParseCancellationException} so it is not caught by the\n     * rule function catches. Use {@link Exception//getCause()} to get the\n     * original {@link RecognitionException}.\n     */\n    recover(recognizer, e) {\n        let context = recognizer._ctx\n        while (context !== null) {\n            context.exception = e;\n            context = context.parentCtx;\n        }\n        throw new ParseCancellationException(e);\n    }\n\n    /**\n     * Make sure we don't attempt to recover inline; if the parser\n     * successfully recovers, it won't throw an exception.\n     */\n    recoverInline(recognizer) {\n        this.recover(recognizer, new InputMismatchException(recognizer));\n    }\n\n// Make sure we don't attempt to recover from problems in subrules.//\n    sync(recognizer) {\n        // pass\n    }\n}\n\n\nmodule.exports = {BailErrorStrategy, DefaultErrorStrategy};\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n *  3 kinds of errors: prediction errors, failed predicate errors, and\n *  mismatched input errors. In each case, the parser knows where it is\n *  in the input, where it is in the ATN, the rule invocation stack,\n *  and what kind of problem occurred.\n */\n\nconst {PredicateTransition} = require('./../atn/Transition');\nconst {Interval} = require('../IntervalSet').Interval;\n\nclass RecognitionException extends Error {\n    constructor(params) {\n        super(params.message);\n        if (!!Error.captureStackTrace) {\n            Error.captureStackTrace(this, RecognitionException);\n        } else {\n            var stack = new Error().stack;\n        }\n        this.message = params.message;\n        this.recognizer = params.recognizer;\n        this.input = params.input;\n        this.ctx = params.ctx;\n        /**\n         * The current {@link Token} when an error occurred. Since not all streams\n         * support accessing symbols by index, we have to track the {@link Token}\n         * instance itself\n        */\n        this.offendingToken = null;\n        /**\n         * Get the ATN state number the parser was in at the time the error\n         * occurred. For {@link NoViableAltException} and\n         * {@link LexerNoViableAltException} exceptions, this is the\n         * {@link DecisionState} number. For others, it is the state whose outgoing\n         * edge we couldn't match.\n         */\n        this.offendingState = -1;\n        if (this.recognizer!==null) {\n            this.offendingState = this.recognizer.state;\n        }\n    }\n\n    /**\n     * Gets the set of input symbols which could potentially follow the\n     * previously matched symbol at the time this exception was thrown.\n     *\n     * <p>If the set of expected tokens is not known and could not be computed,\n     * this method returns {@code null}.</p>\n     *\n     * @return The set of token types that could potentially follow the current\n     * state in the ATN, or {@code null} if the information is not available.\n     */\n    getExpectedTokens() {\n        if (this.recognizer!==null) {\n            return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n        } else {\n            return null;\n        }\n    }\n\n    // <p>If the state number is not known, this method returns -1.</p>\n    toString() {\n        return this.message;\n    }\n}\n\nclass LexerNoViableAltException extends RecognitionException {\n    constructor(lexer, input, startIndex, deadEndConfigs) {\n        super({message: \"\", recognizer: lexer, input: input, ctx: null});\n        this.startIndex = startIndex;\n        this.deadEndConfigs = deadEndConfigs;\n    }\n\n    toString() {\n        let symbol = \"\";\n        if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n            symbol = this.input.getText(new Interval(this.startIndex,this.startIndex));\n        }\n        return \"LexerNoViableAltException\" + symbol;\n    }\n}\n\n\n/**\n * Indicates that the parser could not decide which of two or more paths\n * to take based upon the remaining input. It tracks the starting token\n * of the offending input and also knows where the parser was\n * in the various paths when the error. Reported by reportNoViableAlternative()\n */\nclass NoViableAltException extends RecognitionException {\n    constructor(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n        ctx = ctx || recognizer._ctx;\n        offendingToken = offendingToken || recognizer.getCurrentToken();\n        startToken = startToken || recognizer.getCurrentToken();\n        input = input || recognizer.getInputStream();\n        super({message: \"\", recognizer: recognizer, input: input, ctx: ctx});\n        // Which configurations did we try at input.index() that couldn't match\n        // input.LT(1)?//\n        this.deadEndConfigs = deadEndConfigs;\n        // The token object at the start index; the input stream might\n        // not be buffering tokens so get a reference to it. (At the\n        // time the error occurred, of course the stream needs to keep a\n        // buffer all of the tokens but later we might not have access to those.)\n        this.startToken = startToken;\n        this.offendingToken = offendingToken;\n    }\n}\n\n/**\n * This signifies any kind of mismatched input exceptions such as\n * when the current input does not match the expected token.\n*/\nclass InputMismatchException extends RecognitionException {\n    constructor(recognizer) {\n        super({message: \"\", recognizer: recognizer, input: recognizer.getInputStream(), ctx: recognizer._ctx});\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\nfunction formatMessage(predicate, message) {\n    if (message !==null) {\n        return message;\n    } else {\n        return \"failed predicate: {\" + predicate + \"}?\";\n    }\n}\n\n/**\n * A semantic predicate failed during validation. Validation of predicates\n * occurs when normally parsing the alternative just like matching a token.\n * Disambiguating predicate evaluation occurs when we test a predicate during\n * prediction.\n*/\nclass FailedPredicateException extends RecognitionException {\n    constructor(recognizer, predicate, message) {\n        super({\n            message: formatMessage(predicate, message || null), recognizer: recognizer,\n            input: recognizer.getInputStream(), ctx: recognizer._ctx\n        });\n        const s = recognizer._interp.atn.states[recognizer.state]\n        const trans = s.transitions[0]\n        if (trans instanceof PredicateTransition) {\n            this.ruleIndex = trans.ruleIndex;\n            this.predicateIndex = trans.predIndex;\n        } else {\n            this.ruleIndex = 0;\n            this.predicateIndex = 0;\n        }\n        this.predicate = predicate;\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\n\nclass ParseCancellationException extends Error{\n    constructor() {\n        super()\n        Error.captureStackTrace(this, ParseCancellationException);\n    }\n}\n\nmodule.exports = {\n    RecognitionException,\n    NoViableAltException,\n    LexerNoViableAltException,\n    InputMismatchException,\n    FailedPredicateException,\n    ParseCancellationException\n};\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nmodule.exports.RecognitionException = require('./Errors').RecognitionException;\nmodule.exports.NoViableAltException = require('./Errors').NoViableAltException;\nmodule.exports.LexerNoViableAltException = require('./Errors').LexerNoViableAltException;\nmodule.exports.InputMismatchException = require('./Errors').InputMismatchException;\nmodule.exports.FailedPredicateException = require('./Errors').FailedPredicateException;\nmodule.exports.DiagnosticErrorListener = require('./DiagnosticErrorListener');\nmodule.exports.BailErrorStrategy = require('./ErrorStrategy').BailErrorStrategy;\nmodule.exports.DefaultErrorStrategy = require('./ErrorStrategy').DefaultErrorStrategy;\nmodule.exports.ErrorListener = require('./ErrorListener').ErrorListener;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexports.atn = require('./atn/index');\nexports.codepointat = require('./polyfills/codepointat');\nexports.dfa = require('./dfa/index');\nexports.fromcodepoint = require('./polyfills/fromcodepoint');\nexports.tree = require('./tree/index');\nexports.error = require('./error/index');\nexports.Token = require('./Token').Token;\nexports.CharStreams = require('./CharStreams');\nexports.CommonToken = require('./Token').CommonToken;\nexports.InputStream = require('./InputStream');\nexports.FileStream = require('./FileStream');\nexports.CommonTokenStream = require('./CommonTokenStream');\nexports.Lexer = require('./Lexer');\nexports.Parser = require('./Parser');\nvar pc = require('./PredictionContext');\nexports.PredictionContextCache = pc.PredictionContextCache;\nexports.ParserRuleContext = require('./ParserRuleContext');\nexports.Interval = require('./IntervalSet').Interval;\nexports.IntervalSet = require('./IntervalSet').IntervalSet;\nexports.Utils = require('./Utils');\nexports.LL1Analyzer = require('./LL1Analyzer').LL1Analyzer;\n","/*! https://mths.be/codepointat v0.2.0 by @mathias */\nif (!String.prototype.codePointAt) {\n\t(function() {\n\t\t'use strict'; // needed to support `apply`/`call` with `undefined`/`null`\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\tlet result;\n\t\t\ttry {\n\t\t\t\tconst object = {};\n\t\t\t\tconst $defineProperty = Object.defineProperty;\n\t\t\t\tresult = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {\n\t\t\t}\n\t\t\treturn result;\n\t\t}());\n\t\tconst codePointAt = function(position) {\n\t\t\tif (this == null) {\n\t\t\t\tthrow TypeError();\n\t\t\t}\n\t\t\tconst string = String(this);\n\t\t\tconst size = string.length;\n\t\t\t// `ToInteger`\n\t\t\tlet index = position ? Number(position) : 0;\n\t\t\tif (index !== index) { // better `isNaN`\n\t\t\t\tindex = 0;\n\t\t\t}\n\t\t\t// Account for out-of-bounds indices:\n\t\t\tif (index < 0 || index >= size) {\n\t\t\t\treturn undefined;\n\t\t\t}\n\t\t\t// Get the first code unit\n\t\t\tconst first = string.charCodeAt(index);\n\t\t\tlet second;\n\t\t\tif ( // check if it’s the start of a surrogate pair\n\t\t\t\tfirst >= 0xD800 && first <= 0xDBFF && // high surrogate\n\t\t\t\tsize > index + 1 // there is a next code unit\n\t\t\t) {\n\t\t\t\tsecond = string.charCodeAt(index + 1);\n\t\t\t\tif (second >= 0xDC00 && second <= 0xDFFF) { // low surrogate\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\treturn (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn first;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String.prototype, 'codePointAt', {\n\t\t\t\t'value': codePointAt,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.prototype.codePointAt = codePointAt;\n\t\t}\n\t}());\n}\n","/*! https://mths.be/fromcodepoint v0.2.1 by @mathias */\nif (!String.fromCodePoint) {\n\t(function() {\n\t\tconst defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\tlet result;\n\t\t\ttry {\n\t\t\t\tconst object = {};\n\t\t\t\tconst $defineProperty = Object.defineProperty;\n\t\t\t\tresult = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tconst stringFromCharCode = String.fromCharCode;\n\t\tconst floor = Math.floor;\n\t\tconst fromCodePoint = function(_) {\n\t\t\tconst MAX_SIZE = 0x4000;\n\t\t\tconst codeUnits = [];\n\t\t\tlet highSurrogate;\n\t\t\tlet lowSurrogate;\n\t\t\tlet index = -1;\n\t\t\tconst length = arguments.length;\n\t\t\tif (!length) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\tlet result = '';\n\t\t\twhile (++index < length) {\n\t\t\t\tlet codePoint = Number(arguments[index]);\n\t\t\t\tif (\n\t\t\t\t\t!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`\n\t\t\t\t\tcodePoint < 0 || // not a valid Unicode code point\n\t\t\t\t\tcodePoint > 0x10FFFF || // not a valid Unicode code point\n\t\t\t\t\tfloor(codePoint) !== codePoint // not an integer\n\t\t\t\t) {\n\t\t\t\t\tthrow RangeError('Invalid code point: ' + codePoint);\n\t\t\t\t}\n\t\t\t\tif (codePoint <= 0xFFFF) { // BMP code point\n\t\t\t\t\tcodeUnits.push(codePoint);\n\t\t\t\t} else { // Astral code point; split in surrogate halves\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\tcodePoint -= 0x10000;\n\t\t\t\t\thighSurrogate = (codePoint >> 10) + 0xD800;\n\t\t\t\t\tlowSurrogate = (codePoint % 0x400) + 0xDC00;\n\t\t\t\t\tcodeUnits.push(highSurrogate, lowSurrogate);\n\t\t\t\t}\n\t\t\t\tif (index + 1 === length || codeUnits.length > MAX_SIZE) {\n\t\t\t\t\tresult += stringFromCharCode.apply(null, codeUnits);\n\t\t\t\t\tcodeUnits.length = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String, 'fromCodePoint', {\n\t\t\t\t'value': fromCodePoint,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.fromCodePoint = fromCodePoint;\n\t\t}\n\t}());\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst {Interval} = require('./../IntervalSet');\nconst INVALID_INTERVAL = new Interval(-1, -2);\n\n/**\n * The basic notion of a tree has a parent, a payload, and a list of children.\n * It is the most abstract interface for all the trees used by ANTLR.\n */\nclass Tree {}\n\nclass SyntaxTree extends Tree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ParseTree extends SyntaxTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass RuleNode extends ParseTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetRuleContext(){\n\t\tthrow new Error(\"missing interface implementation\")\n\t}\n}\n\nclass TerminalNode extends ParseTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ErrorNode extends TerminalNode {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ParseTreeVisitor {\n\tvisit(ctx) {\n\t\t if (Array.isArray(ctx)) {\n\t\t\treturn ctx.map(function(child) {\n\t\t\t\treturn child.accept(this);\n\t\t\t}, this);\n\t\t} else {\n\t\t\treturn ctx.accept(this);\n\t\t}\n\t}\n\n\tvisitChildren(ctx) {\n\t\tif (ctx.children) {\n\t\t\treturn this.visit(ctx.children);\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tvisitTerminal(node) {\n\t}\n\n\tvisitErrorNode(node) {\n\t}\n}\n\nclass ParseTreeListener {\n\tvisitTerminal(node) {\n\t}\n\n\tvisitErrorNode(node) {\n\t}\n\n\tenterEveryRule(node) {\n\t}\n\n\texitEveryRule(node) {\n\t}\n}\n\nclass TerminalNodeImpl extends TerminalNode {\n\tconstructor(symbol) {\n\t\tsuper();\n\t\tthis.parentCtx = null;\n\t\tthis.symbol = symbol;\n\t}\n\n\tgetChild(i) {\n\t\treturn null;\n\t}\n\n\tgetSymbol() {\n\t\treturn this.symbol;\n\t}\n\n\tgetParent() {\n\t\treturn this.parentCtx;\n\t}\n\n\tgetPayload() {\n\t\treturn this.symbol;\n\t}\n\n\tgetSourceInterval() {\n\t\tif (this.symbol === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t}\n\t\tconst tokenIndex = this.symbol.tokenIndex;\n\t\treturn new Interval(tokenIndex, tokenIndex);\n\t}\n\n\tgetChildCount() {\n\t\treturn 0;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitTerminal(this);\n\t}\n\n\tgetText() {\n\t\treturn this.symbol.text;\n\t}\n\n\ttoString() {\n\t\tif (this.symbol.type === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else {\n\t\t\treturn this.symbol.text;\n\t\t}\n\t}\n}\n\n\n/**\n * Represents a token that was consumed during resynchronization\n * rather than during a valid match operation. For example,\n * we will create this kind of a node during single token insertion\n * and deletion as well as during \"consume until error recovery set\"\n * upon no viable alternative exceptions.\n */\nclass ErrorNodeImpl extends TerminalNodeImpl {\n\tconstructor(token) {\n\t\tsuper(token);\n\t}\n\n\tisErrorNode() {\n\t\treturn true;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitErrorNode(this);\n\t}\n}\n\nclass ParseTreeWalker {\n\n\t/**\n\t * Performs a walk on the given parse tree starting at the root and going down recursively\n\t * with depth-first search. On each node, {@link ParseTreeWalker//enterRule} is called before\n\t * recursively walking down into child nodes, then\n\t * {@link ParseTreeWalker//exitRule} is called after the recursive call to wind up.\n\t * @param listener The listener used by the walker to process grammar rules\n\t * @param t The parse tree to be walked on\n\t */\n\twalk(listener, t) {\n\t\tconst errorNode = t instanceof ErrorNode ||\n\t\t\t\t(t.isErrorNode !== undefined && t.isErrorNode());\n\t\tif (errorNode) {\n\t\t\tlistener.visitErrorNode(t);\n\t\t} else if (t instanceof TerminalNode) {\n\t\t\tlistener.visitTerminal(t);\n\t\t} else {\n\t\t\tthis.enterRule(listener, t);\n\t\t\tfor (let i = 0; i < t.getChildCount(); i++) {\n\t\t\t\tconst child = t.getChild(i);\n\t\t\t\tthis.walk(listener, child);\n\t\t\t}\n\t\t\tthis.exitRule(listener, t);\n\t\t}\n\t}\n\n\t/**\n\t * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener//enterEveryRule}\n\t * then by triggering the event specific to the given parse tree node\n\t * @param listener The listener responding to the trigger events\n\t * @param r The grammar rule containing the rule context\n\t */\n\tenterRule(listener, r) {\n\t\tconst ctx = r.getRuleContext();\n\t\tlistener.enterEveryRule(ctx);\n\t\tctx.enterRule(listener);\n\t}\n\n\t/**\n\t * Exits a grammar rule by first triggering the event specific to the given parse tree node\n\t * then by triggering the generic event {@link ParseTreeListener//exitEveryRule}\n\t * @param listener The listener responding to the trigger events\n\t * @param r The grammar rule containing the rule context\n\t */\n\texitRule(listener, r) {\n\t\tconst ctx = r.getRuleContext();\n\t\tctx.exitRule(listener);\n\t\tlistener.exitEveryRule(ctx);\n\t}\n}\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n\nmodule.exports = {\n\tRuleNode,\n\tErrorNode,\n\tTerminalNode,\n\tErrorNodeImpl,\n\tTerminalNodeImpl,\n\tParseTreeListener,\n\tParseTreeVisitor,\n\tParseTreeWalker,\n\tINVALID_INTERVAL\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Utils = require('./../Utils');\nconst {Token} = require('./../Token');\nconst {ErrorNode, TerminalNode, RuleNode} = require('./Tree');\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nconst Trees = {\n    /**\n     * Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n     *  node payloads to get the text for the nodes.  Detect\n     *  parse trees and extract data appropriately.\n     */\n    toStringTree: function(tree, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        let s = Trees.getNodeText(tree, ruleNames);\n        s = Utils.escapeWhitespace(s, false);\n        const c = tree.getChildCount();\n        if(c===0) {\n            return s;\n        }\n        let res = \"(\" + s + ' ';\n        if(c>0) {\n            s = Trees.toStringTree(tree.getChild(0), ruleNames);\n            res = res.concat(s);\n        }\n        for(let i=1;i<c;i++) {\n            s = Trees.toStringTree(tree.getChild(i), ruleNames);\n            res = res.concat(' ' + s);\n        }\n        res = res.concat(\")\");\n        return res;\n    },\n\n    getNodeText: function(t, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        if(ruleNames!==null) {\n            if (t instanceof RuleNode) {\n                const context = t.getRuleContext()\n                const altNumber = context.getAltNumber();\n                // use const value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n                if ( altNumber != 0 ) {\n                    return ruleNames[t.ruleIndex]+\":\"+altNumber;\n                }\n                return ruleNames[t.ruleIndex];\n            } else if ( t instanceof ErrorNode) {\n                return t.toString();\n            } else if(t instanceof TerminalNode) {\n                if(t.symbol!==null) {\n                    return t.symbol.text;\n                }\n            }\n        }\n        // no recog for rule names\n        const payload = t.getPayload();\n        if (payload instanceof Token ) {\n            return payload.text;\n        }\n        return t.getPayload().toString();\n    },\n\n    /**\n     * Return ordered list of all children of this node\n     */\n    getChildren: function(t) {\n        const list = [];\n        for(let i=0;i<t.getChildCount();i++) {\n            list.push(t.getChild(i));\n        }\n        return list;\n    },\n\n    /**\n     * Return a list of all ancestors of this node.  The first node of\n     * list is the root and the last is the parent of this node.\n     */\n    getAncestors: function(t) {\n        let ancestors = [];\n        t = t.getParent();\n        while(t!==null) {\n            ancestors = [t].concat(ancestors);\n            t = t.getParent();\n        }\n        return ancestors;\n    },\n\n    findAllTokenNodes: function(t, ttype) {\n        return Trees.findAllNodes(t, ttype, true);\n    },\n\n    findAllRuleNodes: function(t, ruleIndex) {\n        return Trees.findAllNodes(t, ruleIndex, false);\n    },\n\n    findAllNodes: function(t, index, findTokens) {\n        const nodes = [];\n        Trees._findAllNodes(t, index, findTokens, nodes);\n        return nodes;\n    },\n\n    _findAllNodes: function(t, index, findTokens, nodes) {\n        // check this node (the root) first\n        if(findTokens && (t instanceof TerminalNode)) {\n            if(t.symbol.type===index) {\n                nodes.push(t);\n            }\n        } else if(!findTokens && (t instanceof RuleNode)) {\n            if(t.ruleIndex===index) {\n                nodes.push(t);\n            }\n        }\n        // check children\n        for(let i=0;i<t.getChildCount();i++) {\n            Trees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n        }\n    },\n\n    descendants: function(t) {\n        let nodes = [t];\n        for(let i=0;i<t.getChildCount();i++) {\n            nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n        }\n        return nodes;\n    }\n}\n\nmodule.exports = Trees;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Tree = require('./Tree');\nconst Trees = require('./Trees');\nmodule.exports = {...Tree, Trees}\n","(function(exports) {\n  \"use strict\";\n\n  function isArray(obj) {\n    if (obj !== null) {\n      return Object.prototype.toString.call(obj) === \"[object Array]\";\n    } else {\n      return false;\n    }\n  }\n\n  function isObject(obj) {\n    if (obj !== null) {\n      return Object.prototype.toString.call(obj) === \"[object Object]\";\n    } else {\n      return false;\n    }\n  }\n\n  function strictDeepEqual(first, second) {\n    // Check the scalar case first.\n    if (first === second) {\n      return true;\n    }\n\n    // Check if they are the same type.\n    var firstType = Object.prototype.toString.call(first);\n    if (firstType !== Object.prototype.toString.call(second)) {\n      return false;\n    }\n    // We know that first and second have the same type so we can just check the\n    // first type from now on.\n    if (isArray(first) === true) {\n      // Short circuit if they're not the same length;\n      if (first.length !== second.length) {\n        return false;\n      }\n      for (var i = 0; i < first.length; i++) {\n        if (strictDeepEqual(first[i], second[i]) === false) {\n          return false;\n        }\n      }\n      return true;\n    }\n    if (isObject(first) === true) {\n      // An object is equal if it has the same key/value pairs.\n      var keysSeen = {};\n      for (var key in first) {\n        if (hasOwnProperty.call(first, key)) {\n          if (strictDeepEqual(first[key], second[key]) === false) {\n            return false;\n          }\n          keysSeen[key] = true;\n        }\n      }\n      // Now check that there aren't any keys in second that weren't\n      // in first.\n      for (var key2 in second) {\n        if (hasOwnProperty.call(second, key2)) {\n          if (keysSeen[key2] !== true) {\n            return false;\n          }\n        }\n      }\n      return true;\n    }\n    return false;\n  }\n\n  function isFalse(obj) {\n    // From the spec:\n    // A false value corresponds to the following values:\n    // Empty list\n    // Empty object\n    // Empty string\n    // False boolean\n    // null value\n\n    // First check the scalar values.\n    if (obj === \"\" || obj === false || obj === null) {\n        return true;\n    } else if (isArray(obj) && obj.length === 0) {\n        // Check for an empty array.\n        return true;\n    } else if (isObject(obj)) {\n        // Check for an empty object.\n        for (var key in obj) {\n            // If there are any keys, then\n            // the object is not empty so the object\n            // is not false.\n            if (obj.hasOwnProperty(key)) {\n              return false;\n            }\n        }\n        return true;\n    } else {\n        return false;\n    }\n  }\n\n  function objValues(obj) {\n    var keys = Object.keys(obj);\n    var values = [];\n    for (var i = 0; i < keys.length; i++) {\n      values.push(obj[keys[i]]);\n    }\n    return values;\n  }\n\n  function merge(a, b) {\n      var merged = {};\n      for (var key in a) {\n          merged[key] = a[key];\n      }\n      for (var key2 in b) {\n          merged[key2] = b[key2];\n      }\n      return merged;\n  }\n\n  var trimLeft;\n  if (typeof String.prototype.trimLeft === \"function\") {\n    trimLeft = function(str) {\n      return str.trimLeft();\n    };\n  } else {\n    trimLeft = function(str) {\n      return str.match(/^\\s*(.*)/)[1];\n    };\n  }\n\n  // Type constants used to define functions.\n  var TYPE_NUMBER = 0;\n  var TYPE_ANY = 1;\n  var TYPE_STRING = 2;\n  var TYPE_ARRAY = 3;\n  var TYPE_OBJECT = 4;\n  var TYPE_BOOLEAN = 5;\n  var TYPE_EXPREF = 6;\n  var TYPE_NULL = 7;\n  var TYPE_ARRAY_NUMBER = 8;\n  var TYPE_ARRAY_STRING = 9;\n\n  var TOK_EOF = \"EOF\";\n  var TOK_UNQUOTEDIDENTIFIER = \"UnquotedIdentifier\";\n  var TOK_QUOTEDIDENTIFIER = \"QuotedIdentifier\";\n  var TOK_RBRACKET = \"Rbracket\";\n  var TOK_RPAREN = \"Rparen\";\n  var TOK_COMMA = \"Comma\";\n  var TOK_COLON = \"Colon\";\n  var TOK_RBRACE = \"Rbrace\";\n  var TOK_NUMBER = \"Number\";\n  var TOK_CURRENT = \"Current\";\n  var TOK_EXPREF = \"Expref\";\n  var TOK_PIPE = \"Pipe\";\n  var TOK_OR = \"Or\";\n  var TOK_AND = \"And\";\n  var TOK_EQ = \"EQ\";\n  var TOK_GT = \"GT\";\n  var TOK_LT = \"LT\";\n  var TOK_GTE = \"GTE\";\n  var TOK_LTE = \"LTE\";\n  var TOK_NE = \"NE\";\n  var TOK_FLATTEN = \"Flatten\";\n  var TOK_STAR = \"Star\";\n  var TOK_FILTER = \"Filter\";\n  var TOK_DOT = \"Dot\";\n  var TOK_NOT = \"Not\";\n  var TOK_LBRACE = \"Lbrace\";\n  var TOK_LBRACKET = \"Lbracket\";\n  var TOK_LPAREN= \"Lparen\";\n  var TOK_LITERAL= \"Literal\";\n\n  // The \"&\", \"[\", \"<\", \">\" tokens\n  // are not in basicToken because\n  // there are two token variants\n  // (\"&&\", \"[?\", \"<=\", \">=\").  This is specially handled\n  // below.\n\n  var basicTokens = {\n    \".\": TOK_DOT,\n    \"*\": TOK_STAR,\n    \",\": TOK_COMMA,\n    \":\": TOK_COLON,\n    \"{\": TOK_LBRACE,\n    \"}\": TOK_RBRACE,\n    \"]\": TOK_RBRACKET,\n    \"(\": TOK_LPAREN,\n    \")\": TOK_RPAREN,\n    \"@\": TOK_CURRENT\n  };\n\n  var operatorStartToken = {\n      \"<\": true,\n      \">\": true,\n      \"=\": true,\n      \"!\": true\n  };\n\n  var skipChars = {\n      \" \": true,\n      \"\\t\": true,\n      \"\\n\": true\n  };\n\n\n  function isAlpha(ch) {\n      return (ch >= \"a\" && ch <= \"z\") ||\n             (ch >= \"A\" && ch <= \"Z\") ||\n             ch === \"_\";\n  }\n\n  function isNum(ch) {\n      return (ch >= \"0\" && ch <= \"9\") ||\n             ch === \"-\";\n  }\n  function isAlphaNum(ch) {\n      return (ch >= \"a\" && ch <= \"z\") ||\n             (ch >= \"A\" && ch <= \"Z\") ||\n             (ch >= \"0\" && ch <= \"9\") ||\n             ch === \"_\";\n  }\n\n  function Lexer() {\n  }\n  Lexer.prototype = {\n      tokenize: function(stream) {\n          var tokens = [];\n          this._current = 0;\n          var start;\n          var identifier;\n          var token;\n          while (this._current < stream.length) {\n              if (isAlpha(stream[this._current])) {\n                  start = this._current;\n                  identifier = this._consumeUnquotedIdentifier(stream);\n                  tokens.push({type: TOK_UNQUOTEDIDENTIFIER,\n                               value: identifier,\n                               start: start});\n              } else if (basicTokens[stream[this._current]] !== undefined) {\n                  tokens.push({type: basicTokens[stream[this._current]],\n                              value: stream[this._current],\n                              start: this._current});\n                  this._current++;\n              } else if (isNum(stream[this._current])) {\n                  token = this._consumeNumber(stream);\n                  tokens.push(token);\n              } else if (stream[this._current] === \"[\") {\n                  // No need to increment this._current.  This happens\n                  // in _consumeLBracket\n                  token = this._consumeLBracket(stream);\n                  tokens.push(token);\n              } else if (stream[this._current] === \"\\\"\") {\n                  start = this._current;\n                  identifier = this._consumeQuotedIdentifier(stream);\n                  tokens.push({type: TOK_QUOTEDIDENTIFIER,\n                               value: identifier,\n                               start: start});\n              } else if (stream[this._current] === \"'\") {\n                  start = this._current;\n                  identifier = this._consumeRawStringLiteral(stream);\n                  tokens.push({type: TOK_LITERAL,\n                               value: identifier,\n                               start: start});\n              } else if (stream[this._current] === \"`\") {\n                  start = this._current;\n                  var literal = this._consumeLiteral(stream);\n                  tokens.push({type: TOK_LITERAL,\n                               value: literal,\n                               start: start});\n              } else if (operatorStartToken[stream[this._current]] !== undefined) {\n                  tokens.push(this._consumeOperator(stream));\n              } else if (skipChars[stream[this._current]] !== undefined) {\n                  // Ignore whitespace.\n                  this._current++;\n              } else if (stream[this._current] === \"&\") {\n                  start = this._current;\n                  this._current++;\n                  if (stream[this._current] === \"&\") {\n                      this._current++;\n                      tokens.push({type: TOK_AND, value: \"&&\", start: start});\n                  } else {\n                      tokens.push({type: TOK_EXPREF, value: \"&\", start: start});\n                  }\n              } else if (stream[this._current] === \"|\") {\n                  start = this._current;\n                  this._current++;\n                  if (stream[this._current] === \"|\") {\n                      this._current++;\n                      tokens.push({type: TOK_OR, value: \"||\", start: start});\n                  } else {\n                      tokens.push({type: TOK_PIPE, value: \"|\", start: start});\n                  }\n              } else {\n                  var error = new Error(\"Unknown character:\" + stream[this._current]);\n                  error.name = \"LexerError\";\n                  throw error;\n              }\n          }\n          return tokens;\n      },\n\n      _consumeUnquotedIdentifier: function(stream) {\n          var start = this._current;\n          this._current++;\n          while (this._current < stream.length && isAlphaNum(stream[this._current])) {\n              this._current++;\n          }\n          return stream.slice(start, this._current);\n      },\n\n      _consumeQuotedIdentifier: function(stream) {\n          var start = this._current;\n          this._current++;\n          var maxLength = stream.length;\n          while (stream[this._current] !== \"\\\"\" && this._current < maxLength) {\n              // You can escape a double quote and you can escape an escape.\n              var current = this._current;\n              if (stream[current] === \"\\\\\" && (stream[current + 1] === \"\\\\\" ||\n                                               stream[current + 1] === \"\\\"\")) {\n                  current += 2;\n              } else {\n                  current++;\n              }\n              this._current = current;\n          }\n          this._current++;\n          return JSON.parse(stream.slice(start, this._current));\n      },\n\n      _consumeRawStringLiteral: function(stream) {\n          var start = this._current;\n          this._current++;\n          var maxLength = stream.length;\n          while (stream[this._current] !== \"'\" && this._current < maxLength) {\n              // You can escape a single quote and you can escape an escape.\n              var current = this._current;\n              if (stream[current] === \"\\\\\" && (stream[current + 1] === \"\\\\\" ||\n                                               stream[current + 1] === \"'\")) {\n                  current += 2;\n              } else {\n                  current++;\n              }\n              this._current = current;\n          }\n          this._current++;\n          var literal = stream.slice(start + 1, this._current - 1);\n          return literal.replace(\"\\\\'\", \"'\");\n      },\n\n      _consumeNumber: function(stream) {\n          var start = this._current;\n          this._current++;\n          var maxLength = stream.length;\n          while (isNum(stream[this._current]) && this._current < maxLength) {\n              this._current++;\n          }\n          var value = parseInt(stream.slice(start, this._current));\n          return {type: TOK_NUMBER, value: value, start: start};\n      },\n\n      _consumeLBracket: function(stream) {\n          var start = this._current;\n          this._current++;\n          if (stream[this._current] === \"?\") {\n              this._current++;\n              return {type: TOK_FILTER, value: \"[?\", start: start};\n          } else if (stream[this._current] === \"]\") {\n              this._current++;\n              return {type: TOK_FLATTEN, value: \"[]\", start: start};\n          } else {\n              return {type: TOK_LBRACKET, value: \"[\", start: start};\n          }\n      },\n\n      _consumeOperator: function(stream) {\n          var start = this._current;\n          var startingChar = stream[start];\n          this._current++;\n          if (startingChar === \"!\") {\n              if (stream[this._current] === \"=\") {\n                  this._current++;\n                  return {type: TOK_NE, value: \"!=\", start: start};\n              } else {\n                return {type: TOK_NOT, value: \"!\", start: start};\n              }\n          } else if (startingChar === \"<\") {\n              if (stream[this._current] === \"=\") {\n                  this._current++;\n                  return {type: TOK_LTE, value: \"<=\", start: start};\n              } else {\n                  return {type: TOK_LT, value: \"<\", start: start};\n              }\n          } else if (startingChar === \">\") {\n              if (stream[this._current] === \"=\") {\n                  this._current++;\n                  return {type: TOK_GTE, value: \">=\", start: start};\n              } else {\n                  return {type: TOK_GT, value: \">\", start: start};\n              }\n          } else if (startingChar === \"=\") {\n              if (stream[this._current] === \"=\") {\n                  this._current++;\n                  return {type: TOK_EQ, value: \"==\", start: start};\n              }\n          }\n      },\n\n      _consumeLiteral: function(stream) {\n          this._current++;\n          var start = this._current;\n          var maxLength = stream.length;\n          var literal;\n          while(stream[this._current] !== \"`\" && this._current < maxLength) {\n              // You can escape a literal char or you can escape the escape.\n              var current = this._current;\n              if (stream[current] === \"\\\\\" && (stream[current + 1] === \"\\\\\" ||\n                                               stream[current + 1] === \"`\")) {\n                  current += 2;\n              } else {\n                  current++;\n              }\n              this._current = current;\n          }\n          var literalString = trimLeft(stream.slice(start, this._current));\n          literalString = literalString.replace(\"\\\\`\", \"`\");\n          if (this._looksLikeJSON(literalString)) {\n              literal = JSON.parse(literalString);\n          } else {\n              // Try to JSON parse it as \"<literal>\"\n              literal = JSON.parse(\"\\\"\" + literalString + \"\\\"\");\n          }\n          // +1 gets us to the ending \"`\", +1 to move on to the next char.\n          this._current++;\n          return literal;\n      },\n\n      _looksLikeJSON: function(literalString) {\n          var startingChars = \"[{\\\"\";\n          var jsonLiterals = [\"true\", \"false\", \"null\"];\n          var numberLooking = \"-0123456789\";\n\n          if (literalString === \"\") {\n              return false;\n          } else if (startingChars.indexOf(literalString[0]) >= 0) {\n              return true;\n          } else if (jsonLiterals.indexOf(literalString) >= 0) {\n              return true;\n          } else if (numberLooking.indexOf(literalString[0]) >= 0) {\n              try {\n                  JSON.parse(literalString);\n                  return true;\n              } catch (ex) {\n                  return false;\n              }\n          } else {\n              return false;\n          }\n      }\n  };\n\n      var bindingPower = {};\n      bindingPower[TOK_EOF] = 0;\n      bindingPower[TOK_UNQUOTEDIDENTIFIER] = 0;\n      bindingPower[TOK_QUOTEDIDENTIFIER] = 0;\n      bindingPower[TOK_RBRACKET] = 0;\n      bindingPower[TOK_RPAREN] = 0;\n      bindingPower[TOK_COMMA] = 0;\n      bindingPower[TOK_RBRACE] = 0;\n      bindingPower[TOK_NUMBER] = 0;\n      bindingPower[TOK_CURRENT] = 0;\n      bindingPower[TOK_EXPREF] = 0;\n      bindingPower[TOK_PIPE] = 1;\n      bindingPower[TOK_OR] = 2;\n      bindingPower[TOK_AND] = 3;\n      bindingPower[TOK_EQ] = 5;\n      bindingPower[TOK_GT] = 5;\n      bindingPower[TOK_LT] = 5;\n      bindingPower[TOK_GTE] = 5;\n      bindingPower[TOK_LTE] = 5;\n      bindingPower[TOK_NE] = 5;\n      bindingPower[TOK_FLATTEN] = 9;\n      bindingPower[TOK_STAR] = 20;\n      bindingPower[TOK_FILTER] = 21;\n      bindingPower[TOK_DOT] = 40;\n      bindingPower[TOK_NOT] = 45;\n      bindingPower[TOK_LBRACE] = 50;\n      bindingPower[TOK_LBRACKET] = 55;\n      bindingPower[TOK_LPAREN] = 60;\n\n  function Parser() {\n  }\n\n  Parser.prototype = {\n      parse: function(expression) {\n          this._loadTokens(expression);\n          this.index = 0;\n          var ast = this.expression(0);\n          if (this._lookahead(0) !== TOK_EOF) {\n              var t = this._lookaheadToken(0);\n              var error = new Error(\n                  \"Unexpected token type: \" + t.type + \", value: \" + t.value);\n              error.name = \"ParserError\";\n              throw error;\n          }\n          return ast;\n      },\n\n      _loadTokens: function(expression) {\n          var lexer = new Lexer();\n          var tokens = lexer.tokenize(expression);\n          tokens.push({type: TOK_EOF, value: \"\", start: expression.length});\n          this.tokens = tokens;\n      },\n\n      expression: function(rbp) {\n          var leftToken = this._lookaheadToken(0);\n          this._advance();\n          var left = this.nud(leftToken);\n          var currentToken = this._lookahead(0);\n          while (rbp < bindingPower[currentToken]) {\n              this._advance();\n              left = this.led(currentToken, left);\n              currentToken = this._lookahead(0);\n          }\n          return left;\n      },\n\n      _lookahead: function(number) {\n          return this.tokens[this.index + number].type;\n      },\n\n      _lookaheadToken: function(number) {\n          return this.tokens[this.index + number];\n      },\n\n      _advance: function() {\n          this.index++;\n      },\n\n      nud: function(token) {\n        var left;\n        var right;\n        var expression;\n        switch (token.type) {\n          case TOK_LITERAL:\n            return {type: \"Literal\", value: token.value};\n          case TOK_UNQUOTEDIDENTIFIER:\n            return {type: \"Field\", name: token.value};\n          case TOK_QUOTEDIDENTIFIER:\n            var node = {type: \"Field\", name: token.value};\n            if (this._lookahead(0) === TOK_LPAREN) {\n                throw new Error(\"Quoted identifier not allowed for function names.\");\n            } else {\n                return node;\n            }\n            break;\n          case TOK_NOT:\n            right = this.expression(bindingPower.Not);\n            return {type: \"NotExpression\", children: [right]};\n          case TOK_STAR:\n            left = {type: \"Identity\"};\n            right = null;\n            if (this._lookahead(0) === TOK_RBRACKET) {\n                // This can happen in a multiselect,\n                // [a, b, *]\n                right = {type: \"Identity\"};\n            } else {\n                right = this._parseProjectionRHS(bindingPower.Star);\n            }\n            return {type: \"ValueProjection\", children: [left, right]};\n          case TOK_FILTER:\n            return this.led(token.type, {type: \"Identity\"});\n          case TOK_LBRACE:\n            return this._parseMultiselectHash();\n          case TOK_FLATTEN:\n            left = {type: TOK_FLATTEN, children: [{type: \"Identity\"}]};\n            right = this._parseProjectionRHS(bindingPower.Flatten);\n            return {type: \"Projection\", children: [left, right]};\n          case TOK_LBRACKET:\n            if (this._lookahead(0) === TOK_NUMBER || this._lookahead(0) === TOK_COLON) {\n                right = this._parseIndexExpression();\n                return this._projectIfSlice({type: \"Identity\"}, right);\n            } else if (this._lookahead(0) === TOK_STAR &&\n                       this._lookahead(1) === TOK_RBRACKET) {\n                this._advance();\n                this._advance();\n                right = this._parseProjectionRHS(bindingPower.Star);\n                return {type: \"Projection\",\n                        children: [{type: \"Identity\"}, right]};\n            } else {\n                return this._parseMultiselectList();\n            }\n            break;\n          case TOK_CURRENT:\n            return {type: TOK_CURRENT};\n          case TOK_EXPREF:\n            expression = this.expression(bindingPower.Expref);\n            return {type: \"ExpressionReference\", children: [expression]};\n          case TOK_LPAREN:\n            var args = [];\n            while (this._lookahead(0) !== TOK_RPAREN) {\n              if (this._lookahead(0) === TOK_CURRENT) {\n                expression = {type: TOK_CURRENT};\n                this._advance();\n              } else {\n                expression = this.expression(0);\n              }\n              args.push(expression);\n            }\n            this._match(TOK_RPAREN);\n            return args[0];\n          default:\n            this._errorToken(token);\n        }\n      },\n\n      led: function(tokenName, left) {\n        var right;\n        switch(tokenName) {\n          case TOK_DOT:\n            var rbp = bindingPower.Dot;\n            if (this._lookahead(0) !== TOK_STAR) {\n                right = this._parseDotRHS(rbp);\n                return {type: \"Subexpression\", children: [left, right]};\n            } else {\n                // Creating a projection.\n                this._advance();\n                right = this._parseProjectionRHS(rbp);\n                return {type: \"ValueProjection\", children: [left, right]};\n            }\n            break;\n          case TOK_PIPE:\n            right = this.expression(bindingPower.Pipe);\n            return {type: TOK_PIPE, children: [left, right]};\n          case TOK_OR:\n            right = this.expression(bindingPower.Or);\n            return {type: \"OrExpression\", children: [left, right]};\n          case TOK_AND:\n            right = this.expression(bindingPower.And);\n            return {type: \"AndExpression\", children: [left, right]};\n          case TOK_LPAREN:\n            var name = left.name;\n            var args = [];\n            var expression, node;\n            while (this._lookahead(0) !== TOK_RPAREN) {\n              if (this._lookahead(0) === TOK_CURRENT) {\n                expression = {type: TOK_CURRENT};\n                this._advance();\n              } else {\n                expression = this.expression(0);\n              }\n              if (this._lookahead(0) === TOK_COMMA) {\n                this._match(TOK_COMMA);\n              }\n              args.push(expression);\n            }\n            this._match(TOK_RPAREN);\n            node = {type: \"Function\", name: name, children: args};\n            return node;\n          case TOK_FILTER:\n            var condition = this.expression(0);\n            this._match(TOK_RBRACKET);\n            if (this._lookahead(0) === TOK_FLATTEN) {\n              right = {type: \"Identity\"};\n            } else {\n              right = this._parseProjectionRHS(bindingPower.Filter);\n            }\n            return {type: \"FilterProjection\", children: [left, right, condition]};\n          case TOK_FLATTEN:\n            var leftNode = {type: TOK_FLATTEN, children: [left]};\n            var rightNode = this._parseProjectionRHS(bindingPower.Flatten);\n            return {type: \"Projection\", children: [leftNode, rightNode]};\n          case TOK_EQ:\n          case TOK_NE:\n          case TOK_GT:\n          case TOK_GTE:\n          case TOK_LT:\n          case TOK_LTE:\n            return this._parseComparator(left, tokenName);\n          case TOK_LBRACKET:\n            var token = this._lookaheadToken(0);\n            if (token.type === TOK_NUMBER || token.type === TOK_COLON) {\n                right = this._parseIndexExpression();\n                return this._projectIfSlice(left, right);\n            } else {\n                this._match(TOK_STAR);\n                this._match(TOK_RBRACKET);\n                right = this._parseProjectionRHS(bindingPower.Star);\n                return {type: \"Projection\", children: [left, right]};\n            }\n            break;\n          default:\n            this._errorToken(this._lookaheadToken(0));\n        }\n      },\n\n      _match: function(tokenType) {\n          if (this._lookahead(0) === tokenType) {\n              this._advance();\n          } else {\n              var t = this._lookaheadToken(0);\n              var error = new Error(\"Expected \" + tokenType + \", got: \" + t.type);\n              error.name = \"ParserError\";\n              throw error;\n          }\n      },\n\n      _errorToken: function(token) {\n          var error = new Error(\"Invalid token (\" +\n                                token.type + \"): \\\"\" +\n                                token.value + \"\\\"\");\n          error.name = \"ParserError\";\n          throw error;\n      },\n\n\n      _parseIndexExpression: function() {\n          if (this._lookahead(0) === TOK_COLON || this._lookahead(1) === TOK_COLON) {\n              return this._parseSliceExpression();\n          } else {\n              var node = {\n                  type: \"Index\",\n                  value: this._lookaheadToken(0).value};\n              this._advance();\n              this._match(TOK_RBRACKET);\n              return node;\n          }\n      },\n\n      _projectIfSlice: function(left, right) {\n          var indexExpr = {type: \"IndexExpression\", children: [left, right]};\n          if (right.type === \"Slice\") {\n              return {\n                  type: \"Projection\",\n                  children: [indexExpr, this._parseProjectionRHS(bindingPower.Star)]\n              };\n          } else {\n              return indexExpr;\n          }\n      },\n\n      _parseSliceExpression: function() {\n          // [start:end:step] where each part is optional, as well as the last\n          // colon.\n          var parts = [null, null, null];\n          var index = 0;\n          var currentToken = this._lookahead(0);\n          while (currentToken !== TOK_RBRACKET && index < 3) {\n              if (currentToken === TOK_COLON) {\n                  index++;\n                  this._advance();\n              } else if (currentToken === TOK_NUMBER) {\n                  parts[index] = this._lookaheadToken(0).value;\n                  this._advance();\n              } else {\n                  var t = this._lookahead(0);\n                  var error = new Error(\"Syntax error, unexpected token: \" +\n                                        t.value + \"(\" + t.type + \")\");\n                  error.name = \"Parsererror\";\n                  throw error;\n              }\n              currentToken = this._lookahead(0);\n          }\n          this._match(TOK_RBRACKET);\n          return {\n              type: \"Slice\",\n              children: parts\n          };\n      },\n\n      _parseComparator: function(left, comparator) {\n        var right = this.expression(bindingPower[comparator]);\n        return {type: \"Comparator\", name: comparator, children: [left, right]};\n      },\n\n      _parseDotRHS: function(rbp) {\n          var lookahead = this._lookahead(0);\n          var exprTokens = [TOK_UNQUOTEDIDENTIFIER, TOK_QUOTEDIDENTIFIER, TOK_STAR];\n          if (exprTokens.indexOf(lookahead) >= 0) {\n              return this.expression(rbp);\n          } else if (lookahead === TOK_LBRACKET) {\n              this._match(TOK_LBRACKET);\n              return this._parseMultiselectList();\n          } else if (lookahead === TOK_LBRACE) {\n              this._match(TOK_LBRACE);\n              return this._parseMultiselectHash();\n          }\n      },\n\n      _parseProjectionRHS: function(rbp) {\n          var right;\n          if (bindingPower[this._lookahead(0)] < 10) {\n              right = {type: \"Identity\"};\n          } else if (this._lookahead(0) === TOK_LBRACKET) {\n              right = this.expression(rbp);\n          } else if (this._lookahead(0) === TOK_FILTER) {\n              right = this.expression(rbp);\n          } else if (this._lookahead(0) === TOK_DOT) {\n              this._match(TOK_DOT);\n              right = this._parseDotRHS(rbp);\n          } else {\n              var t = this._lookaheadToken(0);\n              var error = new Error(\"Sytanx error, unexpected token: \" +\n                                    t.value + \"(\" + t.type + \")\");\n              error.name = \"ParserError\";\n              throw error;\n          }\n          return right;\n      },\n\n      _parseMultiselectList: function() {\n          var expressions = [];\n          while (this._lookahead(0) !== TOK_RBRACKET) {\n              var expression = this.expression(0);\n              expressions.push(expression);\n              if (this._lookahead(0) === TOK_COMMA) {\n                  this._match(TOK_COMMA);\n                  if (this._lookahead(0) === TOK_RBRACKET) {\n                    throw new Error(\"Unexpected token Rbracket\");\n                  }\n              }\n          }\n          this._match(TOK_RBRACKET);\n          return {type: \"MultiSelectList\", children: expressions};\n      },\n\n      _parseMultiselectHash: function() {\n        var pairs = [];\n        var identifierTypes = [TOK_UNQUOTEDIDENTIFIER, TOK_QUOTEDIDENTIFIER];\n        var keyToken, keyName, value, node;\n        for (;;) {\n          keyToken = this._lookaheadToken(0);\n          if (identifierTypes.indexOf(keyToken.type) < 0) {\n            throw new Error(\"Expecting an identifier token, got: \" +\n                            keyToken.type);\n          }\n          keyName = keyToken.value;\n          this._advance();\n          this._match(TOK_COLON);\n          value = this.expression(0);\n          node = {type: \"KeyValuePair\", name: keyName, value: value};\n          pairs.push(node);\n          if (this._lookahead(0) === TOK_COMMA) {\n            this._match(TOK_COMMA);\n          } else if (this._lookahead(0) === TOK_RBRACE) {\n            this._match(TOK_RBRACE);\n            break;\n          }\n        }\n        return {type: \"MultiSelectHash\", children: pairs};\n      }\n  };\n\n\n  function TreeInterpreter(runtime) {\n    this.runtime = runtime;\n  }\n\n  TreeInterpreter.prototype = {\n      search: function(node, value) {\n          return this.visit(node, value);\n      },\n\n      visit: function(node, value) {\n          var matched, current, result, first, second, field, left, right, collected, i;\n          switch (node.type) {\n            case \"Field\":\n              if (value === null ) {\n                  return null;\n              } else if (isObject(value)) {\n                  field = value[node.name];\n                  if (field === undefined) {\n                      return null;\n                  } else {\n                      return field;\n                  }\n              } else {\n                return null;\n              }\n              break;\n            case \"Subexpression\":\n              result = this.visit(node.children[0], value);\n              for (i = 1; i < node.children.length; i++) {\n                  result = this.visit(node.children[1], result);\n                  if (result === null) {\n                      return null;\n                  }\n              }\n              return result;\n            case \"IndexExpression\":\n              left = this.visit(node.children[0], value);\n              right = this.visit(node.children[1], left);\n              return right;\n            case \"Index\":\n              if (!isArray(value)) {\n                return null;\n              }\n              var index = node.value;\n              if (index < 0) {\n                index = value.length + index;\n              }\n              result = value[index];\n              if (result === undefined) {\n                result = null;\n              }\n              return result;\n            case \"Slice\":\n              if (!isArray(value)) {\n                return null;\n              }\n              var sliceParams = node.children.slice(0);\n              var computed = this.computeSliceParams(value.length, sliceParams);\n              var start = computed[0];\n              var stop = computed[1];\n              var step = computed[2];\n              result = [];\n              if (step > 0) {\n                  for (i = start; i < stop; i += step) {\n                      result.push(value[i]);\n                  }\n              } else {\n                  for (i = start; i > stop; i += step) {\n                      result.push(value[i]);\n                  }\n              }\n              return result;\n            case \"Projection\":\n              // Evaluate left child.\n              var base = this.visit(node.children[0], value);\n              if (!isArray(base)) {\n                return null;\n              }\n              collected = [];\n              for (i = 0; i < base.length; i++) {\n                current = this.visit(node.children[1], base[i]);\n                if (current !== null) {\n                  collected.push(current);\n                }\n              }\n              return collected;\n            case \"ValueProjection\":\n              // Evaluate left child.\n              base = this.visit(node.children[0], value);\n              if (!isObject(base)) {\n                return null;\n              }\n              collected = [];\n              var values = objValues(base);\n              for (i = 0; i < values.length; i++) {\n                current = this.visit(node.children[1], values[i]);\n                if (current !== null) {\n                  collected.push(current);\n                }\n              }\n              return collected;\n            case \"FilterProjection\":\n              base = this.visit(node.children[0], value);\n              if (!isArray(base)) {\n                return null;\n              }\n              var filtered = [];\n              var finalResults = [];\n              for (i = 0; i < base.length; i++) {\n                matched = this.visit(node.children[2], base[i]);\n                if (!isFalse(matched)) {\n                  filtered.push(base[i]);\n                }\n              }\n              for (var j = 0; j < filtered.length; j++) {\n                current = this.visit(node.children[1], filtered[j]);\n                if (current !== null) {\n                  finalResults.push(current);\n                }\n              }\n              return finalResults;\n            case \"Comparator\":\n              first = this.visit(node.children[0], value);\n              second = this.visit(node.children[1], value);\n              switch(node.name) {\n                case TOK_EQ:\n                  result = strictDeepEqual(first, second);\n                  break;\n                case TOK_NE:\n                  result = !strictDeepEqual(first, second);\n                  break;\n                case TOK_GT:\n                  result = first > second;\n                  break;\n                case TOK_GTE:\n                  result = first >= second;\n                  break;\n                case TOK_LT:\n                  result = first < second;\n                  break;\n                case TOK_LTE:\n                  result = first <= second;\n                  break;\n                default:\n                  throw new Error(\"Unknown comparator: \" + node.name);\n              }\n              return result;\n            case TOK_FLATTEN:\n              var original = this.visit(node.children[0], value);\n              if (!isArray(original)) {\n                return null;\n              }\n              var merged = [];\n              for (i = 0; i < original.length; i++) {\n                current = original[i];\n                if (isArray(current)) {\n                  merged.push.apply(merged, current);\n                } else {\n                  merged.push(current);\n                }\n              }\n              return merged;\n            case \"Identity\":\n              return value;\n            case \"MultiSelectList\":\n              if (value === null) {\n                return null;\n              }\n              collected = [];\n              for (i = 0; i < node.children.length; i++) {\n                  collected.push(this.visit(node.children[i], value));\n              }\n              return collected;\n            case \"MultiSelectHash\":\n              if (value === null) {\n                return null;\n              }\n              collected = {};\n              var child;\n              for (i = 0; i < node.children.length; i++) {\n                child = node.children[i];\n                collected[child.name] = this.visit(child.value, value);\n              }\n              return collected;\n            case \"OrExpression\":\n              matched = this.visit(node.children[0], value);\n              if (isFalse(matched)) {\n                  matched = this.visit(node.children[1], value);\n              }\n              return matched;\n            case \"AndExpression\":\n              first = this.visit(node.children[0], value);\n\n              if (isFalse(first) === true) {\n                return first;\n              }\n              return this.visit(node.children[1], value);\n            case \"NotExpression\":\n              first = this.visit(node.children[0], value);\n              return isFalse(first);\n            case \"Literal\":\n              return node.value;\n            case TOK_PIPE:\n              left = this.visit(node.children[0], value);\n              return this.visit(node.children[1], left);\n            case TOK_CURRENT:\n              return value;\n            case \"Function\":\n              var resolvedArgs = [];\n              for (i = 0; i < node.children.length; i++) {\n                  resolvedArgs.push(this.visit(node.children[i], value));\n              }\n              return this.runtime.callFunction(node.name, resolvedArgs);\n            case \"ExpressionReference\":\n              var refNode = node.children[0];\n              // Tag the node with a specific attribute so the type\n              // checker verify the type.\n              refNode.jmespathType = TOK_EXPREF;\n              return refNode;\n            default:\n              throw new Error(\"Unknown node type: \" + node.type);\n          }\n      },\n\n      computeSliceParams: function(arrayLength, sliceParams) {\n        var start = sliceParams[0];\n        var stop = sliceParams[1];\n        var step = sliceParams[2];\n        var computed = [null, null, null];\n        if (step === null) {\n          step = 1;\n        } else if (step === 0) {\n          var error = new Error(\"Invalid slice, step cannot be 0\");\n          error.name = \"RuntimeError\";\n          throw error;\n        }\n        var stepValueNegative = step < 0 ? true : false;\n\n        if (start === null) {\n            start = stepValueNegative ? arrayLength - 1 : 0;\n        } else {\n            start = this.capSliceRange(arrayLength, start, step);\n        }\n\n        if (stop === null) {\n            stop = stepValueNegative ? -1 : arrayLength;\n        } else {\n            stop = this.capSliceRange(arrayLength, stop, step);\n        }\n        computed[0] = start;\n        computed[1] = stop;\n        computed[2] = step;\n        return computed;\n      },\n\n      capSliceRange: function(arrayLength, actualValue, step) {\n          if (actualValue < 0) {\n              actualValue += arrayLength;\n              if (actualValue < 0) {\n                  actualValue = step < 0 ? -1 : 0;\n              }\n          } else if (actualValue >= arrayLength) {\n              actualValue = step < 0 ? arrayLength - 1 : arrayLength;\n          }\n          return actualValue;\n      }\n\n  };\n\n  function Runtime(interpreter) {\n    this._interpreter = interpreter;\n    this.functionTable = {\n        // name: [function, <signature>]\n        // The <signature> can be:\n        //\n        // {\n        //   args: [[type1, type2], [type1, type2]],\n        //   variadic: true|false\n        // }\n        //\n        // Each arg in the arg list is a list of valid types\n        // (if the function is overloaded and supports multiple\n        // types.  If the type is \"any\" then no type checking\n        // occurs on the argument.  Variadic is optional\n        // and if not provided is assumed to be false.\n        abs: {_func: this._functionAbs, _signature: [{types: [TYPE_NUMBER]}]},\n        avg: {_func: this._functionAvg, _signature: [{types: [TYPE_ARRAY_NUMBER]}]},\n        ceil: {_func: this._functionCeil, _signature: [{types: [TYPE_NUMBER]}]},\n        contains: {\n            _func: this._functionContains,\n            _signature: [{types: [TYPE_STRING, TYPE_ARRAY]},\n                        {types: [TYPE_ANY]}]},\n        \"ends_with\": {\n            _func: this._functionEndsWith,\n            _signature: [{types: [TYPE_STRING]}, {types: [TYPE_STRING]}]},\n        floor: {_func: this._functionFloor, _signature: [{types: [TYPE_NUMBER]}]},\n        length: {\n            _func: this._functionLength,\n            _signature: [{types: [TYPE_STRING, TYPE_ARRAY, TYPE_OBJECT]}]},\n        map: {\n            _func: this._functionMap,\n            _signature: [{types: [TYPE_EXPREF]}, {types: [TYPE_ARRAY]}]},\n        max: {\n            _func: this._functionMax,\n            _signature: [{types: [TYPE_ARRAY_NUMBER, TYPE_ARRAY_STRING]}]},\n        \"merge\": {\n            _func: this._functionMerge,\n            _signature: [{types: [TYPE_OBJECT], variadic: true}]\n        },\n        \"max_by\": {\n          _func: this._functionMaxBy,\n          _signature: [{types: [TYPE_ARRAY]}, {types: [TYPE_EXPREF]}]\n        },\n        sum: {_func: this._functionSum, _signature: [{types: [TYPE_ARRAY_NUMBER]}]},\n        \"starts_with\": {\n            _func: this._functionStartsWith,\n            _signature: [{types: [TYPE_STRING]}, {types: [TYPE_STRING]}]},\n        min: {\n            _func: this._functionMin,\n            _signature: [{types: [TYPE_ARRAY_NUMBER, TYPE_ARRAY_STRING]}]},\n        \"min_by\": {\n          _func: this._functionMinBy,\n          _signature: [{types: [TYPE_ARRAY]}, {types: [TYPE_EXPREF]}]\n        },\n        type: {_func: this._functionType, _signature: [{types: [TYPE_ANY]}]},\n        keys: {_func: this._functionKeys, _signature: [{types: [TYPE_OBJECT]}]},\n        values: {_func: this._functionValues, _signature: [{types: [TYPE_OBJECT]}]},\n        sort: {_func: this._functionSort, _signature: [{types: [TYPE_ARRAY_STRING, TYPE_ARRAY_NUMBER]}]},\n        \"sort_by\": {\n          _func: this._functionSortBy,\n          _signature: [{types: [TYPE_ARRAY]}, {types: [TYPE_EXPREF]}]\n        },\n        join: {\n            _func: this._functionJoin,\n            _signature: [\n                {types: [TYPE_STRING]},\n                {types: [TYPE_ARRAY_STRING]}\n            ]\n        },\n        reverse: {\n            _func: this._functionReverse,\n            _signature: [{types: [TYPE_STRING, TYPE_ARRAY]}]},\n        \"to_array\": {_func: this._functionToArray, _signature: [{types: [TYPE_ANY]}]},\n        \"to_string\": {_func: this._functionToString, _signature: [{types: [TYPE_ANY]}]},\n        \"to_number\": {_func: this._functionToNumber, _signature: [{types: [TYPE_ANY]}]},\n        \"not_null\": {\n            _func: this._functionNotNull,\n            _signature: [{types: [TYPE_ANY], variadic: true}]\n        }\n    };\n  }\n\n  Runtime.prototype = {\n    callFunction: function(name, resolvedArgs) {\n      var functionEntry = this.functionTable[name];\n      if (functionEntry === undefined) {\n          throw new Error(\"Unknown function: \" + name + \"()\");\n      }\n      this._validateArgs(name, resolvedArgs, functionEntry._signature);\n      return functionEntry._func.call(this, resolvedArgs);\n    },\n\n    _validateArgs: function(name, args, signature) {\n        // Validating the args requires validating\n        // the correct arity and the correct type of each arg.\n        // If the last argument is declared as variadic, then we need\n        // a minimum number of args to be required.  Otherwise it has to\n        // be an exact amount.\n        var pluralized;\n        if (signature[signature.length - 1].variadic) {\n            if (args.length < signature.length) {\n                pluralized = signature.length === 1 ? \" argument\" : \" arguments\";\n                throw new Error(\"ArgumentError: \" + name + \"() \" +\n                                \"takes at least\" + signature.length + pluralized +\n                                \" but received \" + args.length);\n            }\n        } else if (args.length !== signature.length) {\n            pluralized = signature.length === 1 ? \" argument\" : \" arguments\";\n            throw new Error(\"ArgumentError: \" + name + \"() \" +\n                            \"takes \" + signature.length + pluralized +\n                            \" but received \" + args.length);\n        }\n        var currentSpec;\n        var actualType;\n        var typeMatched;\n        for (var i = 0; i < signature.length; i++) {\n            typeMatched = false;\n            currentSpec = signature[i].types;\n            actualType = this._getTypeName(args[i]);\n            for (var j = 0; j < currentSpec.length; j++) {\n                if (this._typeMatches(actualType, currentSpec[j], args[i])) {\n                    typeMatched = true;\n                    break;\n                }\n            }\n            if (!typeMatched) {\n                throw new Error(\"TypeError: \" + name + \"() \" +\n                                \"expected argument \" + (i + 1) +\n                                \" to be type \" + currentSpec +\n                                \" but received type \" + actualType +\n                                \" instead.\");\n            }\n        }\n    },\n\n    _typeMatches: function(actual, expected, argValue) {\n        if (expected === TYPE_ANY) {\n            return true;\n        }\n        if (expected === TYPE_ARRAY_STRING ||\n            expected === TYPE_ARRAY_NUMBER ||\n            expected === TYPE_ARRAY) {\n            // The expected type can either just be array,\n            // or it can require a specific subtype (array of numbers).\n            //\n            // The simplest case is if \"array\" with no subtype is specified.\n            if (expected === TYPE_ARRAY) {\n                return actual === TYPE_ARRAY;\n            } else if (actual === TYPE_ARRAY) {\n                // Otherwise we need to check subtypes.\n                // I think this has potential to be improved.\n                var subtype;\n                if (expected === TYPE_ARRAY_NUMBER) {\n                  subtype = TYPE_NUMBER;\n                } else if (expected === TYPE_ARRAY_STRING) {\n                  subtype = TYPE_STRING;\n                }\n                for (var i = 0; i < argValue.length; i++) {\n                    if (!this._typeMatches(\n                            this._getTypeName(argValue[i]), subtype,\n                                             argValue[i])) {\n                        return false;\n                    }\n                }\n                return true;\n            }\n        } else {\n            return actual === expected;\n        }\n    },\n    _getTypeName: function(obj) {\n        switch (Object.prototype.toString.call(obj)) {\n            case \"[object String]\":\n              return TYPE_STRING;\n            case \"[object Number]\":\n              return TYPE_NUMBER;\n            case \"[object Array]\":\n              return TYPE_ARRAY;\n            case \"[object Boolean]\":\n              return TYPE_BOOLEAN;\n            case \"[object Null]\":\n              return TYPE_NULL;\n            case \"[object Object]\":\n              // Check if it's an expref.  If it has, it's been\n              // tagged with a jmespathType attr of 'Expref';\n              if (obj.jmespathType === TOK_EXPREF) {\n                return TYPE_EXPREF;\n              } else {\n                return TYPE_OBJECT;\n              }\n        }\n    },\n\n    _functionStartsWith: function(resolvedArgs) {\n        return resolvedArgs[0].lastIndexOf(resolvedArgs[1]) === 0;\n    },\n\n    _functionEndsWith: function(resolvedArgs) {\n        var searchStr = resolvedArgs[0];\n        var suffix = resolvedArgs[1];\n        return searchStr.indexOf(suffix, searchStr.length - suffix.length) !== -1;\n    },\n\n    _functionReverse: function(resolvedArgs) {\n        var typeName = this._getTypeName(resolvedArgs[0]);\n        if (typeName === TYPE_STRING) {\n          var originalStr = resolvedArgs[0];\n          var reversedStr = \"\";\n          for (var i = originalStr.length - 1; i >= 0; i--) {\n              reversedStr += originalStr[i];\n          }\n          return reversedStr;\n        } else {\n          var reversedArray = resolvedArgs[0].slice(0);\n          reversedArray.reverse();\n          return reversedArray;\n        }\n    },\n\n    _functionAbs: function(resolvedArgs) {\n      return Math.abs(resolvedArgs[0]);\n    },\n\n    _functionCeil: function(resolvedArgs) {\n        return Math.ceil(resolvedArgs[0]);\n    },\n\n    _functionAvg: function(resolvedArgs) {\n        var sum = 0;\n        var inputArray = resolvedArgs[0];\n        for (var i = 0; i < inputArray.length; i++) {\n            sum += inputArray[i];\n        }\n        return sum / inputArray.length;\n    },\n\n    _functionContains: function(resolvedArgs) {\n        return resolvedArgs[0].indexOf(resolvedArgs[1]) >= 0;\n    },\n\n    _functionFloor: function(resolvedArgs) {\n        return Math.floor(resolvedArgs[0]);\n    },\n\n    _functionLength: function(resolvedArgs) {\n       if (!isObject(resolvedArgs[0])) {\n         return resolvedArgs[0].length;\n       } else {\n         // As far as I can tell, there's no way to get the length\n         // of an object without O(n) iteration through the object.\n         return Object.keys(resolvedArgs[0]).length;\n       }\n    },\n\n    _functionMap: function(resolvedArgs) {\n      var mapped = [];\n      var interpreter = this._interpreter;\n      var exprefNode = resolvedArgs[0];\n      var elements = resolvedArgs[1];\n      for (var i = 0; i < elements.length; i++) {\n          mapped.push(interpreter.visit(exprefNode, elements[i]));\n      }\n      return mapped;\n    },\n\n    _functionMerge: function(resolvedArgs) {\n      var merged = {};\n      for (var i = 0; i < resolvedArgs.length; i++) {\n        var current = resolvedArgs[i];\n        for (var key in current) {\n          merged[key] = current[key];\n        }\n      }\n      return merged;\n    },\n\n    _functionMax: function(resolvedArgs) {\n      if (resolvedArgs[0].length > 0) {\n        var typeName = this._getTypeName(resolvedArgs[0][0]);\n        if (typeName === TYPE_NUMBER) {\n          return Math.max.apply(Math, resolvedArgs[0]);\n        } else {\n          var elements = resolvedArgs[0];\n          var maxElement = elements[0];\n          for (var i = 1; i < elements.length; i++) {\n              if (maxElement.localeCompare(elements[i]) < 0) {\n                  maxElement = elements[i];\n              }\n          }\n          return maxElement;\n        }\n      } else {\n          return null;\n      }\n    },\n\n    _functionMin: function(resolvedArgs) {\n      if (resolvedArgs[0].length > 0) {\n        var typeName = this._getTypeName(resolvedArgs[0][0]);\n        if (typeName === TYPE_NUMBER) {\n          return Math.min.apply(Math, resolvedArgs[0]);\n        } else {\n          var elements = resolvedArgs[0];\n          var minElement = elements[0];\n          for (var i = 1; i < elements.length; i++) {\n              if (elements[i].localeCompare(minElement) < 0) {\n                  minElement = elements[i];\n              }\n          }\n          return minElement;\n        }\n      } else {\n        return null;\n      }\n    },\n\n    _functionSum: function(resolvedArgs) {\n      var sum = 0;\n      var listToSum = resolvedArgs[0];\n      for (var i = 0; i < listToSum.length; i++) {\n        sum += listToSum[i];\n      }\n      return sum;\n    },\n\n    _functionType: function(resolvedArgs) {\n        switch (this._getTypeName(resolvedArgs[0])) {\n          case TYPE_NUMBER:\n            return \"number\";\n          case TYPE_STRING:\n            return \"string\";\n          case TYPE_ARRAY:\n            return \"array\";\n          case TYPE_OBJECT:\n            return \"object\";\n          case TYPE_BOOLEAN:\n            return \"boolean\";\n          case TYPE_EXPREF:\n            return \"expref\";\n          case TYPE_NULL:\n            return \"null\";\n        }\n    },\n\n    _functionKeys: function(resolvedArgs) {\n        return Object.keys(resolvedArgs[0]);\n    },\n\n    _functionValues: function(resolvedArgs) {\n        var obj = resolvedArgs[0];\n        var keys = Object.keys(obj);\n        var values = [];\n        for (var i = 0; i < keys.length; i++) {\n            values.push(obj[keys[i]]);\n        }\n        return values;\n    },\n\n    _functionJoin: function(resolvedArgs) {\n        var joinChar = resolvedArgs[0];\n        var listJoin = resolvedArgs[1];\n        return listJoin.join(joinChar);\n    },\n\n    _functionToArray: function(resolvedArgs) {\n        if (this._getTypeName(resolvedArgs[0]) === TYPE_ARRAY) {\n            return resolvedArgs[0];\n        } else {\n            return [resolvedArgs[0]];\n        }\n    },\n\n    _functionToString: function(resolvedArgs) {\n        if (this._getTypeName(resolvedArgs[0]) === TYPE_STRING) {\n            return resolvedArgs[0];\n        } else {\n            return JSON.stringify(resolvedArgs[0]);\n        }\n    },\n\n    _functionToNumber: function(resolvedArgs) {\n        var typeName = this._getTypeName(resolvedArgs[0]);\n        var convertedValue;\n        if (typeName === TYPE_NUMBER) {\n            return resolvedArgs[0];\n        } else if (typeName === TYPE_STRING) {\n            convertedValue = +resolvedArgs[0];\n            if (!isNaN(convertedValue)) {\n                return convertedValue;\n            }\n        }\n        return null;\n    },\n\n    _functionNotNull: function(resolvedArgs) {\n        for (var i = 0; i < resolvedArgs.length; i++) {\n            if (this._getTypeName(resolvedArgs[i]) !== TYPE_NULL) {\n                return resolvedArgs[i];\n            }\n        }\n        return null;\n    },\n\n    _functionSort: function(resolvedArgs) {\n        var sortedArray = resolvedArgs[0].slice(0);\n        sortedArray.sort();\n        return sortedArray;\n    },\n\n    _functionSortBy: function(resolvedArgs) {\n        var sortedArray = resolvedArgs[0].slice(0);\n        if (sortedArray.length === 0) {\n            return sortedArray;\n        }\n        var interpreter = this._interpreter;\n        var exprefNode = resolvedArgs[1];\n        var requiredType = this._getTypeName(\n            interpreter.visit(exprefNode, sortedArray[0]));\n        if ([TYPE_NUMBER, TYPE_STRING].indexOf(requiredType) < 0) {\n            throw new Error(\"TypeError\");\n        }\n        var that = this;\n        // In order to get a stable sort out of an unstable\n        // sort algorithm, we decorate/sort/undecorate (DSU)\n        // by creating a new list of [index, element] pairs.\n        // In the cmp function, if the evaluated elements are\n        // equal, then the index will be used as the tiebreaker.\n        // After the decorated list has been sorted, it will be\n        // undecorated to extract the original elements.\n        var decorated = [];\n        for (var i = 0; i < sortedArray.length; i++) {\n          decorated.push([i, sortedArray[i]]);\n        }\n        decorated.sort(function(a, b) {\n          var exprA = interpreter.visit(exprefNode, a[1]);\n          var exprB = interpreter.visit(exprefNode, b[1]);\n          if (that._getTypeName(exprA) !== requiredType) {\n              throw new Error(\n                  \"TypeError: expected \" + requiredType + \", received \" +\n                  that._getTypeName(exprA));\n          } else if (that._getTypeName(exprB) !== requiredType) {\n              throw new Error(\n                  \"TypeError: expected \" + requiredType + \", received \" +\n                  that._getTypeName(exprB));\n          }\n          if (exprA > exprB) {\n            return 1;\n          } else if (exprA < exprB) {\n            return -1;\n          } else {\n            // If they're equal compare the items by their\n            // order to maintain relative order of equal keys\n            // (i.e. to get a stable sort).\n            return a[0] - b[0];\n          }\n        });\n        // Undecorate: extract out the original list elements.\n        for (var j = 0; j < decorated.length; j++) {\n          sortedArray[j] = decorated[j][1];\n        }\n        return sortedArray;\n    },\n\n    _functionMaxBy: function(resolvedArgs) {\n      var exprefNode = resolvedArgs[1];\n      var resolvedArray = resolvedArgs[0];\n      var keyFunction = this.createKeyFunction(exprefNode, [TYPE_NUMBER, TYPE_STRING]);\n      var maxNumber = -Infinity;\n      var maxRecord;\n      var current;\n      for (var i = 0; i < resolvedArray.length; i++) {\n        current = keyFunction(resolvedArray[i]);\n        if (current > maxNumber) {\n          maxNumber = current;\n          maxRecord = resolvedArray[i];\n        }\n      }\n      return maxRecord;\n    },\n\n    _functionMinBy: function(resolvedArgs) {\n      var exprefNode = resolvedArgs[1];\n      var resolvedArray = resolvedArgs[0];\n      var keyFunction = this.createKeyFunction(exprefNode, [TYPE_NUMBER, TYPE_STRING]);\n      var minNumber = Infinity;\n      var minRecord;\n      var current;\n      for (var i = 0; i < resolvedArray.length; i++) {\n        current = keyFunction(resolvedArray[i]);\n        if (current < minNumber) {\n          minNumber = current;\n          minRecord = resolvedArray[i];\n        }\n      }\n      return minRecord;\n    },\n\n    createKeyFunction: function(exprefNode, allowedTypes) {\n      var that = this;\n      var interpreter = this._interpreter;\n      var keyFunc = function(x) {\n        var current = interpreter.visit(exprefNode, x);\n        if (allowedTypes.indexOf(that._getTypeName(current)) < 0) {\n          var msg = \"TypeError: expected one of \" + allowedTypes +\n                    \", received \" + that._getTypeName(current);\n          throw new Error(msg);\n        }\n        return current;\n      };\n      return keyFunc;\n    }\n\n  };\n\n  function compile(stream) {\n    var parser = new Parser();\n    var ast = parser.parse(stream);\n    return ast;\n  }\n\n  function tokenize(stream) {\n      var lexer = new Lexer();\n      return lexer.tokenize(stream);\n  }\n\n  function search(data, expression) {\n      var parser = new Parser();\n      // This needs to be improved.  Both the interpreter and runtime depend on\n      // each other.  The runtime needs the interpreter to support exprefs.\n      // There's likely a clean way to avoid the cyclic dependency.\n      var runtime = new Runtime();\n      var interpreter = new TreeInterpreter(runtime);\n      runtime._interpreter = interpreter;\n      var node = parser.parse(expression);\n      return interpreter.search(node, data);\n  }\n\n  exports.tokenize = tokenize;\n  exports.compile = compile;\n  exports.search = search;\n  exports.strictDeepEqual = strictDeepEqual;\n})(typeof exports === \"undefined\" ? this.jmespath = {} : exports);\n","/* (ignored) */","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Generated from antlr/JSONFormula.g4 by ANTLR 4.9.2\n// jshint ignore: start\nimport antlr4 from 'antlr4';\n\n// This class defines a complete listener for a parse tree produced by JSONFormulaParser.\nexport default class JSONFormulaListener extends antlr4.tree.ParseTreeListener {\n\n\t// Enter a parse tree produced by JSONFormulaParser#formula.\n\tenterFormula(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#formula.\n\texitFormula(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#binaryExpression.\n\tenterBinaryExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#binaryExpression.\n\texitBinaryExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jmesPath.\n\tenterJmesPath(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jmesPath.\n\texitJmesPath(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#topLevelString.\n\tenterTopLevelString(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#topLevelString.\n\texitTopLevelString(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#topLevelInt.\n\tenterTopLevelInt(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#topLevelInt.\n\texitTopLevelInt(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#functionCall.\n\tenterFunctionCall(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#functionCall.\n\texitFunctionCall(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#braceExpression.\n\tenterBraceExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#braceExpression.\n\texitBraceExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#postfix.\n\tenterPostfix(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#postfix.\n\texitPostfix(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#unaryExpression.\n\tenterUnaryExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#unaryExpression.\n\texitUnaryExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#topLevelNumber.\n\tenterTopLevelNumber(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#topLevelNumber.\n\texitTopLevelNumber(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#unary_op.\n\tenterUnary_op(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#unary_op.\n\texitUnary_op(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#binary_op.\n\tenterBinary_op(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#binary_op.\n\texitBinary_op(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#postfix_op.\n\tenterPostfix_op(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#postfix_op.\n\texitPostfix_op(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#function_call.\n\tenterFunction_call(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#function_call.\n\texitFunction_call(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#parameter.\n\tenterParameter(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#parameter.\n\texitParameter(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#nonempty_expr_list.\n\tenterNonempty_expr_list(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#nonempty_expr_list.\n\texitNonempty_expr_list(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#expression_list.\n\tenterExpression_list(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#expression_list.\n\texitExpression_list(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#parm_separator.\n\tenterParm_separator(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#parm_separator.\n\texitParm_separator(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#pipeExpression.\n\tenterPipeExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#pipeExpression.\n\texitPipeExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#identifierExpression.\n\tenterIdentifierExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#identifierExpression.\n\texitIdentifierExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#notExpression.\n\tenterNotExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#notExpression.\n\texitNotExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#rawStringExpression.\n\tenterRawStringExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#rawStringExpression.\n\texitRawStringExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#comparisonExpression.\n\tenterComparisonExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#comparisonExpression.\n\texitComparisonExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#parenExpression.\n\tenterParenExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#parenExpression.\n\texitParenExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#bracketExpression.\n\tenterBracketExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#bracketExpression.\n\texitBracketExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#orExpression.\n\tenterOrExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#orExpression.\n\texitOrExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#currentNodeExpression.\n\tenterCurrentNodeExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#currentNodeExpression.\n\texitCurrentNodeExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#chainExpression.\n\tenterChainExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#chainExpression.\n\texitChainExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#andExpression.\n\tenterAndExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#andExpression.\n\texitAndExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#multiSelectHashExpression.\n\tenterMultiSelectHashExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#multiSelectHashExpression.\n\texitMultiSelectHashExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#wildcardExpression.\n\tenterWildcardExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#wildcardExpression.\n\texitWildcardExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#functionCallExpression.\n\tenterFunctionCallExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#functionCallExpression.\n\texitFunctionCallExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#multiSelectListExpression.\n\tenterMultiSelectListExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#multiSelectListExpression.\n\texitMultiSelectListExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#bracketedExpression.\n\tenterBracketedExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#bracketedExpression.\n\texitBracketedExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#literalExpression.\n\tenterLiteralExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#literalExpression.\n\texitLiteralExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#chainedIdentifier.\n\tenterChainedIdentifier(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#chainedIdentifier.\n\texitChainedIdentifier(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#chainedMultiSelectList.\n\tenterChainedMultiSelectList(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#chainedMultiSelectList.\n\texitChainedMultiSelectList(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#chainedMultiSelectHash.\n\tenterChainedMultiSelectHash(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#chainedMultiSelectHash.\n\texitChainedMultiSelectHash(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#chainedFunctionExpression.\n\tenterChainedFunctionExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#chainedFunctionExpression.\n\texitChainedFunctionExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#chainedWildcard.\n\tenterChainedWildcard(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#chainedWildcard.\n\texitChainedWildcard(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#wildcard.\n\tenterWildcard(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#wildcard.\n\texitWildcard(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#multiSelectList.\n\tenterMultiSelectList(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#multiSelectList.\n\texitMultiSelectList(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#multiSelectHash.\n\tenterMultiSelectHash(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#multiSelectHash.\n\texitMultiSelectHash(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#keyvalExpr.\n\tenterKeyvalExpr(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#keyvalExpr.\n\texitKeyvalExpr(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#bracketIndex.\n\tenterBracketIndex(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#bracketIndex.\n\texitBracketIndex(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#bracketStar.\n\tenterBracketStar(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#bracketStar.\n\texitBracketStar(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#bracketSlice.\n\tenterBracketSlice(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#bracketSlice.\n\texitBracketSlice(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#bracketFlatten.\n\tenterBracketFlatten(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#bracketFlatten.\n\texitBracketFlatten(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#select.\n\tenterSelect(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#select.\n\texitSelect(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#slice.\n\tenterSlice(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#slice.\n\texitSlice(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#functionExpression.\n\tenterFunctionExpression(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#functionExpression.\n\texitFunctionExpression(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#functionArg.\n\tenterFunctionArg(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#functionArg.\n\texitFunctionArg(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#currentNode.\n\tenterCurrentNode(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#currentNode.\n\texitCurrentNode(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#expressionType.\n\tenterExpressionType(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#expressionType.\n\texitExpressionType(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#literal.\n\tenterLiteral(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#literal.\n\texitLiteral(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#identifier.\n\tenterIdentifier(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#identifier.\n\texitIdentifier(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonObject.\n\tenterJsonObject(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonObject.\n\texitJsonObject(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonObjectPair.\n\tenterJsonObjectPair(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonObjectPair.\n\texitJsonObjectPair(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonArray.\n\tenterJsonArray(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonArray.\n\texitJsonArray(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonStringValue.\n\tenterJsonStringValue(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonStringValue.\n\texitJsonStringValue(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonNumberValue.\n\tenterJsonNumberValue(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonNumberValue.\n\texitJsonNumberValue(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonObjectValue.\n\tenterJsonObjectValue(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonObjectValue.\n\texitJsonObjectValue(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonArrayValue.\n\tenterJsonArrayValue(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonArrayValue.\n\texitJsonArrayValue(ctx) {\n\t}\n\n\n\t// Enter a parse tree produced by JSONFormulaParser#jsonConstantValue.\n\tenterJsonConstantValue(ctx) {\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jsonConstantValue.\n\texitJsonConstantValue(ctx) {\n\t}\n\n\n\n}","// Generated from antlr/JSONFormula.g4 by ANTLR 4.9.2\n// jshint ignore: start\nimport antlr4 from 'antlr4';\nimport JSONFormulaListener from './JSONFormulaListener.js';\n\nconst serializedATN = [\"\\u0003\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\",\n    \"\\u5964\\u0003$\\u012a\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\\u0004\",\n    \"\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\\t\\u0007\",\n    \"\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\\f\\t\\f\",\n    \"\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f\\u0004\\u0010\\t\\u0010\",\n    \"\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013\\t\\u0013\\u0004\\u0014\",\n    \"\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016\\u0004\\u0017\\t\\u0017\",\n    \"\\u0004\\u0018\\t\\u0018\\u0004\\u0019\\t\\u0019\\u0004\\u001a\\t\\u001a\\u0004\\u001b\",\n    \"\\t\\u001b\\u0004\\u001c\\t\\u001c\\u0004\\u001d\\t\\u001d\\u0003\\u0002\\u0003\\u0002\",\n    \"\\u0003\\u0002\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\n    \"\\u0003\\u0003\\u0003\\u0003\\u0005\\u0003K\\n\\u0003\\u0003\\u0003\\u0003\\u0003\",\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0007\\u0003S\\n\\u0003\",\n    \"\\f\\u0003\\u000e\\u0003V\\u000b\\u0003\\u0003\\u0004\\u0003\\u0004\\u0003\\u0005\",\n    \"\\u0003\\u0005\\u0003\\u0006\\u0003\\u0006\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\",\n    \"\\u0003\\u0007\\u0003\\u0007\\u0003\\b\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\",\n    \"\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0007\\tl\\n\\t\\f\\t\\u000e\\to\\u000b\\t\\u0003\\n\",\n    \"\\u0003\\n\\u0005\\ns\\n\\n\\u0003\\u000b\\u0003\\u000b\\u0003\\f\\u0003\\f\\u0003\",\n    \"\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\",\n    \"\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0005\\f\\u0087\\n\\f\\u0003\\f\\u0003\\f\",\n    \"\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\",\n    \"\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0007\\f\\u009a\\n\\f\",\n    \"\\f\\f\\u000e\\f\\u009d\\u000b\\f\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0005\",\n    \"\\r\\u00a4\\n\\r\\u0003\\u000e\\u0003\\u000e\\u0003\\u000f\\u0003\\u000f\\u0003\\u000f\",\n    \"\\u0003\\u000f\\u0007\\u000f\\u00ac\\n\\u000f\\f\\u000f\\u000e\\u000f\\u00af\\u000b\",\n    \"\\u000f\\u0003\\u000f\\u0003\\u000f\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\\u0003\",\n    \"\\u0010\\u0007\\u0010\\u00b7\\n\\u0010\\f\\u0010\\u000e\\u0010\\u00ba\\u000b\\u0010\",\n    \"\\u0003\\u0010\\u0003\\u0010\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\",\n    \"\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\",\n    \"\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\",\n    \"\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0005\\u0012\\u00d2\\n\",\n    \"\\u0012\\u0003\\u0013\\u0005\\u0013\\u00d5\\n\\u0013\\u0003\\u0013\\u0003\\u0013\",\n    \"\\u0005\\u0013\\u00d9\\n\\u0013\\u0003\\u0013\\u0003\\u0013\\u0005\\u0013\\u00dd\",\n    \"\\n\\u0013\\u0005\\u0013\\u00df\\n\\u0013\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\",\n    \"\\u0003\\u0014\\u0003\\u0014\\u0007\\u0014\\u00e6\\n\\u0014\\f\\u0014\\u000e\\u0014\",\n    \"\\u00e9\\u000b\\u0014\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\\u0003\",\n    \"\\u0014\\u0005\\u0014\\u00f0\\n\\u0014\\u0003\\u0015\\u0003\\u0015\\u0005\\u0015\",\n    \"\\u00f4\\n\\u0015\\u0003\\u0016\\u0003\\u0016\\u0003\\u0017\\u0003\\u0017\\u0003\",\n    \"\\u0017\\u0003\\u0018\\u0003\\u0018\\u0003\\u0018\\u0003\\u0018\\u0003\\u0019\\u0003\",\n    \"\\u0019\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0007\\u001a\\u0105\",\n    \"\\n\\u001a\\f\\u001a\\u000e\\u001a\\u0108\\u000b\\u001a\\u0003\\u001a\\u0003\\u001a\",\n    \"\\u0003\\u001a\\u0003\\u001a\\u0005\\u001a\\u010e\\n\\u001a\\u0003\\u001b\\u0003\",\n    \"\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\",\n    \"\\u001c\\u0007\\u001c\\u0118\\n\\u001c\\f\\u001c\\u000e\\u001c\\u011b\\u000b\\u001c\",\n    \"\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0005\\u001c\\u0121\\n\",\n    \"\\u001c\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0005\",\n    \"\\u001d\\u0128\\n\\u001d\\u0003\\u001d\\u0002\\u0005\\u0004\\u0010\\u0016\\u001e\",\n    \"\\u0002\\u0004\\u0006\\b\\n\\f\\u000e\\u0010\\u0012\\u0014\\u0016\\u0018\\u001a\\u001c\",\n    \"\\u001e \\\"$&(*,.02468\\u0002\\u0006\\u0003\\u0002\\u0005\\u0006\\u0004\\u0002\",\n    \"\\u0005\\u000b\\u001e\\u001e\\u0003\\u0002 \\\"\\u0004\\u0002\\u001b\\u001b##\\u0002\",\n    \"\\u0140\\u0002:\\u0003\\u0002\\u0002\\u0002\\u0004J\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0006W\\u0003\\u0002\\u0002\\u0002\\bY\\u0003\\u0002\\u0002\\u0002\\n[\\u0003\",\n    \"\\u0002\\u0002\\u0002\\f]\\u0003\\u0002\\u0002\\u0002\\u000eb\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0010d\\u0003\\u0002\\u0002\\u0002\\u0012r\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0014t\\u0003\\u0002\\u0002\\u0002\\u0016\\u0086\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0018\\u00a3\\u0003\\u0002\\u0002\\u0002\\u001a\\u00a5\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u001c\\u00a7\\u0003\\u0002\\u0002\\u0002\\u001e\\u00b2\\u0003\\u0002\\u0002\\u0002\",\n    \" \\u00bd\\u0003\\u0002\\u0002\\u0002\\\"\\u00d1\\u0003\\u0002\\u0002\\u0002$\\u00d4\",\n    \"\\u0003\\u0002\\u0002\\u0002&\\u00ef\\u0003\\u0002\\u0002\\u0002(\\u00f3\\u0003\",\n    \"\\u0002\\u0002\\u0002*\\u00f5\\u0003\\u0002\\u0002\\u0002,\\u00f7\\u0003\\u0002\",\n    \"\\u0002\\u0002.\\u00fa\\u0003\\u0002\\u0002\\u00020\\u00fe\\u0003\\u0002\\u0002\",\n    \"\\u00022\\u010d\\u0003\\u0002\\u0002\\u00024\\u010f\\u0003\\u0002\\u0002\\u0002\",\n    \"6\\u0120\\u0003\\u0002\\u0002\\u00028\\u0127\\u0003\\u0002\\u0002\\u0002:;\\u0005\",\n    \"\\u0004\\u0003\\u0002;<\\u0007\\u0002\\u0002\\u0003<\\u0003\\u0003\\u0002\\u0002\",\n    \"\\u0002=>\\b\\u0003\\u0001\\u0002>K\\u0007\\u001b\\u0002\\u0002?K\\u0007\\u001c\",\n    \"\\u0002\\u0002@K\\u0007\\u001f\\u0002\\u0002AB\\u0005\\u0006\\u0004\\u0002BC\\u0005\",\n    \"\\u0004\\u0003\\u0007CK\\u0003\\u0002\\u0002\\u0002DE\\u0007\\u0003\\u0002\\u0002\",\n    \"EF\\u0005\\u0004\\u0003\\u0002FG\\u0007\\u0004\\u0002\\u0002GK\\u0003\\u0002\\u0002\",\n    \"\\u0002HK\\u0005\\f\\u0007\\u0002IK\\u0005\\u0016\\f\\u0002J=\\u0003\\u0002\\u0002\",\n    \"\\u0002J?\\u0003\\u0002\\u0002\\u0002J@\\u0003\\u0002\\u0002\\u0002JA\\u0003\\u0002\",\n    \"\\u0002\\u0002JD\\u0003\\u0002\\u0002\\u0002JH\\u0003\\u0002\\u0002\\u0002JI\\u0003\",\n    \"\\u0002\\u0002\\u0002KT\\u0003\\u0002\\u0002\\u0002LM\\f\\b\\u0002\\u0002MN\\u0005\",\n    \"\\b\\u0005\\u0002NO\\u0005\\u0004\\u0003\\tOS\\u0003\\u0002\\u0002\\u0002PQ\\f\\u0006\",\n    \"\\u0002\\u0002QS\\u0005\\n\\u0006\\u0002RL\\u0003\\u0002\\u0002\\u0002RP\\u0003\",\n    \"\\u0002\\u0002\\u0002SV\\u0003\\u0002\\u0002\\u0002TR\\u0003\\u0002\\u0002\\u0002\",\n    \"TU\\u0003\\u0002\\u0002\\u0002U\\u0005\\u0003\\u0002\\u0002\\u0002VT\\u0003\\u0002\",\n    \"\\u0002\\u0002WX\\t\\u0002\\u0002\\u0002X\\u0007\\u0003\\u0002\\u0002\\u0002YZ\",\n    \"\\t\\u0003\\u0002\\u0002Z\\t\\u0003\\u0002\\u0002\\u0002[\\\\\\u0007\\f\\u0002\\u0002\",\n    \"\\\\\\u000b\\u0003\\u0002\\u0002\\u0002]^\\u0007\\u001d\\u0002\\u0002^_\\u0007\\u0003\",\n    \"\\u0002\\u0002_`\\u0005\\u0012\\n\\u0002`a\\u0007\\u0004\\u0002\\u0002a\\r\\u0003\",\n    \"\\u0002\\u0002\\u0002bc\\u0005\\u0004\\u0003\\u0002c\\u000f\\u0003\\u0002\\u0002\",\n    \"\\u0002de\\b\\t\\u0001\\u0002ef\\u0005\\u000e\\b\\u0002fm\\u0003\\u0002\\u0002\\u0002\",\n    \"gh\\f\\u0003\\u0002\\u0002hi\\u0005\\u0014\\u000b\\u0002ij\\u0005\\u000e\\b\\u0002\",\n    \"jl\\u0003\\u0002\\u0002\\u0002kg\\u0003\\u0002\\u0002\\u0002lo\\u0003\\u0002\\u0002\",\n    \"\\u0002mk\\u0003\\u0002\\u0002\\u0002mn\\u0003\\u0002\\u0002\\u0002n\\u0011\\u0003\",\n    \"\\u0002\\u0002\\u0002om\\u0003\\u0002\\u0002\\u0002ps\\u0003\\u0002\\u0002\\u0002\",\n    \"qs\\u0005\\u0010\\t\\u0002rp\\u0003\\u0002\\u0002\\u0002rq\\u0003\\u0002\\u0002\",\n    \"\\u0002s\\u0013\\u0003\\u0002\\u0002\\u0002tu\\u0007\\r\\u0002\\u0002u\\u0015\\u0003\",\n    \"\\u0002\\u0002\\u0002vw\\b\\f\\u0001\\u0002w\\u0087\\u0005\\\"\\u0012\\u0002x\\u0087\",\n    \"\\u00050\\u0019\\u0002yz\\u0007\\u0011\\u0002\\u0002z\\u0087\\u0005\\u0016\\f\\f\",\n    \"{|\\u0007\\u0003\\u0002\\u0002|}\\u0005\\u0016\\f\\u0002}~\\u0007\\u0004\\u0002\",\n    \"\\u0002~\\u0087\\u0003\\u0002\\u0002\\u0002\\u007f\\u0087\\u0005\\u001a\\u000e\",\n    \"\\u0002\\u0080\\u0087\\u0005\\u001c\\u000f\\u0002\\u0081\\u0087\\u0005\\u001e\\u0010\",\n    \"\\u0002\\u0082\\u0087\\u0005.\\u0018\\u0002\\u0083\\u0087\\u0005&\\u0014\\u0002\",\n    \"\\u0084\\u0087\\u0007\\u001f\\u0002\\u0002\\u0085\\u0087\\u0005*\\u0016\\u0002\",\n    \"\\u0086v\\u0003\\u0002\\u0002\\u0002\\u0086x\\u0003\\u0002\\u0002\\u0002\\u0086\",\n    \"y\\u0003\\u0002\\u0002\\u0002\\u0086{\\u0003\\u0002\\u0002\\u0002\\u0086\\u007f\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0086\\u0080\\u0003\\u0002\\u0002\\u0002\\u0086\\u0081\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0086\\u0082\\u0003\\u0002\\u0002\\u0002\\u0086\\u0083\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0086\\u0084\\u0003\\u0002\\u0002\\u0002\\u0086\\u0085\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0087\\u009b\\u0003\\u0002\\u0002\\u0002\\u0088\\u0089\",\n    \"\\f\\u0010\\u0002\\u0002\\u0089\\u008a\\u0007\\u001e\\u0002\\u0002\\u008a\\u009a\",\n    \"\\u0005\\u0016\\f\\u0011\\u008b\\u008c\\f\\u000f\\u0002\\u0002\\u008c\\u008d\\u0007\",\n    \"\\u000f\\u0002\\u0002\\u008d\\u009a\\u0005\\u0016\\f\\u0010\\u008e\\u008f\\f\\u000e\",\n    \"\\u0002\\u0002\\u008f\\u0090\\u0007\\u0010\\u0002\\u0002\\u0090\\u009a\\u0005\\u0016\",\n    \"\\f\\u000f\\u0091\\u0092\\f\\u0005\\u0002\\u0002\\u0092\\u0093\\u0007\\u0012\\u0002\",\n    \"\\u0002\\u0093\\u009a\\u0005\\u0016\\f\\u0006\\u0094\\u0095\\f\\u0013\\u0002\\u0002\",\n    \"\\u0095\\u0096\\u0007\\u000e\\u0002\\u0002\\u0096\\u009a\\u0005\\u0018\\r\\u0002\",\n    \"\\u0097\\u0098\\f\\u0012\\u0002\\u0002\\u0098\\u009a\\u0005\\\"\\u0012\\u0002\\u0099\",\n    \"\\u0088\\u0003\\u0002\\u0002\\u0002\\u0099\\u008b\\u0003\\u0002\\u0002\\u0002\\u0099\",\n    \"\\u008e\\u0003\\u0002\\u0002\\u0002\\u0099\\u0091\\u0003\\u0002\\u0002\\u0002\\u0099\",\n    \"\\u0094\\u0003\\u0002\\u0002\\u0002\\u0099\\u0097\\u0003\\u0002\\u0002\\u0002\\u009a\",\n    \"\\u009d\\u0003\\u0002\\u0002\\u0002\\u009b\\u0099\\u0003\\u0002\\u0002\\u0002\\u009b\",\n    \"\\u009c\\u0003\\u0002\\u0002\\u0002\\u009c\\u0017\\u0003\\u0002\\u0002\\u0002\\u009d\",\n    \"\\u009b\\u0003\\u0002\\u0002\\u0002\\u009e\\u00a4\\u00050\\u0019\\u0002\\u009f\",\n    \"\\u00a4\\u0005\\u001c\\u000f\\u0002\\u00a0\\u00a4\\u0005\\u001e\\u0010\\u0002\\u00a1\",\n    \"\\u00a4\\u0005&\\u0014\\u0002\\u00a2\\u00a4\\u0005\\u001a\\u000e\\u0002\\u00a3\",\n    \"\\u009e\\u0003\\u0002\\u0002\\u0002\\u00a3\\u009f\\u0003\\u0002\\u0002\\u0002\\u00a3\",\n    \"\\u00a0\\u0003\\u0002\\u0002\\u0002\\u00a3\\u00a1\\u0003\\u0002\\u0002\\u0002\\u00a3\",\n    \"\\u00a2\\u0003\\u0002\\u0002\\u0002\\u00a4\\u0019\\u0003\\u0002\\u0002\\u0002\\u00a5\",\n    \"\\u00a6\\u0007\\t\\u0002\\u0002\\u00a6\\u001b\\u0003\\u0002\\u0002\\u0002\\u00a7\",\n    \"\\u00a8\\u0007\\u0013\\u0002\\u0002\\u00a8\\u00ad\\u0005\\u0016\\f\\u0002\\u00a9\",\n    \"\\u00aa\\u0007\\r\\u0002\\u0002\\u00aa\\u00ac\\u0005\\u0016\\f\\u0002\\u00ab\\u00a9\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00ac\\u00af\\u0003\\u0002\\u0002\\u0002\\u00ad\\u00ab\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00ad\\u00ae\\u0003\\u0002\\u0002\\u0002\\u00ae\\u00b0\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00af\\u00ad\\u0003\\u0002\\u0002\\u0002\\u00b0\\u00b1\",\n    \"\\u0007\\u0014\\u0002\\u0002\\u00b1\\u001d\\u0003\\u0002\\u0002\\u0002\\u00b2\\u00b3\",\n    \"\\u0007\\u0015\\u0002\\u0002\\u00b3\\u00b8\\u0005 \\u0011\\u0002\\u00b4\\u00b5\",\n    \"\\u0007\\r\\u0002\\u0002\\u00b5\\u00b7\\u0005 \\u0011\\u0002\\u00b6\\u00b4\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00b7\\u00ba\\u0003\\u0002\\u0002\\u0002\\u00b8\\u00b6\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00b8\\u00b9\\u0003\\u0002\\u0002\\u0002\\u00b9\\u00bb\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00ba\\u00b8\\u0003\\u0002\\u0002\\u0002\\u00bb\\u00bc\\u0007\",\n    \"\\u0016\\u0002\\u0002\\u00bc\\u001f\\u0003\\u0002\\u0002\\u0002\\u00bd\\u00be\\u0005\",\n    \"0\\u0019\\u0002\\u00be\\u00bf\\u0007\\u0017\\u0002\\u0002\\u00bf\\u00c0\\u0005\",\n    \"\\u0016\\f\\u0002\\u00c0!\\u0003\\u0002\\u0002\\u0002\\u00c1\\u00c2\\u0007\\u0013\",\n    \"\\u0002\\u0002\\u00c2\\u00c3\\u0007\\u001b\\u0002\\u0002\\u00c3\\u00d2\\u0007\\u0014\",\n    \"\\u0002\\u0002\\u00c4\\u00c5\\u0007\\u0013\\u0002\\u0002\\u00c5\\u00c6\\u0007\\t\",\n    \"\\u0002\\u0002\\u00c6\\u00d2\\u0007\\u0014\\u0002\\u0002\\u00c7\\u00c8\\u0007\\u0013\",\n    \"\\u0002\\u0002\\u00c8\\u00c9\\u0005$\\u0013\\u0002\\u00c9\\u00ca\\u0007\\u0014\",\n    \"\\u0002\\u0002\\u00ca\\u00d2\\u0003\\u0002\\u0002\\u0002\\u00cb\\u00cc\\u0007\\u0013\",\n    \"\\u0002\\u0002\\u00cc\\u00d2\\u0007\\u0014\\u0002\\u0002\\u00cd\\u00ce\\u0007\\u0018\",\n    \"\\u0002\\u0002\\u00ce\\u00cf\\u0005\\u0016\\f\\u0002\\u00cf\\u00d0\\u0007\\u0014\",\n    \"\\u0002\\u0002\\u00d0\\u00d2\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00c1\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d1\\u00c4\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00c7\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d1\\u00cb\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00cd\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d2#\\u0003\\u0002\\u0002\\u0002\\u00d3\\u00d5\\u0007\\u001b\",\n    \"\\u0002\\u0002\\u00d4\\u00d3\\u0003\\u0002\\u0002\\u0002\\u00d4\\u00d5\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d5\\u00d6\\u0003\\u0002\\u0002\\u0002\\u00d6\\u00d8\\u0007\\u0017\",\n    \"\\u0002\\u0002\\u00d7\\u00d9\\u0007\\u001b\\u0002\\u0002\\u00d8\\u00d7\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d8\\u00d9\\u0003\\u0002\\u0002\\u0002\\u00d9\\u00de\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00da\\u00dc\\u0007\\u0017\\u0002\\u0002\\u00db\\u00dd\\u0007\\u001b\",\n    \"\\u0002\\u0002\\u00dc\\u00db\\u0003\\u0002\\u0002\\u0002\\u00dc\\u00dd\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00dd\\u00df\\u0003\\u0002\\u0002\\u0002\\u00de\\u00da\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00de\\u00df\\u0003\\u0002\\u0002\\u0002\\u00df%\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00e0\\u00e1\\u0007!\\u0002\\u0002\\u00e1\\u00e2\\u0007\\u0003\",\n    \"\\u0002\\u0002\\u00e2\\u00e7\\u0005(\\u0015\\u0002\\u00e3\\u00e4\\u0007\\r\\u0002\",\n    \"\\u0002\\u00e4\\u00e6\\u0005(\\u0015\\u0002\\u00e5\\u00e3\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00e6\\u00e9\\u0003\\u0002\\u0002\\u0002\\u00e7\\u00e5\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00e7\\u00e8\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00ea\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00e9\\u00e7\\u0003\\u0002\\u0002\\u0002\\u00ea\\u00eb\\u0007\\u0004\\u0002\",\n    \"\\u0002\\u00eb\\u00f0\\u0003\\u0002\\u0002\\u0002\\u00ec\\u00ed\\u0007!\\u0002\",\n    \"\\u0002\\u00ed\\u00ee\\u0007\\u0003\\u0002\\u0002\\u00ee\\u00f0\\u0007\\u0004\\u0002\",\n    \"\\u0002\\u00ef\\u00e0\\u0003\\u0002\\u0002\\u0002\\u00ef\\u00ec\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00f0\\'\\u0003\\u0002\\u0002\\u0002\\u00f1\\u00f4\\u0005\\u0016\\f\\u0002\",\n    \"\\u00f2\\u00f4\\u0005,\\u0017\\u0002\\u00f3\\u00f1\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00f3\\u00f2\\u0003\\u0002\\u0002\\u0002\\u00f4)\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00f5\\u00f6\\u0007\\u0019\\u0002\\u0002\\u00f6+\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00f7\\u00f8\\u0007\\b\\u0002\\u0002\\u00f8\\u00f9\\u0005\\u0016\\f\\u0002\\u00f9\",\n    \"-\\u0003\\u0002\\u0002\\u0002\\u00fa\\u00fb\\u0007\\u001a\\u0002\\u0002\\u00fb\",\n    \"\\u00fc\\u00058\\u001d\\u0002\\u00fc\\u00fd\\u0007\\u001a\\u0002\\u0002\\u00fd\",\n    \"/\\u0003\\u0002\\u0002\\u0002\\u00fe\\u00ff\\t\\u0004\\u0002\\u0002\\u00ff1\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0100\\u0101\\u0007\\u0015\\u0002\\u0002\\u0101\\u0106\\u0005\",\n    \"4\\u001b\\u0002\\u0102\\u0103\\u0007\\r\\u0002\\u0002\\u0103\\u0105\\u00054\\u001b\",\n    \"\\u0002\\u0104\\u0102\\u0003\\u0002\\u0002\\u0002\\u0105\\u0108\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0106\\u0104\\u0003\\u0002\\u0002\\u0002\\u0106\\u0107\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0107\\u0109\\u0003\\u0002\\u0002\\u0002\\u0108\\u0106\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0109\\u010a\\u0007\\u0016\\u0002\\u0002\\u010a\\u010e\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u010b\\u010c\\u0007\\u0015\\u0002\\u0002\\u010c\\u010e\\u0007\\u0016\\u0002\",\n    \"\\u0002\\u010d\\u0100\\u0003\\u0002\\u0002\\u0002\\u010d\\u010b\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u010e3\\u0003\\u0002\\u0002\\u0002\\u010f\\u0110\\u0007\\\"\\u0002\\u0002\",\n    \"\\u0110\\u0111\\u0007\\u0017\\u0002\\u0002\\u0111\\u0112\\u00058\\u001d\\u0002\",\n    \"\\u01125\\u0003\\u0002\\u0002\\u0002\\u0113\\u0114\\u0007\\u0013\\u0002\\u0002\",\n    \"\\u0114\\u0119\\u00058\\u001d\\u0002\\u0115\\u0116\\u0007\\r\\u0002\\u0002\\u0116\",\n    \"\\u0118\\u00058\\u001d\\u0002\\u0117\\u0115\\u0003\\u0002\\u0002\\u0002\\u0118\",\n    \"\\u011b\\u0003\\u0002\\u0002\\u0002\\u0119\\u0117\\u0003\\u0002\\u0002\\u0002\\u0119\",\n    \"\\u011a\\u0003\\u0002\\u0002\\u0002\\u011a\\u011c\\u0003\\u0002\\u0002\\u0002\\u011b\",\n    \"\\u0119\\u0003\\u0002\\u0002\\u0002\\u011c\\u011d\\u0007\\u0014\\u0002\\u0002\\u011d\",\n    \"\\u0121\\u0003\\u0002\\u0002\\u0002\\u011e\\u011f\\u0007\\u0013\\u0002\\u0002\\u011f\",\n    \"\\u0121\\u0007\\u0014\\u0002\\u0002\\u0120\\u0113\\u0003\\u0002\\u0002\\u0002\\u0120\",\n    \"\\u011e\\u0003\\u0002\\u0002\\u0002\\u01217\\u0003\\u0002\\u0002\\u0002\\u0122\",\n    \"\\u0128\\u0007\\\"\\u0002\\u0002\\u0123\\u0128\\t\\u0005\\u0002\\u0002\\u0124\\u0128\",\n    \"\\u00052\\u001a\\u0002\\u0125\\u0128\\u00056\\u001c\\u0002\\u0126\\u0128\\u0007\",\n    \" \\u0002\\u0002\\u0127\\u0122\\u0003\\u0002\\u0002\\u0002\\u0127\\u0123\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0127\\u0124\\u0003\\u0002\\u0002\\u0002\\u0127\\u0125\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0127\\u0126\\u0003\\u0002\\u0002\\u0002\\u01289\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u001aJRTmr\\u0086\\u0099\\u009b\\u00a3\\u00ad\\u00b8\\u00d1\",\n    \"\\u00d4\\u00d8\\u00dc\\u00de\\u00e7\\u00ef\\u00f3\\u0106\\u010d\\u0119\\u0120\\u0127\"].join(\"\");\n\n\nconst atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\n\nconst decisionsToDFA = atn.decisionToState.map( (ds, index) => new antlr4.dfa.DFA(ds, index) );\n\nconst sharedContextCache = new antlr4.PredictionContextCache();\n\nexport default class JSONFormulaParser extends antlr4.Parser {\n\n    static grammarFileName = \"JSONFormula.g4\";\n    static literalNames = [ null, \"'('\", \"')'\", \"'+'\", \"'-'\", \"'<>'\", \"'&'\", \n                            \"'*'\", \"'/'\", \"'^'\", \"'%'\", \"','\", \"'.'\", \"'&&'\", \n                            \"'||'\", \"'!'\", \"'|'\", \"'['\", \"']'\", \"'{'\", \"'}'\", \n                            \"':'\", \"'[?'\", \"'@'\", \"'`'\" ];\n    static symbolicNames = [ null, null, null, null, null, null, null, null, \n                             null, null, null, null, null, null, null, null, \n                             null, null, null, null, null, null, null, null, \n                             null, \"SIGNED_INT\", \"NUMBER\", \"FUNCTIONS\", \n                             \"COMPARATOR\", \"RAW_STRING\", \"JSON_CONSTANT\", \n                             \"NAME\", \"STRING\", \"REAL_OR_EXPONENT_NUMBER\", \n                             \"WS\" ];\n    static ruleNames = [ \"formula\", \"expression\", \"unary_op\", \"binary_op\", \n                         \"postfix_op\", \"function_call\", \"parameter\", \"nonempty_expr_list\", \n                         \"expression_list\", \"parm_separator\", \"jmesPathExpression\", \n                         \"chainedExpression\", \"wildcard\", \"multiSelectList\", \n                         \"multiSelectHash\", \"keyvalExpr\", \"bracketSpecifier\", \n                         \"slice\", \"functionExpression\", \"functionArg\", \"currentNode\", \n                         \"expressionType\", \"literal\", \"identifier\", \"jsonObject\", \n                         \"jsonObjectPair\", \"jsonArray\", \"jsonValue\" ];\n\n    constructor(input) {\n        super(input);\n        this._interp = new antlr4.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);\n        this.ruleNames = JSONFormulaParser.ruleNames;\n        this.literalNames = JSONFormulaParser.literalNames;\n        this.symbolicNames = JSONFormulaParser.symbolicNames;\n    }\n\n    get atn() {\n        return atn;\n    }\n\n    sempred(localctx, ruleIndex, predIndex) {\n    \tswitch(ruleIndex) {\n    \tcase 1:\n    \t    \t\treturn this.expression_sempred(localctx, predIndex);\n    \tcase 7:\n    \t    \t\treturn this.nonempty_expr_list_sempred(localctx, predIndex);\n    \tcase 10:\n    \t    \t\treturn this.jmesPathExpression_sempred(localctx, predIndex);\n        default:\n            throw \"No predicate with index:\" + ruleIndex;\n       }\n    }\n\n    expression_sempred(localctx, predIndex) {\n    \tswitch(predIndex) {\n    \t\tcase 0:\n    \t\t\treturn this.precpred(this._ctx, 6);\n    \t\tcase 1:\n    \t\t\treturn this.precpred(this._ctx, 4);\n    \t\tdefault:\n    \t\t\tthrow \"No predicate with index:\" + predIndex;\n    \t}\n    };\n\n    nonempty_expr_list_sempred(localctx, predIndex) {\n    \tswitch(predIndex) {\n    \t\tcase 2:\n    \t\t\treturn this.precpred(this._ctx, 1);\n    \t\tdefault:\n    \t\t\tthrow \"No predicate with index:\" + predIndex;\n    \t}\n    };\n\n    jmesPathExpression_sempred(localctx, predIndex) {\n    \tswitch(predIndex) {\n    \t\tcase 3:\n    \t\t\treturn this.precpred(this._ctx, 14);\n    \t\tcase 4:\n    \t\t\treturn this.precpred(this._ctx, 13);\n    \t\tcase 5:\n    \t\t\treturn this.precpred(this._ctx, 12);\n    \t\tcase 6:\n    \t\t\treturn this.precpred(this._ctx, 3);\n    \t\tcase 7:\n    \t\t\treturn this.precpred(this._ctx, 17);\n    \t\tcase 8:\n    \t\t\treturn this.precpred(this._ctx, 16);\n    \t\tdefault:\n    \t\t\tthrow \"No predicate with index:\" + predIndex;\n    \t}\n    };\n\n\n\n\n\tformula() {\n\t    let localctx = new FormulaContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 0, JSONFormulaParser.RULE_formula);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 56;\n\t        this.expression(0);\n\t        this.state = 57;\n\t        this.match(JSONFormulaParser.EOF);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\texpression(_p) {\n\t\tif(_p===undefined) {\n\t\t    _p = 0;\n\t\t}\n\t    const _parentctx = this._ctx;\n\t    const _parentState = this.state;\n\t    let localctx = new ExpressionContext(this, this._ctx, _parentState);\n\t    let _prevctx = localctx;\n\t    const _startState = 2;\n\t    this.enterRecursionRule(localctx, 2, JSONFormulaParser.RULE_expression, _p);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 72;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,0,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            localctx = new TopLevelIntContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\n\t            this.state = 60;\n\t            this.match(JSONFormulaParser.SIGNED_INT);\n\t            break;\n\n\t        case 2:\n\t            localctx = new TopLevelNumberContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 61;\n\t            this.match(JSONFormulaParser.NUMBER);\n\t            break;\n\n\t        case 3:\n\t            localctx = new TopLevelStringContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 62;\n\t            this.match(JSONFormulaParser.RAW_STRING);\n\t            break;\n\n\t        case 4:\n\t            localctx = new UnaryExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 63;\n\t            this.unary_op();\n\t            this.state = 64;\n\t            this.expression(5);\n\t            break;\n\n\t        case 5:\n\t            localctx = new BraceExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 66;\n\t            this.match(JSONFormulaParser.T__0);\n\t            this.state = 67;\n\t            this.expression(0);\n\t            this.state = 68;\n\t            this.match(JSONFormulaParser.T__1);\n\t            break;\n\n\t        case 6:\n\t            localctx = new FunctionCallContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 70;\n\t            this.function_call();\n\t            break;\n\n\t        case 7:\n\t            localctx = new JmesPathContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 71;\n\t            this.jmesPathExpression(0);\n\t            break;\n\n\t        }\n\t        this._ctx.stop = this._input.LT(-1);\n\t        this.state = 82;\n\t        this._errHandler.sync(this);\n\t        var _alt = this._interp.adaptivePredict(this._input,2,this._ctx)\n\t        while(_alt!=2 && _alt!=antlr4.atn.ATN.INVALID_ALT_NUMBER) {\n\t            if(_alt===1) {\n\t                if(this._parseListeners!==null) {\n\t                    this.triggerExitRuleEvent();\n\t                }\n\t                _prevctx = localctx;\n\t                this.state = 80;\n\t                this._errHandler.sync(this);\n\t                var la_ = this._interp.adaptivePredict(this._input,1,this._ctx);\n\t                switch(la_) {\n\t                case 1:\n\t                    localctx = new BinaryExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_expression);\n\t                    this.state = 74;\n\t                    if (!( this.precpred(this._ctx, 6))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 6)\");\n\t                    }\n\t                    this.state = 75;\n\t                    this.binary_op();\n\t                    this.state = 76;\n\t                    this.expression(7);\n\t                    break;\n\n\t                case 2:\n\t                    localctx = new PostfixContext(this, new ExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_expression);\n\t                    this.state = 78;\n\t                    if (!( this.precpred(this._ctx, 4))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 4)\");\n\t                    }\n\t                    this.state = 79;\n\t                    this.postfix_op();\n\t                    break;\n\n\t                } \n\t            }\n\t            this.state = 84;\n\t            this._errHandler.sync(this);\n\t            _alt = this._interp.adaptivePredict(this._input,2,this._ctx);\n\t        }\n\n\t    } catch( error) {\n\t        if(error instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = error;\n\t\t        this._errHandler.reportError(this, error);\n\t\t        this._errHandler.recover(this, error);\n\t\t    } else {\n\t\t    \tthrow error;\n\t\t    }\n\t    } finally {\n\t        this.unrollRecursionContexts(_parentctx)\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tunary_op() {\n\t    let localctx = new Unary_opContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 4, JSONFormulaParser.RULE_unary_op);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 85;\n\t        _la = this._input.LA(1);\n\t        if(!(_la===JSONFormulaParser.T__2 || _la===JSONFormulaParser.T__3)) {\n\t        this._errHandler.recoverInline(this);\n\t        }\n\t        else {\n\t        \tthis._errHandler.reportMatch(this);\n\t            this.consume();\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tbinary_op() {\n\t    let localctx = new Binary_opContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 6, JSONFormulaParser.RULE_binary_op);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 87;\n\t        _la = this._input.LA(1);\n\t        if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << JSONFormulaParser.T__2) | (1 << JSONFormulaParser.T__3) | (1 << JSONFormulaParser.T__4) | (1 << JSONFormulaParser.T__5) | (1 << JSONFormulaParser.T__6) | (1 << JSONFormulaParser.T__7) | (1 << JSONFormulaParser.T__8) | (1 << JSONFormulaParser.COMPARATOR))) !== 0))) {\n\t        this._errHandler.recoverInline(this);\n\t        }\n\t        else {\n\t        \tthis._errHandler.reportMatch(this);\n\t            this.consume();\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tpostfix_op() {\n\t    let localctx = new Postfix_opContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 8, JSONFormulaParser.RULE_postfix_op);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 89;\n\t        this.match(JSONFormulaParser.T__9);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tfunction_call() {\n\t    let localctx = new Function_callContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 10, JSONFormulaParser.RULE_function_call);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 91;\n\t        this.match(JSONFormulaParser.FUNCTIONS);\n\t        this.state = 92;\n\t        this.match(JSONFormulaParser.T__0);\n\t        this.state = 93;\n\t        this.expression_list();\n\t        this.state = 94;\n\t        this.match(JSONFormulaParser.T__1);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tparameter() {\n\t    let localctx = new ParameterContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 12, JSONFormulaParser.RULE_parameter);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 96;\n\t        this.expression(0);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\tnonempty_expr_list(_p) {\n\t\tif(_p===undefined) {\n\t\t    _p = 0;\n\t\t}\n\t    const _parentctx = this._ctx;\n\t    const _parentState = this.state;\n\t    let localctx = new Nonempty_expr_listContext(this, this._ctx, _parentState);\n\t    let _prevctx = localctx;\n\t    const _startState = 14;\n\t    this.enterRecursionRule(localctx, 14, JSONFormulaParser.RULE_nonempty_expr_list, _p);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 99;\n\t        this.parameter();\n\t        this._ctx.stop = this._input.LT(-1);\n\t        this.state = 107;\n\t        this._errHandler.sync(this);\n\t        var _alt = this._interp.adaptivePredict(this._input,3,this._ctx)\n\t        while(_alt!=2 && _alt!=antlr4.atn.ATN.INVALID_ALT_NUMBER) {\n\t            if(_alt===1) {\n\t                if(this._parseListeners!==null) {\n\t                    this.triggerExitRuleEvent();\n\t                }\n\t                _prevctx = localctx;\n\t                localctx = new Nonempty_expr_listContext(this, _parentctx, _parentState);\n\t                this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_nonempty_expr_list);\n\t                this.state = 101;\n\t                if (!( this.precpred(this._ctx, 1))) {\n\t                    throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 1)\");\n\t                }\n\t                this.state = 102;\n\t                this.parm_separator();\n\t                this.state = 103;\n\t                this.parameter(); \n\t            }\n\t            this.state = 109;\n\t            this._errHandler.sync(this);\n\t            _alt = this._interp.adaptivePredict(this._input,3,this._ctx);\n\t        }\n\n\t    } catch( error) {\n\t        if(error instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = error;\n\t\t        this._errHandler.reportError(this, error);\n\t\t        this._errHandler.recover(this, error);\n\t\t    } else {\n\t\t    \tthrow error;\n\t\t    }\n\t    } finally {\n\t        this.unrollRecursionContexts(_parentctx)\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\texpression_list() {\n\t    let localctx = new Expression_listContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 16, JSONFormulaParser.RULE_expression_list);\n\t    try {\n\t        this.state = 112;\n\t        this._errHandler.sync(this);\n\t        switch(this._input.LA(1)) {\n\t        case JSONFormulaParser.T__1:\n\t            this.enterOuterAlt(localctx, 1);\n\n\t            break;\n\t        case JSONFormulaParser.T__0:\n\t        case JSONFormulaParser.T__2:\n\t        case JSONFormulaParser.T__3:\n\t        case JSONFormulaParser.T__6:\n\t        case JSONFormulaParser.T__14:\n\t        case JSONFormulaParser.T__16:\n\t        case JSONFormulaParser.T__18:\n\t        case JSONFormulaParser.T__21:\n\t        case JSONFormulaParser.T__22:\n\t        case JSONFormulaParser.T__23:\n\t        case JSONFormulaParser.SIGNED_INT:\n\t        case JSONFormulaParser.NUMBER:\n\t        case JSONFormulaParser.FUNCTIONS:\n\t        case JSONFormulaParser.RAW_STRING:\n\t        case JSONFormulaParser.JSON_CONSTANT:\n\t        case JSONFormulaParser.NAME:\n\t        case JSONFormulaParser.STRING:\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 111;\n\t            this.nonempty_expr_list(0);\n\t            break;\n\t        default:\n\t            throw new antlr4.error.NoViableAltException(this);\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tparm_separator() {\n\t    let localctx = new Parm_separatorContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 18, JSONFormulaParser.RULE_parm_separator);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 114;\n\t        this.match(JSONFormulaParser.T__10);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\tjmesPathExpression(_p) {\n\t\tif(_p===undefined) {\n\t\t    _p = 0;\n\t\t}\n\t    const _parentctx = this._ctx;\n\t    const _parentState = this.state;\n\t    let localctx = new JmesPathExpressionContext(this, this._ctx, _parentState);\n\t    let _prevctx = localctx;\n\t    const _startState = 20;\n\t    this.enterRecursionRule(localctx, 20, JSONFormulaParser.RULE_jmesPathExpression, _p);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 132;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,5,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            localctx = new BracketExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\n\t            this.state = 117;\n\t            this.bracketSpecifier();\n\t            break;\n\n\t        case 2:\n\t            localctx = new IdentifierExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 118;\n\t            this.identifier();\n\t            break;\n\n\t        case 3:\n\t            localctx = new NotExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 119;\n\t            this.match(JSONFormulaParser.T__14);\n\t            this.state = 120;\n\t            this.jmesPathExpression(10);\n\t            break;\n\n\t        case 4:\n\t            localctx = new ParenExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 121;\n\t            this.match(JSONFormulaParser.T__0);\n\t            this.state = 122;\n\t            this.jmesPathExpression(0);\n\t            this.state = 123;\n\t            this.match(JSONFormulaParser.T__1);\n\t            break;\n\n\t        case 5:\n\t            localctx = new WildcardExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 125;\n\t            this.wildcard();\n\t            break;\n\n\t        case 6:\n\t            localctx = new MultiSelectListExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 126;\n\t            this.multiSelectList();\n\t            break;\n\n\t        case 7:\n\t            localctx = new MultiSelectHashExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 127;\n\t            this.multiSelectHash();\n\t            break;\n\n\t        case 8:\n\t            localctx = new LiteralExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 128;\n\t            this.literal();\n\t            break;\n\n\t        case 9:\n\t            localctx = new FunctionCallExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 129;\n\t            this.functionExpression();\n\t            break;\n\n\t        case 10:\n\t            localctx = new RawStringExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 130;\n\t            this.match(JSONFormulaParser.RAW_STRING);\n\t            break;\n\n\t        case 11:\n\t            localctx = new CurrentNodeExpressionContext(this, localctx);\n\t            this._ctx = localctx;\n\t            _prevctx = localctx;\n\t            this.state = 131;\n\t            this.currentNode();\n\t            break;\n\n\t        }\n\t        this._ctx.stop = this._input.LT(-1);\n\t        this.state = 153;\n\t        this._errHandler.sync(this);\n\t        var _alt = this._interp.adaptivePredict(this._input,7,this._ctx)\n\t        while(_alt!=2 && _alt!=antlr4.atn.ATN.INVALID_ALT_NUMBER) {\n\t            if(_alt===1) {\n\t                if(this._parseListeners!==null) {\n\t                    this.triggerExitRuleEvent();\n\t                }\n\t                _prevctx = localctx;\n\t                this.state = 151;\n\t                this._errHandler.sync(this);\n\t                var la_ = this._interp.adaptivePredict(this._input,6,this._ctx);\n\t                switch(la_) {\n\t                case 1:\n\t                    localctx = new ComparisonExpressionContext(this, new JmesPathExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_jmesPathExpression);\n\t                    this.state = 134;\n\t                    if (!( this.precpred(this._ctx, 14))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 14)\");\n\t                    }\n\t                    this.state = 135;\n\t                    this.match(JSONFormulaParser.COMPARATOR);\n\t                    this.state = 136;\n\t                    this.jmesPathExpression(15);\n\t                    break;\n\n\t                case 2:\n\t                    localctx = new AndExpressionContext(this, new JmesPathExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_jmesPathExpression);\n\t                    this.state = 137;\n\t                    if (!( this.precpred(this._ctx, 13))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 13)\");\n\t                    }\n\t                    this.state = 138;\n\t                    this.match(JSONFormulaParser.T__12);\n\t                    this.state = 139;\n\t                    this.jmesPathExpression(14);\n\t                    break;\n\n\t                case 3:\n\t                    localctx = new OrExpressionContext(this, new JmesPathExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_jmesPathExpression);\n\t                    this.state = 140;\n\t                    if (!( this.precpred(this._ctx, 12))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 12)\");\n\t                    }\n\t                    this.state = 141;\n\t                    this.match(JSONFormulaParser.T__13);\n\t                    this.state = 142;\n\t                    this.jmesPathExpression(13);\n\t                    break;\n\n\t                case 4:\n\t                    localctx = new PipeExpressionContext(this, new JmesPathExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_jmesPathExpression);\n\t                    this.state = 143;\n\t                    if (!( this.precpred(this._ctx, 3))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 3)\");\n\t                    }\n\t                    this.state = 144;\n\t                    this.match(JSONFormulaParser.T__15);\n\t                    this.state = 145;\n\t                    this.jmesPathExpression(4);\n\t                    break;\n\n\t                case 5:\n\t                    localctx = new ChainExpressionContext(this, new JmesPathExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_jmesPathExpression);\n\t                    this.state = 146;\n\t                    if (!( this.precpred(this._ctx, 17))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 17)\");\n\t                    }\n\t                    this.state = 147;\n\t                    this.match(JSONFormulaParser.T__11);\n\t                    this.state = 148;\n\t                    this.chainedExpression();\n\t                    break;\n\n\t                case 6:\n\t                    localctx = new BracketedExpressionContext(this, new JmesPathExpressionContext(this, _parentctx, _parentState));\n\t                    this.pushNewRecursionContext(localctx, _startState, JSONFormulaParser.RULE_jmesPathExpression);\n\t                    this.state = 149;\n\t                    if (!( this.precpred(this._ctx, 16))) {\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 16)\");\n\t                    }\n\t                    this.state = 150;\n\t                    this.bracketSpecifier();\n\t                    break;\n\n\t                } \n\t            }\n\t            this.state = 155;\n\t            this._errHandler.sync(this);\n\t            _alt = this._interp.adaptivePredict(this._input,7,this._ctx);\n\t        }\n\n\t    } catch( error) {\n\t        if(error instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = error;\n\t\t        this._errHandler.reportError(this, error);\n\t\t        this._errHandler.recover(this, error);\n\t\t    } else {\n\t\t    \tthrow error;\n\t\t    }\n\t    } finally {\n\t        this.unrollRecursionContexts(_parentctx)\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tchainedExpression() {\n\t    let localctx = new ChainedExpressionContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 22, JSONFormulaParser.RULE_chainedExpression);\n\t    try {\n\t        this.state = 161;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,8,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            localctx = new ChainedIdentifierContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 156;\n\t            this.identifier();\n\t            break;\n\n\t        case 2:\n\t            localctx = new ChainedMultiSelectListContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 157;\n\t            this.multiSelectList();\n\t            break;\n\n\t        case 3:\n\t            localctx = new ChainedMultiSelectHashContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 3);\n\t            this.state = 158;\n\t            this.multiSelectHash();\n\t            break;\n\n\t        case 4:\n\t            localctx = new ChainedFunctionExpressionContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 4);\n\t            this.state = 159;\n\t            this.functionExpression();\n\t            break;\n\n\t        case 5:\n\t            localctx = new ChainedWildcardContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 5);\n\t            this.state = 160;\n\t            this.wildcard();\n\t            break;\n\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\twildcard() {\n\t    let localctx = new WildcardContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 24, JSONFormulaParser.RULE_wildcard);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 163;\n\t        this.match(JSONFormulaParser.T__6);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tmultiSelectList() {\n\t    let localctx = new MultiSelectListContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 26, JSONFormulaParser.RULE_multiSelectList);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 165;\n\t        this.match(JSONFormulaParser.T__16);\n\t        this.state = 166;\n\t        this.jmesPathExpression(0);\n\t        this.state = 171;\n\t        this._errHandler.sync(this);\n\t        _la = this._input.LA(1);\n\t        while(_la===JSONFormulaParser.T__10) {\n\t            this.state = 167;\n\t            this.match(JSONFormulaParser.T__10);\n\t            this.state = 168;\n\t            this.jmesPathExpression(0);\n\t            this.state = 173;\n\t            this._errHandler.sync(this);\n\t            _la = this._input.LA(1);\n\t        }\n\t        this.state = 174;\n\t        this.match(JSONFormulaParser.T__17);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tmultiSelectHash() {\n\t    let localctx = new MultiSelectHashContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 28, JSONFormulaParser.RULE_multiSelectHash);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 176;\n\t        this.match(JSONFormulaParser.T__18);\n\t        this.state = 177;\n\t        this.keyvalExpr();\n\t        this.state = 182;\n\t        this._errHandler.sync(this);\n\t        _la = this._input.LA(1);\n\t        while(_la===JSONFormulaParser.T__10) {\n\t            this.state = 178;\n\t            this.match(JSONFormulaParser.T__10);\n\t            this.state = 179;\n\t            this.keyvalExpr();\n\t            this.state = 184;\n\t            this._errHandler.sync(this);\n\t            _la = this._input.LA(1);\n\t        }\n\t        this.state = 185;\n\t        this.match(JSONFormulaParser.T__19);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tkeyvalExpr() {\n\t    let localctx = new KeyvalExprContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 30, JSONFormulaParser.RULE_keyvalExpr);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 187;\n\t        this.identifier();\n\t        this.state = 188;\n\t        this.match(JSONFormulaParser.T__20);\n\t        this.state = 189;\n\t        this.jmesPathExpression(0);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tbracketSpecifier() {\n\t    let localctx = new BracketSpecifierContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 32, JSONFormulaParser.RULE_bracketSpecifier);\n\t    try {\n\t        this.state = 207;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,11,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            localctx = new BracketIndexContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 191;\n\t            this.match(JSONFormulaParser.T__16);\n\t            this.state = 192;\n\t            this.match(JSONFormulaParser.SIGNED_INT);\n\t            this.state = 193;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        case 2:\n\t            localctx = new BracketStarContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 194;\n\t            this.match(JSONFormulaParser.T__16);\n\t            this.state = 195;\n\t            this.match(JSONFormulaParser.T__6);\n\t            this.state = 196;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        case 3:\n\t            localctx = new BracketSliceContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 3);\n\t            this.state = 197;\n\t            this.match(JSONFormulaParser.T__16);\n\t            this.state = 198;\n\t            this.slice();\n\t            this.state = 199;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        case 4:\n\t            localctx = new BracketFlattenContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 4);\n\t            this.state = 201;\n\t            this.match(JSONFormulaParser.T__16);\n\t            this.state = 202;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        case 5:\n\t            localctx = new SelectContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 5);\n\t            this.state = 203;\n\t            this.match(JSONFormulaParser.T__21);\n\t            this.state = 204;\n\t            this.jmesPathExpression(0);\n\t            this.state = 205;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tslice() {\n\t    let localctx = new SliceContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 34, JSONFormulaParser.RULE_slice);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 210;\n\t        this._errHandler.sync(this);\n\t        _la = this._input.LA(1);\n\t        if(_la===JSONFormulaParser.SIGNED_INT) {\n\t            this.state = 209;\n\t            localctx.start = this.match(JSONFormulaParser.SIGNED_INT);\n\t        }\n\n\t        this.state = 212;\n\t        this.match(JSONFormulaParser.T__20);\n\t        this.state = 214;\n\t        this._errHandler.sync(this);\n\t        _la = this._input.LA(1);\n\t        if(_la===JSONFormulaParser.SIGNED_INT) {\n\t            this.state = 213;\n\t            localctx.stop = this.match(JSONFormulaParser.SIGNED_INT);\n\t        }\n\n\t        this.state = 220;\n\t        this._errHandler.sync(this);\n\t        _la = this._input.LA(1);\n\t        if(_la===JSONFormulaParser.T__20) {\n\t            this.state = 216;\n\t            this.match(JSONFormulaParser.T__20);\n\t            this.state = 218;\n\t            this._errHandler.sync(this);\n\t            _la = this._input.LA(1);\n\t            if(_la===JSONFormulaParser.SIGNED_INT) {\n\t                this.state = 217;\n\t                localctx.step = this.match(JSONFormulaParser.SIGNED_INT);\n\t            }\n\n\t        }\n\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tfunctionExpression() {\n\t    let localctx = new FunctionExpressionContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 36, JSONFormulaParser.RULE_functionExpression);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.state = 237;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,17,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 222;\n\t            this.match(JSONFormulaParser.NAME);\n\t            this.state = 223;\n\t            this.match(JSONFormulaParser.T__0);\n\t            this.state = 224;\n\t            this.functionArg();\n\t            this.state = 229;\n\t            this._errHandler.sync(this);\n\t            _la = this._input.LA(1);\n\t            while(_la===JSONFormulaParser.T__10) {\n\t                this.state = 225;\n\t                this.match(JSONFormulaParser.T__10);\n\t                this.state = 226;\n\t                this.functionArg();\n\t                this.state = 231;\n\t                this._errHandler.sync(this);\n\t                _la = this._input.LA(1);\n\t            }\n\t            this.state = 232;\n\t            this.match(JSONFormulaParser.T__1);\n\t            break;\n\n\t        case 2:\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 234;\n\t            this.match(JSONFormulaParser.NAME);\n\t            this.state = 235;\n\t            this.match(JSONFormulaParser.T__0);\n\t            this.state = 236;\n\t            this.match(JSONFormulaParser.T__1);\n\t            break;\n\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tfunctionArg() {\n\t    let localctx = new FunctionArgContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 38, JSONFormulaParser.RULE_functionArg);\n\t    try {\n\t        this.state = 241;\n\t        this._errHandler.sync(this);\n\t        switch(this._input.LA(1)) {\n\t        case JSONFormulaParser.T__0:\n\t        case JSONFormulaParser.T__6:\n\t        case JSONFormulaParser.T__14:\n\t        case JSONFormulaParser.T__16:\n\t        case JSONFormulaParser.T__18:\n\t        case JSONFormulaParser.T__21:\n\t        case JSONFormulaParser.T__22:\n\t        case JSONFormulaParser.T__23:\n\t        case JSONFormulaParser.RAW_STRING:\n\t        case JSONFormulaParser.JSON_CONSTANT:\n\t        case JSONFormulaParser.NAME:\n\t        case JSONFormulaParser.STRING:\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 239;\n\t            this.jmesPathExpression(0);\n\t            break;\n\t        case JSONFormulaParser.T__5:\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 240;\n\t            this.expressionType();\n\t            break;\n\t        default:\n\t            throw new antlr4.error.NoViableAltException(this);\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tcurrentNode() {\n\t    let localctx = new CurrentNodeContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 40, JSONFormulaParser.RULE_currentNode);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 243;\n\t        this.match(JSONFormulaParser.T__22);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\texpressionType() {\n\t    let localctx = new ExpressionTypeContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 42, JSONFormulaParser.RULE_expressionType);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 245;\n\t        this.match(JSONFormulaParser.T__5);\n\t        this.state = 246;\n\t        this.jmesPathExpression(0);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tliteral() {\n\t    let localctx = new LiteralContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 44, JSONFormulaParser.RULE_literal);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 248;\n\t        this.match(JSONFormulaParser.T__23);\n\t        this.state = 249;\n\t        this.jsonValue();\n\t        this.state = 250;\n\t        this.match(JSONFormulaParser.T__23);\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tidentifier() {\n\t    let localctx = new IdentifierContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 46, JSONFormulaParser.RULE_identifier);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 252;\n\t        _la = this._input.LA(1);\n\t        if(!(((((_la - 30)) & ~0x1f) == 0 && ((1 << (_la - 30)) & ((1 << (JSONFormulaParser.JSON_CONSTANT - 30)) | (1 << (JSONFormulaParser.NAME - 30)) | (1 << (JSONFormulaParser.STRING - 30)))) !== 0))) {\n\t        this._errHandler.recoverInline(this);\n\t        }\n\t        else {\n\t        \tthis._errHandler.reportMatch(this);\n\t            this.consume();\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tjsonObject() {\n\t    let localctx = new JsonObjectContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 48, JSONFormulaParser.RULE_jsonObject);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.state = 267;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,20,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 254;\n\t            this.match(JSONFormulaParser.T__18);\n\t            this.state = 255;\n\t            this.jsonObjectPair();\n\t            this.state = 260;\n\t            this._errHandler.sync(this);\n\t            _la = this._input.LA(1);\n\t            while(_la===JSONFormulaParser.T__10) {\n\t                this.state = 256;\n\t                this.match(JSONFormulaParser.T__10);\n\t                this.state = 257;\n\t                this.jsonObjectPair();\n\t                this.state = 262;\n\t                this._errHandler.sync(this);\n\t                _la = this._input.LA(1);\n\t            }\n\t            this.state = 263;\n\t            this.match(JSONFormulaParser.T__19);\n\t            break;\n\n\t        case 2:\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 265;\n\t            this.match(JSONFormulaParser.T__18);\n\t            this.state = 266;\n\t            this.match(JSONFormulaParser.T__19);\n\t            break;\n\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tjsonObjectPair() {\n\t    let localctx = new JsonObjectPairContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 50, JSONFormulaParser.RULE_jsonObjectPair);\n\t    try {\n\t        this.enterOuterAlt(localctx, 1);\n\t        this.state = 269;\n\t        this.match(JSONFormulaParser.STRING);\n\t        this.state = 270;\n\t        this.match(JSONFormulaParser.T__20);\n\t        this.state = 271;\n\t        this.jsonValue();\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tjsonArray() {\n\t    let localctx = new JsonArrayContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 52, JSONFormulaParser.RULE_jsonArray);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.state = 286;\n\t        this._errHandler.sync(this);\n\t        var la_ = this._interp.adaptivePredict(this._input,22,this._ctx);\n\t        switch(la_) {\n\t        case 1:\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 273;\n\t            this.match(JSONFormulaParser.T__16);\n\t            this.state = 274;\n\t            this.jsonValue();\n\t            this.state = 279;\n\t            this._errHandler.sync(this);\n\t            _la = this._input.LA(1);\n\t            while(_la===JSONFormulaParser.T__10) {\n\t                this.state = 275;\n\t                this.match(JSONFormulaParser.T__10);\n\t                this.state = 276;\n\t                this.jsonValue();\n\t                this.state = 281;\n\t                this._errHandler.sync(this);\n\t                _la = this._input.LA(1);\n\t            }\n\t            this.state = 282;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        case 2:\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 284;\n\t            this.match(JSONFormulaParser.T__16);\n\t            this.state = 285;\n\t            this.match(JSONFormulaParser.T__17);\n\t            break;\n\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n\n\tjsonValue() {\n\t    let localctx = new JsonValueContext(this, this._ctx, this.state);\n\t    this.enterRule(localctx, 54, JSONFormulaParser.RULE_jsonValue);\n\t    var _la = 0; // Token type\n\t    try {\n\t        this.state = 293;\n\t        this._errHandler.sync(this);\n\t        switch(this._input.LA(1)) {\n\t        case JSONFormulaParser.STRING:\n\t            localctx = new JsonStringValueContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 1);\n\t            this.state = 288;\n\t            this.match(JSONFormulaParser.STRING);\n\t            break;\n\t        case JSONFormulaParser.SIGNED_INT:\n\t        case JSONFormulaParser.REAL_OR_EXPONENT_NUMBER:\n\t            localctx = new JsonNumberValueContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 2);\n\t            this.state = 289;\n\t            _la = this._input.LA(1);\n\t            if(!(_la===JSONFormulaParser.SIGNED_INT || _la===JSONFormulaParser.REAL_OR_EXPONENT_NUMBER)) {\n\t            this._errHandler.recoverInline(this);\n\t            }\n\t            else {\n\t            \tthis._errHandler.reportMatch(this);\n\t                this.consume();\n\t            }\n\t            break;\n\t        case JSONFormulaParser.T__18:\n\t            localctx = new JsonObjectValueContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 3);\n\t            this.state = 290;\n\t            this.jsonObject();\n\t            break;\n\t        case JSONFormulaParser.T__16:\n\t            localctx = new JsonArrayValueContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 4);\n\t            this.state = 291;\n\t            this.jsonArray();\n\t            break;\n\t        case JSONFormulaParser.JSON_CONSTANT:\n\t            localctx = new JsonConstantValueContext(this, localctx);\n\t            this.enterOuterAlt(localctx, 5);\n\t            this.state = 292;\n\t            this.match(JSONFormulaParser.JSON_CONSTANT);\n\t            break;\n\t        default:\n\t            throw new antlr4.error.NoViableAltException(this);\n\t        }\n\t    } catch (re) {\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\n\t\t        localctx.exception = re;\n\t\t        this._errHandler.reportError(this, re);\n\t\t        this._errHandler.recover(this, re);\n\t\t    } else {\n\t\t    \tthrow re;\n\t\t    }\n\t    } finally {\n\t        this.exitRule();\n\t    }\n\t    return localctx;\n\t}\n\n\n}\n\nJSONFormulaParser.EOF = antlr4.Token.EOF;\nJSONFormulaParser.T__0 = 1;\nJSONFormulaParser.T__1 = 2;\nJSONFormulaParser.T__2 = 3;\nJSONFormulaParser.T__3 = 4;\nJSONFormulaParser.T__4 = 5;\nJSONFormulaParser.T__5 = 6;\nJSONFormulaParser.T__6 = 7;\nJSONFormulaParser.T__7 = 8;\nJSONFormulaParser.T__8 = 9;\nJSONFormulaParser.T__9 = 10;\nJSONFormulaParser.T__10 = 11;\nJSONFormulaParser.T__11 = 12;\nJSONFormulaParser.T__12 = 13;\nJSONFormulaParser.T__13 = 14;\nJSONFormulaParser.T__14 = 15;\nJSONFormulaParser.T__15 = 16;\nJSONFormulaParser.T__16 = 17;\nJSONFormulaParser.T__17 = 18;\nJSONFormulaParser.T__18 = 19;\nJSONFormulaParser.T__19 = 20;\nJSONFormulaParser.T__20 = 21;\nJSONFormulaParser.T__21 = 22;\nJSONFormulaParser.T__22 = 23;\nJSONFormulaParser.T__23 = 24;\nJSONFormulaParser.SIGNED_INT = 25;\nJSONFormulaParser.NUMBER = 26;\nJSONFormulaParser.FUNCTIONS = 27;\nJSONFormulaParser.COMPARATOR = 28;\nJSONFormulaParser.RAW_STRING = 29;\nJSONFormulaParser.JSON_CONSTANT = 30;\nJSONFormulaParser.NAME = 31;\nJSONFormulaParser.STRING = 32;\nJSONFormulaParser.REAL_OR_EXPONENT_NUMBER = 33;\nJSONFormulaParser.WS = 34;\n\nJSONFormulaParser.RULE_formula = 0;\nJSONFormulaParser.RULE_expression = 1;\nJSONFormulaParser.RULE_unary_op = 2;\nJSONFormulaParser.RULE_binary_op = 3;\nJSONFormulaParser.RULE_postfix_op = 4;\nJSONFormulaParser.RULE_function_call = 5;\nJSONFormulaParser.RULE_parameter = 6;\nJSONFormulaParser.RULE_nonempty_expr_list = 7;\nJSONFormulaParser.RULE_expression_list = 8;\nJSONFormulaParser.RULE_parm_separator = 9;\nJSONFormulaParser.RULE_jmesPathExpression = 10;\nJSONFormulaParser.RULE_chainedExpression = 11;\nJSONFormulaParser.RULE_wildcard = 12;\nJSONFormulaParser.RULE_multiSelectList = 13;\nJSONFormulaParser.RULE_multiSelectHash = 14;\nJSONFormulaParser.RULE_keyvalExpr = 15;\nJSONFormulaParser.RULE_bracketSpecifier = 16;\nJSONFormulaParser.RULE_slice = 17;\nJSONFormulaParser.RULE_functionExpression = 18;\nJSONFormulaParser.RULE_functionArg = 19;\nJSONFormulaParser.RULE_currentNode = 20;\nJSONFormulaParser.RULE_expressionType = 21;\nJSONFormulaParser.RULE_literal = 22;\nJSONFormulaParser.RULE_identifier = 23;\nJSONFormulaParser.RULE_jsonObject = 24;\nJSONFormulaParser.RULE_jsonObjectPair = 25;\nJSONFormulaParser.RULE_jsonArray = 26;\nJSONFormulaParser.RULE_jsonValue = 27;\n\nclass FormulaContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_formula;\n    }\n\n\texpression() {\n\t    return this.getTypedRuleContext(ExpressionContext,0);\n\t};\n\n\tEOF() {\n\t    return this.getToken(JSONFormulaParser.EOF, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterFormula(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitFormula(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass ExpressionContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_expression;\n    }\n\n\n\t \n\t\tcopyFrom(ctx) {\n\t\t\tsuper.copyFrom(ctx);\n\t\t}\n\n}\n\n\nclass BinaryExpressionContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\texpression = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(ExpressionContext);\n\t    } else {\n\t        return this.getTypedRuleContext(ExpressionContext,i);\n\t    }\n\t};\n\n\tbinary_op() {\n\t    return this.getTypedRuleContext(Binary_opContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBinaryExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBinaryExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BinaryExpressionContext = BinaryExpressionContext;\n\nclass JmesPathContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJmesPath(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJmesPath(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.JmesPathContext = JmesPathContext;\n\nclass TopLevelStringContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tRAW_STRING() {\n\t    return this.getToken(JSONFormulaParser.RAW_STRING, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterTopLevelString(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitTopLevelString(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.TopLevelStringContext = TopLevelStringContext;\n\nclass TopLevelIntContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tSIGNED_INT() {\n\t    return this.getToken(JSONFormulaParser.SIGNED_INT, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterTopLevelInt(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitTopLevelInt(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.TopLevelIntContext = TopLevelIntContext;\n\nclass FunctionCallContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tfunction_call() {\n\t    return this.getTypedRuleContext(Function_callContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterFunctionCall(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitFunctionCall(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.FunctionCallContext = FunctionCallContext;\n\nclass BraceExpressionContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\texpression() {\n\t    return this.getTypedRuleContext(ExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBraceExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBraceExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BraceExpressionContext = BraceExpressionContext;\n\nclass PostfixContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\texpression() {\n\t    return this.getTypedRuleContext(ExpressionContext,0);\n\t};\n\n\tpostfix_op() {\n\t    return this.getTypedRuleContext(Postfix_opContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterPostfix(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitPostfix(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.PostfixContext = PostfixContext;\n\nclass UnaryExpressionContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tunary_op() {\n\t    return this.getTypedRuleContext(Unary_opContext,0);\n\t};\n\n\texpression() {\n\t    return this.getTypedRuleContext(ExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterUnaryExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitUnaryExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.UnaryExpressionContext = UnaryExpressionContext;\n\nclass TopLevelNumberContext extends ExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tNUMBER() {\n\t    return this.getToken(JSONFormulaParser.NUMBER, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterTopLevelNumber(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitTopLevelNumber(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.TopLevelNumberContext = TopLevelNumberContext;\n\nclass Unary_opContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_unary_op;\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterUnary_op(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitUnary_op(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass Binary_opContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_binary_op;\n    }\n\n\tCOMPARATOR() {\n\t    return this.getToken(JSONFormulaParser.COMPARATOR, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBinary_op(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBinary_op(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass Postfix_opContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_postfix_op;\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterPostfix_op(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitPostfix_op(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass Function_callContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_function_call;\n    }\n\n\tFUNCTIONS() {\n\t    return this.getToken(JSONFormulaParser.FUNCTIONS, 0);\n\t};\n\n\texpression_list() {\n\t    return this.getTypedRuleContext(Expression_listContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterFunction_call(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitFunction_call(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass ParameterContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_parameter;\n    }\n\n\texpression() {\n\t    return this.getTypedRuleContext(ExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterParameter(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitParameter(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass Nonempty_expr_listContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_nonempty_expr_list;\n    }\n\n\tparameter() {\n\t    return this.getTypedRuleContext(ParameterContext,0);\n\t};\n\n\tnonempty_expr_list() {\n\t    return this.getTypedRuleContext(Nonempty_expr_listContext,0);\n\t};\n\n\tparm_separator() {\n\t    return this.getTypedRuleContext(Parm_separatorContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterNonempty_expr_list(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitNonempty_expr_list(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass Expression_listContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_expression_list;\n    }\n\n\tnonempty_expr_list() {\n\t    return this.getTypedRuleContext(Nonempty_expr_listContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterExpression_list(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitExpression_list(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass Parm_separatorContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_parm_separator;\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterParm_separator(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitParm_separator(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass JmesPathExpressionContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_jmesPathExpression;\n    }\n\n\n\t \n\t\tcopyFrom(ctx) {\n\t\t\tsuper.copyFrom(ctx);\n\t\t}\n\n}\n\n\nclass PipeExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JmesPathExpressionContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JmesPathExpressionContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterPipeExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitPipeExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.PipeExpressionContext = PipeExpressionContext;\n\nclass IdentifierExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tidentifier() {\n\t    return this.getTypedRuleContext(IdentifierContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterIdentifierExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitIdentifierExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.IdentifierExpressionContext = IdentifierExpressionContext;\n\nclass NotExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterNotExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitNotExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.NotExpressionContext = NotExpressionContext;\n\nclass RawStringExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tRAW_STRING() {\n\t    return this.getToken(JSONFormulaParser.RAW_STRING, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterRawStringExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitRawStringExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.RawStringExpressionContext = RawStringExpressionContext;\n\nclass ComparisonExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JmesPathExpressionContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JmesPathExpressionContext,i);\n\t    }\n\t};\n\n\tCOMPARATOR() {\n\t    return this.getToken(JSONFormulaParser.COMPARATOR, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterComparisonExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitComparisonExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ComparisonExpressionContext = ComparisonExpressionContext;\n\nclass ParenExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterParenExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitParenExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ParenExpressionContext = ParenExpressionContext;\n\nclass BracketExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tbracketSpecifier() {\n\t    return this.getTypedRuleContext(BracketSpecifierContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBracketExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBracketExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BracketExpressionContext = BracketExpressionContext;\n\nclass OrExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JmesPathExpressionContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JmesPathExpressionContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterOrExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitOrExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.OrExpressionContext = OrExpressionContext;\n\nclass CurrentNodeExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tcurrentNode() {\n\t    return this.getTypedRuleContext(CurrentNodeContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterCurrentNodeExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitCurrentNodeExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.CurrentNodeExpressionContext = CurrentNodeExpressionContext;\n\nclass ChainExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tchainedExpression() {\n\t    return this.getTypedRuleContext(ChainedExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterChainExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitChainExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ChainExpressionContext = ChainExpressionContext;\n\nclass AndExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JmesPathExpressionContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JmesPathExpressionContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterAndExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitAndExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.AndExpressionContext = AndExpressionContext;\n\nclass MultiSelectHashExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tmultiSelectHash() {\n\t    return this.getTypedRuleContext(MultiSelectHashContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterMultiSelectHashExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitMultiSelectHashExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.MultiSelectHashExpressionContext = MultiSelectHashExpressionContext;\n\nclass WildcardExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\twildcard() {\n\t    return this.getTypedRuleContext(WildcardContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterWildcardExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitWildcardExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.WildcardExpressionContext = WildcardExpressionContext;\n\nclass FunctionCallExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tfunctionExpression() {\n\t    return this.getTypedRuleContext(FunctionExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterFunctionCallExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitFunctionCallExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.FunctionCallExpressionContext = FunctionCallExpressionContext;\n\nclass MultiSelectListExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tmultiSelectList() {\n\t    return this.getTypedRuleContext(MultiSelectListContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterMultiSelectListExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitMultiSelectListExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.MultiSelectListExpressionContext = MultiSelectListExpressionContext;\n\nclass BracketedExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tbracketSpecifier() {\n\t    return this.getTypedRuleContext(BracketSpecifierContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBracketedExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBracketedExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BracketedExpressionContext = BracketedExpressionContext;\n\nclass LiteralExpressionContext extends JmesPathExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tliteral() {\n\t    return this.getTypedRuleContext(LiteralContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterLiteralExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitLiteralExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.LiteralExpressionContext = LiteralExpressionContext;\n\nclass ChainedExpressionContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_chainedExpression;\n    }\n\n\n\t \n\t\tcopyFrom(ctx) {\n\t\t\tsuper.copyFrom(ctx);\n\t\t}\n\n}\n\n\nclass ChainedMultiSelectListContext extends ChainedExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tmultiSelectList() {\n\t    return this.getTypedRuleContext(MultiSelectListContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterChainedMultiSelectList(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitChainedMultiSelectList(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ChainedMultiSelectListContext = ChainedMultiSelectListContext;\n\nclass ChainedWildcardContext extends ChainedExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\twildcard() {\n\t    return this.getTypedRuleContext(WildcardContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterChainedWildcard(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitChainedWildcard(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ChainedWildcardContext = ChainedWildcardContext;\n\nclass ChainedMultiSelectHashContext extends ChainedExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tmultiSelectHash() {\n\t    return this.getTypedRuleContext(MultiSelectHashContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterChainedMultiSelectHash(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitChainedMultiSelectHash(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ChainedMultiSelectHashContext = ChainedMultiSelectHashContext;\n\nclass ChainedIdentifierContext extends ChainedExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tidentifier() {\n\t    return this.getTypedRuleContext(IdentifierContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterChainedIdentifier(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitChainedIdentifier(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ChainedIdentifierContext = ChainedIdentifierContext;\n\nclass ChainedFunctionExpressionContext extends ChainedExpressionContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tfunctionExpression() {\n\t    return this.getTypedRuleContext(FunctionExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterChainedFunctionExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitChainedFunctionExpression(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.ChainedFunctionExpressionContext = ChainedFunctionExpressionContext;\n\nclass WildcardContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_wildcard;\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterWildcard(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitWildcard(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass MultiSelectListContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_multiSelectList;\n    }\n\n\tjmesPathExpression = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JmesPathExpressionContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JmesPathExpressionContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterMultiSelectList(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitMultiSelectList(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass MultiSelectHashContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_multiSelectHash;\n    }\n\n\tkeyvalExpr = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(KeyvalExprContext);\n\t    } else {\n\t        return this.getTypedRuleContext(KeyvalExprContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterMultiSelectHash(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitMultiSelectHash(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass KeyvalExprContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_keyvalExpr;\n    }\n\n\tidentifier() {\n\t    return this.getTypedRuleContext(IdentifierContext,0);\n\t};\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterKeyvalExpr(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitKeyvalExpr(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass BracketSpecifierContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_bracketSpecifier;\n    }\n\n\n\t \n\t\tcopyFrom(ctx) {\n\t\t\tsuper.copyFrom(ctx);\n\t\t}\n\n}\n\n\nclass SelectContext extends BracketSpecifierContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterSelect(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitSelect(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.SelectContext = SelectContext;\n\nclass BracketFlattenContext extends BracketSpecifierContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBracketFlatten(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBracketFlatten(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BracketFlattenContext = BracketFlattenContext;\n\nclass BracketSliceContext extends BracketSpecifierContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tslice() {\n\t    return this.getTypedRuleContext(SliceContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBracketSlice(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBracketSlice(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BracketSliceContext = BracketSliceContext;\n\nclass BracketIndexContext extends BracketSpecifierContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tSIGNED_INT() {\n\t    return this.getToken(JSONFormulaParser.SIGNED_INT, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBracketIndex(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBracketIndex(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BracketIndexContext = BracketIndexContext;\n\nclass BracketStarContext extends BracketSpecifierContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterBracketStar(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitBracketStar(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.BracketStarContext = BracketStarContext;\n\nclass SliceContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_slice;\n        this.start = null; // Token\n        this.stop = null; // Token\n        this.step = null; // Token\n    }\n\n\tSIGNED_INT = function(i) {\n\t\tif(i===undefined) {\n\t\t\ti = null;\n\t\t}\n\t    if(i===null) {\n\t        return this.getTokens(JSONFormulaParser.SIGNED_INT);\n\t    } else {\n\t        return this.getToken(JSONFormulaParser.SIGNED_INT, i);\n\t    }\n\t};\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterSlice(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitSlice(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass FunctionExpressionContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_functionExpression;\n    }\n\n\tNAME() {\n\t    return this.getToken(JSONFormulaParser.NAME, 0);\n\t};\n\n\tfunctionArg = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(FunctionArgContext);\n\t    } else {\n\t        return this.getTypedRuleContext(FunctionArgContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterFunctionExpression(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitFunctionExpression(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass FunctionArgContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_functionArg;\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\texpressionType() {\n\t    return this.getTypedRuleContext(ExpressionTypeContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterFunctionArg(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitFunctionArg(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass CurrentNodeContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_currentNode;\n    }\n\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterCurrentNode(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitCurrentNode(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass ExpressionTypeContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_expressionType;\n    }\n\n\tjmesPathExpression() {\n\t    return this.getTypedRuleContext(JmesPathExpressionContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterExpressionType(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitExpressionType(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass LiteralContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_literal;\n    }\n\n\tjsonValue() {\n\t    return this.getTypedRuleContext(JsonValueContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterLiteral(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitLiteral(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass IdentifierContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_identifier;\n    }\n\n\tNAME() {\n\t    return this.getToken(JSONFormulaParser.NAME, 0);\n\t};\n\n\tSTRING() {\n\t    return this.getToken(JSONFormulaParser.STRING, 0);\n\t};\n\n\tJSON_CONSTANT() {\n\t    return this.getToken(JSONFormulaParser.JSON_CONSTANT, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterIdentifier(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitIdentifier(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass JsonObjectContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_jsonObject;\n    }\n\n\tjsonObjectPair = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JsonObjectPairContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JsonObjectPairContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonObject(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonObject(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass JsonObjectPairContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_jsonObjectPair;\n    }\n\n\tSTRING() {\n\t    return this.getToken(JSONFormulaParser.STRING, 0);\n\t};\n\n\tjsonValue() {\n\t    return this.getTypedRuleContext(JsonValueContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonObjectPair(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonObjectPair(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass JsonArrayContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_jsonArray;\n    }\n\n\tjsonValue = function(i) {\n\t    if(i===undefined) {\n\t        i = null;\n\t    }\n\t    if(i===null) {\n\t        return this.getTypedRuleContexts(JsonValueContext);\n\t    } else {\n\t        return this.getTypedRuleContext(JsonValueContext,i);\n\t    }\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonArray(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonArray(this);\n\t\t}\n\t}\n\n\n}\n\n\n\nclass JsonValueContext extends antlr4.ParserRuleContext {\n\n    constructor(parser, parent, invokingState) {\n        if(parent===undefined) {\n            parent = null;\n        }\n        if(invokingState===undefined || invokingState===null) {\n            invokingState = -1;\n        }\n        super(parent, invokingState);\n        this.parser = parser;\n        this.ruleIndex = JSONFormulaParser.RULE_jsonValue;\n    }\n\n\n\t \n\t\tcopyFrom(ctx) {\n\t\t\tsuper.copyFrom(ctx);\n\t\t}\n\n}\n\n\nclass JsonArrayValueContext extends JsonValueContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjsonArray() {\n\t    return this.getTypedRuleContext(JsonArrayContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonArrayValue(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonArrayValue(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.JsonArrayValueContext = JsonArrayValueContext;\n\nclass JsonStringValueContext extends JsonValueContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tSTRING() {\n\t    return this.getToken(JSONFormulaParser.STRING, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonStringValue(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonStringValue(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.JsonStringValueContext = JsonStringValueContext;\n\nclass JsonObjectValueContext extends JsonValueContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tjsonObject() {\n\t    return this.getTypedRuleContext(JsonObjectContext,0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonObjectValue(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonObjectValue(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.JsonObjectValueContext = JsonObjectValueContext;\n\nclass JsonConstantValueContext extends JsonValueContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tJSON_CONSTANT() {\n\t    return this.getToken(JSONFormulaParser.JSON_CONSTANT, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonConstantValue(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonConstantValue(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.JsonConstantValueContext = JsonConstantValueContext;\n\nclass JsonNumberValueContext extends JsonValueContext {\n\n    constructor(parser, ctx) {\n        super(parser);\n        super.copyFrom(ctx);\n    }\n\n\tREAL_OR_EXPONENT_NUMBER() {\n\t    return this.getToken(JSONFormulaParser.REAL_OR_EXPONENT_NUMBER, 0);\n\t};\n\n\tSIGNED_INT() {\n\t    return this.getToken(JSONFormulaParser.SIGNED_INT, 0);\n\t};\n\n\tenterRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.enterJsonNumberValue(this);\n\t\t}\n\t}\n\n\texitRule(listener) {\n\t    if(listener instanceof JSONFormulaListener ) {\n\t        listener.exitJsonNumberValue(this);\n\t\t}\n\t}\n\n\n}\n\nJSONFormulaParser.JsonNumberValueContext = JsonNumberValueContext;\n\n\nJSONFormulaParser.FormulaContext = FormulaContext; \nJSONFormulaParser.ExpressionContext = ExpressionContext; \nJSONFormulaParser.Unary_opContext = Unary_opContext; \nJSONFormulaParser.Binary_opContext = Binary_opContext; \nJSONFormulaParser.Postfix_opContext = Postfix_opContext; \nJSONFormulaParser.Function_callContext = Function_callContext; \nJSONFormulaParser.ParameterContext = ParameterContext; \nJSONFormulaParser.Nonempty_expr_listContext = Nonempty_expr_listContext; \nJSONFormulaParser.Expression_listContext = Expression_listContext; \nJSONFormulaParser.Parm_separatorContext = Parm_separatorContext; \nJSONFormulaParser.JmesPathExpressionContext = JmesPathExpressionContext; \nJSONFormulaParser.ChainedExpressionContext = ChainedExpressionContext; \nJSONFormulaParser.WildcardContext = WildcardContext; \nJSONFormulaParser.MultiSelectListContext = MultiSelectListContext; \nJSONFormulaParser.MultiSelectHashContext = MultiSelectHashContext; \nJSONFormulaParser.KeyvalExprContext = KeyvalExprContext; \nJSONFormulaParser.BracketSpecifierContext = BracketSpecifierContext; \nJSONFormulaParser.SliceContext = SliceContext; \nJSONFormulaParser.FunctionExpressionContext = FunctionExpressionContext; \nJSONFormulaParser.FunctionArgContext = FunctionArgContext; \nJSONFormulaParser.CurrentNodeContext = CurrentNodeContext; \nJSONFormulaParser.ExpressionTypeContext = ExpressionTypeContext; \nJSONFormulaParser.LiteralContext = LiteralContext; \nJSONFormulaParser.IdentifierContext = IdentifierContext; \nJSONFormulaParser.JsonObjectContext = JsonObjectContext; \nJSONFormulaParser.JsonObjectPairContext = JsonObjectPairContext; \nJSONFormulaParser.JsonArrayContext = JsonArrayContext; \nJSONFormulaParser.JsonValueContext = JsonValueContext; \n","// Generated from antlr/JSONFormula.g4 by ANTLR 4.9.2\n// jshint ignore: start\nimport antlr4 from 'antlr4';\n\n\n\nconst serializedATN = [\"\\u0003\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\",\n    \"\\u5964\\u0002$\\u0115\\b\\u0001\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\",\n    \"\\u0004\\u0004\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\",\n    \"\\t\\u0007\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\",\n    \"\\f\\t\\f\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f\\u0004\\u0010\",\n    \"\\t\\u0010\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013\\t\\u0013\",\n    \"\\u0004\\u0014\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016\\u0004\\u0017\",\n    \"\\t\\u0017\\u0004\\u0018\\t\\u0018\\u0004\\u0019\\t\\u0019\\u0004\\u001a\\t\\u001a\",\n    \"\\u0004\\u001b\\t\\u001b\\u0004\\u001c\\t\\u001c\\u0004\\u001d\\t\\u001d\\u0004\\u001e\",\n    \"\\t\\u001e\\u0004\\u001f\\t\\u001f\\u0004 \\t \\u0004!\\t!\\u0004\\\"\\t\\\"\\u0004#\",\n    \"\\t#\\u0004$\\t$\\u0004%\\t%\\u0004&\\t&\\u0004\\'\\t\\'\\u0004(\\t(\\u0004)\\t)\\u0004\",\n    \"*\\t*\\u0003\\u0002\\u0003\\u0002\\u0003\\u0003\\u0003\\u0003\\u0003\\u0004\\u0003\",\n    \"\\u0004\\u0003\\u0005\\u0003\\u0005\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\",\n    \"\\u0007\\u0003\\u0007\\u0003\\b\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\\n\\u0003\\n\\u0003\",\n    \"\\u000b\\u0003\\u000b\\u0003\\f\\u0003\\f\\u0003\\r\\u0003\\r\\u0003\\u000e\\u0003\",\n    \"\\u000e\\u0003\\u000e\\u0003\\u000f\\u0003\\u000f\\u0003\\u000f\\u0003\\u0010\\u0003\",\n    \"\\u0010\\u0003\\u0011\\u0003\\u0011\\u0003\\u0012\\u0003\\u0012\\u0003\\u0013\\u0003\",\n    \"\\u0013\\u0003\\u0014\\u0003\\u0014\\u0003\\u0015\\u0003\\u0015\\u0003\\u0016\\u0003\",\n    \"\\u0016\\u0003\\u0017\\u0003\\u0017\\u0003\\u0017\\u0003\\u0018\\u0003\\u0018\\u0003\",\n    \"\\u0019\\u0003\\u0019\\u0003\\u001a\\u0005\\u001a\\u008b\\n\\u001a\\u0003\\u001a\",\n    \"\\u0003\\u001a\\u0003\\u001b\\u0003\\u001b\\u0005\\u001b\\u0091\\n\\u001b\\u0003\",\n    \"\\u001b\\u0007\\u001b\\u0094\\n\\u001b\\f\\u001b\\u000e\\u001b\\u0097\\u000b\\u001b\",\n    \"\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\",\n    \"\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0005\\u001c\\u00a2\\n\\u001c\\u0003\",\n    \"\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0005\",\n    \"\\u001d\\u00aa\\n\\u001d\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\",\n    \"\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\",\n    \"\\u0005\\u001e\\u00b6\\n\\u001e\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0007\",\n    \"\\u001f\\u00bb\\n\\u001f\\f\\u001f\\u000e\\u001f\\u00be\\u000b\\u001f\\u0003\\u001f\",\n    \"\\u0003\\u001f\\u0003 \\u0003 \\u0003 \\u0003!\\u0003!\\u0003!\\u0003!\\u0003\",\n    \"!\\u0005!\\u00ca\\n!\\u0003\\\"\\u0003\\\"\\u0007\\\"\\u00ce\\n\\\"\\f\\\"\\u000e\\\"\\u00d1\",\n    \"\\u000b\\\"\\u0003#\\u0003#\\u0003#\\u0007#\\u00d6\\n#\\f#\\u000e#\\u00d9\\u000b\",\n    \"#\\u0003#\\u0003#\\u0003$\\u0003$\\u0003$\\u0005$\\u00e0\\n$\\u0003%\\u0003%\\u0003\",\n    \"%\\u0003%\\u0003%\\u0003%\\u0003&\\u0003&\\u0003\\'\\u0005\\'\\u00eb\\n\\'\\u0003\",\n    \"\\'\\u0003\\'\\u0003\\'\\u0006\\'\\u00f0\\n\\'\\r\\'\\u000e\\'\\u00f1\\u0003\\'\\u0005\",\n    \"\\'\\u00f5\\n\\'\\u0003\\'\\u0005\\'\\u00f8\\n\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0005\",\n    \"\\'\\u00fd\\n\\'\\u0003(\\u0003(\\u0003(\\u0007(\\u0102\\n(\\f(\\u000e(\\u0105\\u000b\",\n    \"(\\u0005(\\u0107\\n(\\u0003)\\u0003)\\u0005)\\u010b\\n)\\u0003)\\u0003)\\u0003\",\n    \"*\\u0006*\\u0110\\n*\\r*\\u000e*\\u0111\\u0003*\\u0003*\\u0002\\u0002+\\u0003\\u0003\",\n    \"\\u0005\\u0004\\u0007\\u0005\\t\\u0006\\u000b\\u0007\\r\\b\\u000f\\t\\u0011\\n\\u0013\",\n    \"\\u000b\\u0015\\f\\u0017\\r\\u0019\\u000e\\u001b\\u000f\\u001d\\u0010\\u001f\\u0011\",\n    \"!\\u0012#\\u0013%\\u0014\\'\\u0015)\\u0016+\\u0017-\\u0018/\\u00191\\u001a3\\u001b\",\n    \"5\\u001c7\\u00029\\u001d;\\u001e=\\u001f?\\u0002A C!E\\\"G\\u0002I\\u0002K\\u0002\",\n    \"M#O\\u0002Q\\u0002S$\\u0003\\u0002\\r\\u0003\\u00022;\\u0004\\u0002))^^\\u0005\",\n    \"\\u0002C\\\\aac|\\u0006\\u00022;C\\\\aac|\\u0004\\u0002$$^^\\u000b\\u0002$$11^\",\n    \"^bbddhhppttvv\\u0005\\u00022;CHch\\u0003\\u00023;\\u0004\\u0002GGgg\\u0004\",\n    \"\\u0002--//\\u0005\\u0002\\u000b\\f\\u000f\\u000f\\\"\\\"\\u0002\\u0128\\u0002\\u0003\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\u0005\\u0003\\u0002\\u0002\\u0002\\u0002\\u0007\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\t\\u0003\\u0002\\u0002\\u0002\\u0002\\u000b\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\r\\u0003\\u0002\\u0002\\u0002\\u0002\\u000f\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\u0011\\u0003\\u0002\\u0002\\u0002\\u0002\\u0013\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\u0015\\u0003\\u0002\\u0002\\u0002\\u0002\\u0017\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\u0019\\u0003\\u0002\\u0002\\u0002\\u0002\\u001b\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002\\u001d\\u0003\\u0002\\u0002\\u0002\\u0002\\u001f\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u0002!\\u0003\\u0002\\u0002\\u0002\\u0002#\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0002%\\u0003\\u0002\\u0002\\u0002\\u0002\\'\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u0002)\\u0003\\u0002\\u0002\\u0002\\u0002+\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002-\\u0003\\u0002\\u0002\\u0002\\u0002/\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00021\\u0003\\u0002\\u0002\\u0002\\u00023\\u0003\\u0002\\u0002\\u0002\\u0002\",\n    \"5\\u0003\\u0002\\u0002\\u0002\\u00029\\u0003\\u0002\\u0002\\u0002\\u0002;\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0002=\\u0003\\u0002\\u0002\\u0002\\u0002A\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u0002C\\u0003\\u0002\\u0002\\u0002\\u0002E\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002M\\u0003\\u0002\\u0002\\u0002\\u0002S\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0003U\\u0003\\u0002\\u0002\\u0002\\u0005W\\u0003\\u0002\\u0002\\u0002\\u0007\",\n    \"Y\\u0003\\u0002\\u0002\\u0002\\t[\\u0003\\u0002\\u0002\\u0002\\u000b]\\u0003\\u0002\",\n    \"\\u0002\\u0002\\r`\\u0003\\u0002\\u0002\\u0002\\u000fb\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0011d\\u0003\\u0002\\u0002\\u0002\\u0013f\\u0003\\u0002\\u0002\\u0002\\u0015\",\n    \"h\\u0003\\u0002\\u0002\\u0002\\u0017j\\u0003\\u0002\\u0002\\u0002\\u0019l\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u001bn\\u0003\\u0002\\u0002\\u0002\\u001dq\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u001ft\\u0003\\u0002\\u0002\\u0002!v\\u0003\\u0002\\u0002\\u0002\",\n    \"#x\\u0003\\u0002\\u0002\\u0002%z\\u0003\\u0002\\u0002\\u0002\\'|\\u0003\\u0002\",\n    \"\\u0002\\u0002)~\\u0003\\u0002\\u0002\\u0002+\\u0080\\u0003\\u0002\\u0002\\u0002\",\n    \"-\\u0082\\u0003\\u0002\\u0002\\u0002/\\u0085\\u0003\\u0002\\u0002\\u00021\\u0087\",\n    \"\\u0003\\u0002\\u0002\\u00023\\u008a\\u0003\\u0002\\u0002\\u00025\\u008e\\u0003\",\n    \"\\u0002\\u0002\\u00027\\u00a1\\u0003\\u0002\\u0002\\u00029\\u00a9\\u0003\\u0002\",\n    \"\\u0002\\u0002;\\u00b5\\u0003\\u0002\\u0002\\u0002=\\u00b7\\u0003\\u0002\\u0002\",\n    \"\\u0002?\\u00c1\\u0003\\u0002\\u0002\\u0002A\\u00c9\\u0003\\u0002\\u0002\\u0002\",\n    \"C\\u00cb\\u0003\\u0002\\u0002\\u0002E\\u00d2\\u0003\\u0002\\u0002\\u0002G\\u00dc\",\n    \"\\u0003\\u0002\\u0002\\u0002I\\u00e1\\u0003\\u0002\\u0002\\u0002K\\u00e7\\u0003\",\n    \"\\u0002\\u0002\\u0002M\\u00fc\\u0003\\u0002\\u0002\\u0002O\\u0106\\u0003\\u0002\",\n    \"\\u0002\\u0002Q\\u0108\\u0003\\u0002\\u0002\\u0002S\\u010f\\u0003\\u0002\\u0002\",\n    \"\\u0002UV\\u0007*\\u0002\\u0002V\\u0004\\u0003\\u0002\\u0002\\u0002WX\\u0007+\",\n    \"\\u0002\\u0002X\\u0006\\u0003\\u0002\\u0002\\u0002YZ\\u0007-\\u0002\\u0002Z\\b\",\n    \"\\u0003\\u0002\\u0002\\u0002[\\\\\\u0007/\\u0002\\u0002\\\\\\n\\u0003\\u0002\\u0002\",\n    \"\\u0002]^\\u0007>\\u0002\\u0002^_\\u0007@\\u0002\\u0002_\\f\\u0003\\u0002\\u0002\",\n    \"\\u0002`a\\u0007(\\u0002\\u0002a\\u000e\\u0003\\u0002\\u0002\\u0002bc\\u0007,\",\n    \"\\u0002\\u0002c\\u0010\\u0003\\u0002\\u0002\\u0002de\\u00071\\u0002\\u0002e\\u0012\",\n    \"\\u0003\\u0002\\u0002\\u0002fg\\u0007`\\u0002\\u0002g\\u0014\\u0003\\u0002\\u0002\",\n    \"\\u0002hi\\u0007\\'\\u0002\\u0002i\\u0016\\u0003\\u0002\\u0002\\u0002jk\\u0007\",\n    \".\\u0002\\u0002k\\u0018\\u0003\\u0002\\u0002\\u0002lm\\u00070\\u0002\\u0002m\\u001a\",\n    \"\\u0003\\u0002\\u0002\\u0002no\\u0007(\\u0002\\u0002op\\u0007(\\u0002\\u0002p\",\n    \"\\u001c\\u0003\\u0002\\u0002\\u0002qr\\u0007~\\u0002\\u0002rs\\u0007~\\u0002\\u0002\",\n    \"s\\u001e\\u0003\\u0002\\u0002\\u0002tu\\u0007#\\u0002\\u0002u \\u0003\\u0002\\u0002\",\n    \"\\u0002vw\\u0007~\\u0002\\u0002w\\\"\\u0003\\u0002\\u0002\\u0002xy\\u0007]\\u0002\",\n    \"\\u0002y$\\u0003\\u0002\\u0002\\u0002z{\\u0007_\\u0002\\u0002{&\\u0003\\u0002\",\n    \"\\u0002\\u0002|}\\u0007}\\u0002\\u0002}(\\u0003\\u0002\\u0002\\u0002~\\u007f\\u0007\",\n    \"\\u007f\\u0002\\u0002\\u007f*\\u0003\\u0002\\u0002\\u0002\\u0080\\u0081\\u0007\",\n    \"<\\u0002\\u0002\\u0081,\\u0003\\u0002\\u0002\\u0002\\u0082\\u0083\\u0007]\\u0002\",\n    \"\\u0002\\u0083\\u0084\\u0007A\\u0002\\u0002\\u0084.\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0085\\u0086\\u0007B\\u0002\\u0002\\u00860\\u0003\\u0002\\u0002\\u0002\\u0087\",\n    \"\\u0088\\u0007b\\u0002\\u0002\\u00882\\u0003\\u0002\\u0002\\u0002\\u0089\\u008b\",\n    \"\\u0007/\\u0002\\u0002\\u008a\\u0089\\u0003\\u0002\\u0002\\u0002\\u008a\\u008b\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u008b\\u008c\\u0003\\u0002\\u0002\\u0002\\u008c\\u008d\",\n    \"\\u0005O(\\u0002\\u008d4\\u0003\\u0002\\u0002\\u0002\\u008e\\u0090\\u00053\\u001a\",\n    \"\\u0002\\u008f\\u0091\\u00070\\u0002\\u0002\\u0090\\u008f\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0090\\u0091\\u0003\\u0002\\u0002\\u0002\\u0091\\u0095\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0092\\u0094\\t\\u0002\\u0002\\u0002\\u0093\\u0092\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0094\\u0097\\u0003\\u0002\\u0002\\u0002\\u0095\\u0093\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0095\\u0096\\u0003\\u0002\\u0002\\u0002\\u00966\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0097\\u0095\\u0003\\u0002\\u0002\\u0002\\u0098\\u0099\\u0007v\\u0002\",\n    \"\\u0002\\u0099\\u009a\\u0007t\\u0002\\u0002\\u009a\\u009b\\u0007w\\u0002\\u0002\",\n    \"\\u009b\\u00a2\\u0007g\\u0002\\u0002\\u009c\\u009d\\u0007h\\u0002\\u0002\\u009d\",\n    \"\\u009e\\u0007c\\u0002\\u0002\\u009e\\u009f\\u0007n\\u0002\\u0002\\u009f\\u00a0\",\n    \"\\u0007u\\u0002\\u0002\\u00a0\\u00a2\\u0007g\\u0002\\u0002\\u00a1\\u0098\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00a1\\u009c\\u0003\\u0002\\u0002\\u0002\\u00a28\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00a3\\u00aa\\u00057\\u001c\\u0002\\u00a4\\u00a5\\u0007\",\n    \"u\\u0002\\u0002\\u00a5\\u00a6\\u0007w\\u0002\\u0002\\u00a6\\u00aa\\u0007o\\u0002\",\n    \"\\u0002\\u00a7\\u00a8\\u0007k\\u0002\\u0002\\u00a8\\u00aa\\u0007h\\u0002\\u0002\",\n    \"\\u00a9\\u00a3\\u0003\\u0002\\u0002\\u0002\\u00a9\\u00a4\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00a9\\u00a7\\u0003\\u0002\\u0002\\u0002\\u00aa:\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00ab\\u00b6\\u0007>\\u0002\\u0002\\u00ac\\u00ad\\u0007>\\u0002\\u0002\\u00ad\",\n    \"\\u00b6\\u0007?\\u0002\\u0002\\u00ae\\u00af\\u0007?\\u0002\\u0002\\u00af\\u00b6\",\n    \"\\u0007?\\u0002\\u0002\\u00b0\\u00b1\\u0007@\\u0002\\u0002\\u00b1\\u00b6\\u0007\",\n    \"?\\u0002\\u0002\\u00b2\\u00b6\\u0007@\\u0002\\u0002\\u00b3\\u00b4\\u0007#\\u0002\",\n    \"\\u0002\\u00b4\\u00b6\\u0007?\\u0002\\u0002\\u00b5\\u00ab\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00b5\\u00ac\\u0003\\u0002\\u0002\\u0002\\u00b5\\u00ae\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00b5\\u00b0\\u0003\\u0002\\u0002\\u0002\\u00b5\\u00b2\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00b5\\u00b3\\u0003\\u0002\\u0002\\u0002\\u00b6<\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00b7\\u00bc\\u0007)\\u0002\\u0002\\u00b8\\u00bb\\u0005? \\u0002\\u00b9\",\n    \"\\u00bb\\n\\u0003\\u0002\\u0002\\u00ba\\u00b8\\u0003\\u0002\\u0002\\u0002\\u00ba\",\n    \"\\u00b9\\u0003\\u0002\\u0002\\u0002\\u00bb\\u00be\\u0003\\u0002\\u0002\\u0002\\u00bc\",\n    \"\\u00ba\\u0003\\u0002\\u0002\\u0002\\u00bc\\u00bd\\u0003\\u0002\\u0002\\u0002\\u00bd\",\n    \"\\u00bf\\u0003\\u0002\\u0002\\u0002\\u00be\\u00bc\\u0003\\u0002\\u0002\\u0002\\u00bf\",\n    \"\\u00c0\\u0007)\\u0002\\u0002\\u00c0>\\u0003\\u0002\\u0002\\u0002\\u00c1\\u00c2\",\n    \"\\u0007^\\u0002\\u0002\\u00c2\\u00c3\\u000b\\u0002\\u0002\\u0002\\u00c3@\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00c4\\u00ca\\u00057\\u001c\\u0002\\u00c5\\u00c6\\u0007\",\n    \"p\\u0002\\u0002\\u00c6\\u00c7\\u0007w\\u0002\\u0002\\u00c7\\u00c8\\u0007n\\u0002\",\n    \"\\u0002\\u00c8\\u00ca\\u0007n\\u0002\\u0002\\u00c9\\u00c4\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00c9\\u00c5\\u0003\\u0002\\u0002\\u0002\\u00caB\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00cb\\u00cf\\t\\u0004\\u0002\\u0002\\u00cc\\u00ce\\t\\u0005\\u0002\\u0002\",\n    \"\\u00cd\\u00cc\\u0003\\u0002\\u0002\\u0002\\u00ce\\u00d1\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00cf\\u00cd\\u0003\\u0002\\u0002\\u0002\\u00cf\\u00d0\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00d0D\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00cf\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00d2\\u00d7\\u0007$\\u0002\\u0002\\u00d3\\u00d6\\u0005G$\\u0002\\u00d4\\u00d6\",\n    \"\\n\\u0006\\u0002\\u0002\\u00d5\\u00d3\\u0003\\u0002\\u0002\\u0002\\u00d5\\u00d4\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00d6\\u00d9\\u0003\\u0002\\u0002\\u0002\\u00d7\\u00d5\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00d7\\u00d8\\u0003\\u0002\\u0002\\u0002\\u00d8\\u00da\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00d9\\u00d7\\u0003\\u0002\\u0002\\u0002\\u00da\\u00db\",\n    \"\\u0007$\\u0002\\u0002\\u00dbF\\u0003\\u0002\\u0002\\u0002\\u00dc\\u00df\\u0007\",\n    \"^\\u0002\\u0002\\u00dd\\u00e0\\t\\u0007\\u0002\\u0002\\u00de\\u00e0\\u0005I%\\u0002\",\n    \"\\u00df\\u00dd\\u0003\\u0002\\u0002\\u0002\\u00df\\u00de\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u00e0H\\u0003\\u0002\\u0002\\u0002\\u00e1\\u00e2\\u0007w\\u0002\\u0002\\u00e2\",\n    \"\\u00e3\\u0005K&\\u0002\\u00e3\\u00e4\\u0005K&\\u0002\\u00e4\\u00e5\\u0005K&\\u0002\",\n    \"\\u00e5\\u00e6\\u0005K&\\u0002\\u00e6J\\u0003\\u0002\\u0002\\u0002\\u00e7\\u00e8\",\n    \"\\t\\b\\u0002\\u0002\\u00e8L\\u0003\\u0002\\u0002\\u0002\\u00e9\\u00eb\\u0007/\\u0002\",\n    \"\\u0002\\u00ea\\u00e9\\u0003\\u0002\\u0002\\u0002\\u00ea\\u00eb\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00eb\\u00ec\\u0003\\u0002\\u0002\\u0002\\u00ec\\u00ed\\u0005O(\\u0002\",\n    \"\\u00ed\\u00ef\\u00070\\u0002\\u0002\\u00ee\\u00f0\\t\\u0002\\u0002\\u0002\\u00ef\",\n    \"\\u00ee\\u0003\\u0002\\u0002\\u0002\\u00f0\\u00f1\\u0003\\u0002\\u0002\\u0002\\u00f1\",\n    \"\\u00ef\\u0003\\u0002\\u0002\\u0002\\u00f1\\u00f2\\u0003\\u0002\\u0002\\u0002\\u00f2\",\n    \"\\u00f4\\u0003\\u0002\\u0002\\u0002\\u00f3\\u00f5\\u0005Q)\\u0002\\u00f4\\u00f3\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00f4\\u00f5\\u0003\\u0002\\u0002\\u0002\\u00f5\\u00fd\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00f6\\u00f8\\u0007/\\u0002\\u0002\\u00f7\\u00f6\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00f7\\u00f8\\u0003\\u0002\\u0002\\u0002\\u00f8\\u00f9\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00f9\\u00fa\\u0005O(\\u0002\\u00fa\\u00fb\\u0005\",\n    \"Q)\\u0002\\u00fb\\u00fd\\u0003\\u0002\\u0002\\u0002\\u00fc\\u00ea\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00fc\\u00f7\\u0003\\u0002\\u0002\\u0002\\u00fdN\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00fe\\u0107\\u00072\\u0002\\u0002\\u00ff\\u0103\\t\\t\\u0002\\u0002\",\n    \"\\u0100\\u0102\\t\\u0002\\u0002\\u0002\\u0101\\u0100\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0102\\u0105\\u0003\\u0002\\u0002\\u0002\\u0103\\u0101\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0103\\u0104\\u0003\\u0002\\u0002\\u0002\\u0104\\u0107\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0105\\u0103\\u0003\\u0002\\u0002\\u0002\\u0106\\u00fe\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0106\\u00ff\\u0003\\u0002\\u0002\\u0002\\u0107P\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0108\\u010a\\t\\n\\u0002\\u0002\\u0109\\u010b\\t\\u000b\\u0002\\u0002\\u010a\\u0109\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u010a\\u010b\\u0003\\u0002\\u0002\\u0002\\u010b\\u010c\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u010c\\u010d\\u0005O(\\u0002\\u010dR\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u010e\\u0110\\t\\f\\u0002\\u0002\\u010f\\u010e\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0110\\u0111\\u0003\\u0002\\u0002\\u0002\\u0111\\u010f\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0111\\u0112\\u0003\\u0002\\u0002\\u0002\\u0112\\u0113\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0113\\u0114\\b*\\u0002\\u0002\\u0114T\\u0003\\u0002\\u0002\\u0002\\u0019\",\n    \"\\u0002\\u008a\\u0090\\u0095\\u00a1\\u00a9\\u00b5\\u00ba\\u00bc\\u00c9\\u00cf\\u00d5\",\n    \"\\u00d7\\u00df\\u00ea\\u00f1\\u00f4\\u00f7\\u00fc\\u0103\\u0106\\u010a\\u0111\\u0003\",\n    \"\\b\\u0002\\u0002\"].join(\"\");\n\n\nconst atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\n\nconst decisionsToDFA = atn.decisionToState.map( (ds, index) => new antlr4.dfa.DFA(ds, index) );\n\nexport default class JSONFormulaLexer extends antlr4.Lexer {\n\n    static grammarFileName = \"JSONFormula.g4\";\n    static channelNames = [ \"DEFAULT_TOKEN_CHANNEL\", \"HIDDEN\" ];\n\tstatic modeNames = [ \"DEFAULT_MODE\" ];\n\tstatic literalNames = [ null, \"'('\", \"')'\", \"'+'\", \"'-'\", \"'<>'\", \"'&'\", \n                         \"'*'\", \"'/'\", \"'^'\", \"'%'\", \"','\", \"'.'\", \"'&&'\", \n                         \"'||'\", \"'!'\", \"'|'\", \"'['\", \"']'\", \"'{'\", \"'}'\", \n                         \"':'\", \"'[?'\", \"'@'\", \"'`'\" ];\n\tstatic symbolicNames = [ null, null, null, null, null, null, null, null, \n                          null, null, null, null, null, null, null, null, \n                          null, null, null, null, null, null, null, null, \n                          null, \"SIGNED_INT\", \"NUMBER\", \"FUNCTIONS\", \"COMPARATOR\", \n                          \"RAW_STRING\", \"JSON_CONSTANT\", \"NAME\", \"STRING\", \n                          \"REAL_OR_EXPONENT_NUMBER\", \"WS\" ];\n\tstatic ruleNames = [ \"T__0\", \"T__1\", \"T__2\", \"T__3\", \"T__4\", \"T__5\", \"T__6\", \n                      \"T__7\", \"T__8\", \"T__9\", \"T__10\", \"T__11\", \"T__12\", \n                      \"T__13\", \"T__14\", \"T__15\", \"T__16\", \"T__17\", \"T__18\", \n                      \"T__19\", \"T__20\", \"T__21\", \"T__22\", \"T__23\", \"SIGNED_INT\", \n                      \"NUMBER\", \"BOOLEANS\", \"FUNCTIONS\", \"COMPARATOR\", \"RAW_STRING\", \n                      \"RAW_ESC\", \"JSON_CONSTANT\", \"NAME\", \"STRING\", \"ESC\", \n                      \"UNICODE\", \"HEX\", \"REAL_OR_EXPONENT_NUMBER\", \"INT\", \n                      \"EXP\", \"WS\" ];\n\n    constructor(input) {\n        super(input)\n        this._interp = new antlr4.atn.LexerATNSimulator(this, atn, decisionsToDFA, new antlr4.PredictionContextCache());\n    }\n\n    get atn() {\n        return atn;\n    }\n}\n\nJSONFormulaLexer.EOF = antlr4.Token.EOF;\nJSONFormulaLexer.T__0 = 1;\nJSONFormulaLexer.T__1 = 2;\nJSONFormulaLexer.T__2 = 3;\nJSONFormulaLexer.T__3 = 4;\nJSONFormulaLexer.T__4 = 5;\nJSONFormulaLexer.T__5 = 6;\nJSONFormulaLexer.T__6 = 7;\nJSONFormulaLexer.T__7 = 8;\nJSONFormulaLexer.T__8 = 9;\nJSONFormulaLexer.T__9 = 10;\nJSONFormulaLexer.T__10 = 11;\nJSONFormulaLexer.T__11 = 12;\nJSONFormulaLexer.T__12 = 13;\nJSONFormulaLexer.T__13 = 14;\nJSONFormulaLexer.T__14 = 15;\nJSONFormulaLexer.T__15 = 16;\nJSONFormulaLexer.T__16 = 17;\nJSONFormulaLexer.T__17 = 18;\nJSONFormulaLexer.T__18 = 19;\nJSONFormulaLexer.T__19 = 20;\nJSONFormulaLexer.T__20 = 21;\nJSONFormulaLexer.T__21 = 22;\nJSONFormulaLexer.T__22 = 23;\nJSONFormulaLexer.T__23 = 24;\nJSONFormulaLexer.SIGNED_INT = 25;\nJSONFormulaLexer.NUMBER = 26;\nJSONFormulaLexer.FUNCTIONS = 27;\nJSONFormulaLexer.COMPARATOR = 28;\nJSONFormulaLexer.RAW_STRING = 29;\nJSONFormulaLexer.JSON_CONSTANT = 30;\nJSONFormulaLexer.NAME = 31;\nJSONFormulaLexer.STRING = 32;\nJSONFormulaLexer.REAL_OR_EXPONENT_NUMBER = 33;\nJSONFormulaLexer.WS = 34;\n\n\n\n","/*\nCopyright 2021 Adobe. All rights reserved.\nThis file is licensed to you under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License. You may obtain a copy\nof the License at http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under\nthe License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR REPRESENTATIONS\nOF ANY KIND, either express or implied. See the License for the specific language\ngoverning permissions and limitations under the License.\n*/\nimport JSONFormulaListener from \"./antlr/JSONFormulaListener.js\";\nimport jmespath from \"jmespath\";\n\nexport default class Listener extends JSONFormulaListener {\n\tconstructor(data, traceOn) {\n\t\tsuper();\n\t\tthis.stack = [];\n\t\tthis.data = data;\n\t\tthis.traceOn = traceOn;\n\t}\n\ttrace(msg) {\n\t\tif (this.traceOn) console.log(msg);\n\t}\n\n\t// Enter a parse tree produced by JSONFormulaParser#formula.\n\tenterFormula(ctx) {\n\t\tthis.trace(`enterFormula: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#formula.\n\texitFormula(ctx) {\n\t\tthis.trace(`exitFormula: ${ctx.getText()}`);\n\t\tthis.result = this.stack.pop();\n\t\tthis.trace(`\\n\\nRESULT: ${this.result}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#binaryExpression.\n\texitBinaryExpression(ctx) {\n\t\tthis.trace(`exitBinaryExpression: ${ctx.getText()}`);\n\t\tconst op1 = this.stack.pop();\n\t\tconst op = this.stack.pop();\n\t\tconst op2 = this.stack.pop();\n\t\tif (op === \"*\") {\n\t\t\tthis.stack.push(op2 * op1);\n\t\t} else if (op === \"/\") {\n\t\t\tthis.stack.push(op2 / op1);\n\t\t} else if (op === \"-\") {\n\t\t\tthis.stack.push(op2 - op1);\n\t\t} else if (op === \"+\") {\n\t\t\tthis.stack.push(op2 + op1);\n\t\t}\telse if (op === \"<\") {\n\t\t\tthis.stack.push(op2 < op1);\n\t\t} else if (op === \">\") {\n\t\t\tthis.stack.push(op2 > op1);\n\t\t} else if (op === \"<=\") {\n\t\t\tthis.stack.push(op2 <= op1);\n\t\t} else if (op === \">=\") {\n\t\t\tthis.stack.push(op2 >= op1);\n\t\t} else if (op === \"==\") {\n\t\t\tthis.stack.push(op2 == op1);\n    } else if (op === \"!=\" || op === \"<>\") {\n\t\t\tthis.stack.push(op2 != op1);\n    } else if (op === \"&\") {\n\t\t\tthis.stack.push(op2.toString() + op1.toString());\n    } else if (op === \"^\") {\n\t\t\tthis.stack.push(Math.pow(op2, op1));\n    }\n\t}\n\n\t// Enter a parse tree produced by JSONFormulaParser#jmesPath.\n\tenterJmesPath(ctx) {\n\t\tthis.trace(`enterJmesPath: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#jmesPath.\n\texitJmesPath(ctx) {\n\t\tthis.trace(`exitJmesPath ${ctx.getText()}`);\n\t\tconst expr = ctx.getText();\n\t\tconst x = jmespath.search(this.data, expr);\n\t\tthis.trace(x);\n\t\tthis.stack.push(x);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#topLevelString.\n\texitTopLevelString(ctx) {\n\t\tthis.trace(`exitTopLevelString: ${ctx.getText()}`);\n\t\tconst str = ctx.getText().replace(/([^\\\\]|^)'/g, \"$1\").replace(/'$/, \"\").replace(/\\\\'/g, \"'\");\n\t\tthis.stack.push(str);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#functionCall.\n\texitFunctionCall(ctx) {\n\t\tthis.trace(`exitFunctionCall: ${ctx.getText()}`);\n\t\tconst func = ctx.start.text.toLowerCase();\n\t\tif (func === \"sum\") {\n\t\t\tlet result = 0;\n\t\t\twhile (this.stack.length) {\n\t\t\t\tconst elem = this.stack.pop();\n\t\t\t\tif (elem instanceof Array) {\n\t\t\t\t\telem.forEach(e => result = result + e);\n\t\t\t\t} else {\n\t\t\t\t\tresult = result + elem;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.stack.push(result);\n\t\t} else if (func === \"if\") {\n\t\t\tconst choice2 = this.stack.pop();\n\t\t\tconst choice1 = this.stack.pop();\n\t\t\tconst condition = this.stack.pop();\n\t\t\tif (condition) {\n\t\t\t\tthis.stack.push(choice1);\n\t\t\t} else {\n\t\t\t\tthis.stack.push(choice2);\n\t\t\t}\n\t\t} else if (func === \"true\") {\n\t\t\tthis.stack.push(true);\n\t\t} else if (func === \"false\") {\n\t\t\tthis.stack.push(false);\n\t\t} else {\n\t\t\tthrow new Error(`Unimplemented function: ${func}`);\n\t\t}\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#braceExpression.\n\texitBraceExpression(ctx) {\n\t\tthis.trace(`exitBraceExpression: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#postfix.\n\texitPostfix(ctx) {\n\t\tthis.trace(`exitPostfix: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#unaryExpression.\n\texitUnaryExpression(ctx) {\n\t\tthis.trace(`exitUnaryExpression: ${ctx.getText()}`);\n\t\tconst op1 = this.stack.pop();\n\t\tconst op = this.stack.pop();\n\t\tif (op === \"-\") {\n\t\t\tthis.stack.push(- op1);\n\t\t} else {\n\t\t\tthis.stack.push(op1);\n\t\t}\n\t}\n\n\texitTopLevelInt(ctx) {\n\t\tthis.trace(`exitTopLevelNumber: ${ctx.getText()}`);\n\t\tthis.stack.push(ctx.getText() * 1)\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#topLevelNumber.\n\texitTopLevelNumber(ctx) {\n\t\tthis.trace(`exitTopLevelNumber: ${ctx.getText()}`);\n\t\tthis.stack.push(ctx.getText() * 1.0)\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#unary_op.\n\texitUnary_op(ctx) {\n\t\tthis.trace(`exitUnary_op: ${ctx.getText()}`);\n\t\tthis.stack.push(ctx.getText());\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#binary_op.\n\texitBinary_op(ctx) {\n\t\tthis.trace(`exitBinary_op: ${ctx.getText()}`);\n\t\tthis.stack.push(ctx.getText());\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#comparison_op.\n\texitComparison_op(ctx) {\n\t\tthis.trace(`exitComparison_op: ${ctx.getText()}`);\n  }\n\n\t// Exit a parse tree produced by JSONFormulaParser#postfix_op.\n\texitPostfix_op(ctx) {\n\t\tthis.trace(`exitPostfix_op: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#function_call.\n\texitFunction_call(ctx) {\n\t\tthis.trace(`exitFunction_call: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#parameter.\n\texitParameter(ctx) {\n\t\tthis.trace(`exitParameter: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#nonempty_expr_list.\n\texitNonempty_expr_list(ctx) {\n\t\tthis.trace(`exitNonempty_expr_list: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#expression_list.\n\texitExpression_list(ctx) {\n\t\tthis.trace(`exitExpression_list: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#intersection_op.\n\texitIntersection_op(ctx) {\n\t\tthis.trace(`exitIntersection_op: ${ctx.getText()}`);\n\t}\n\n\t// Exit a parse tree produced by JSONFormulaParser#parm_separator.\n\texitParm_separator(ctx) {\n\t\tthis.trace(`exitParm_separator: ${ctx.getText()}`);\n\t}\n}","/*\nCopyright 2021 Adobe. All rights reserved.\nThis file is licensed to you under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License. You may obtain a copy\nof the License at http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under\nthe License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR REPRESENTATIONS\nOF ANY KIND, either express or implied. See the License for the specific language\ngoverning permissions and limitations under the License.\n*/\n\nimport antlr4 from \"antlr4\";\nimport FEParser from \"./antlr/JSONFormulaParser.js\";\nimport FELexer from \"./antlr/JSONFormulaLexer.js\";\n\nimport Listener from \"./Listener.js\";\n\nexport default function evaluate(json, expression, trace) {\n  const chars = new antlr4.InputStream(expression);\n  const lexer = new FELexer(chars);\n  lexer._interp.debug = true;\n  const tokens  = new antlr4.CommonTokenStream(lexer);\n  const parser = new FEParser(tokens);\n  parser.buildParseTrees = true;\n\n  let parseError;\n  class ParseErrorListener extends antlr4.error.ErrorListener {\n    syntaxError(recognizer, offendingSymbol, line, column, msg) {\n      parseError = `line ${line}, col ${column}: ${msg}`;\n      if (trace) console.log(`ERROR: ${parseError}`);\n    }\n  }\n  /*\n  let lexerError;\n  class LexerErrorListener extends antlr4.error.ErrorListener {\n    syntaxError(recognizer, offendingSymbol, line, column, msg) {\n      lexerError = `line ${line}, col ${column}: ${msg}`;\n      if (trace) console.log(`ERROR: ${error}`);\n    }\n  }\n  lexer.removeErrorListeners();\n  const lexerErrHandler = new LexerErrorListener();\n  lexer.addErrorListener(lexerErrHandler);\n  */\n  const parseErrHandler = new ParseErrorListener();\n  parser.removeErrorListeners();\n  parser.addErrorListener(parseErrHandler);\n\n\n  let tree;\n  try {\n    tree = parser.formula();\n  } catch (e) {\n    console.log(e);\n  }\n  const extractor = new Listener(json, trace);\n  antlr4.tree.ParseTreeWalker.DEFAULT.walk(extractor, tree);\n  if (parseError) {\n    if (extractor.result !== undefined) {\n      // antlr recovered from the error\n      return extractor.result;\n    }\n    throw new Error(parseError);\n  }\n  return extractor.result;\n}\n","/*\nCopyright 2021 Adobe. All rights reserved.\nThis file is licensed to you under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License. You may obtain a copy\nof the License at http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under\nthe License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR REPRESENTATIONS\nOF ANY KIND, either express or implied. See the License for the specific language\ngoverning permissions and limitations under the License.\n*/\nimport evaluate from \"./evaluate.js\";\n\nconst data = document.getElementById(\"data\");\nconst expression = document.getElementById(\"expression\");\nconst result = document.getElementById(\"result\");\n\n/*\n  Field class allows objects to evaluate correctly according to context.\n   - if used in an expression, will return a value or string.\n   - for JSON.stringify() returns a scalar\n   - BUT also allows explicit access to properties. e.g. field.required, field.name etc.\n\n   Should allow us to eliminate getFieldProperty()\n*/\nclass Field {\n  constructor(name, val) {\n    this.value = val;\n    this.name = name;\n    this.readonly = false;\n    this.required = true;\n  }\n  valueOf() { return this.value }\n  toString() { return this.value.toString() }\n  toJSON() { return this.value }\n}\n\nfunction createFields(parent, childref, child) {\n  if (child instanceof Array) {\n    child.forEach((item, index) => {\n      createFields(child, index, item);\n    });\n  } else if (typeof child === \"object\") {\n    Object.keys(child).forEach(k => {\n      createFields(child, k, child[k]);\n    })\n  } else {\n    parent[childref] = new Field(childref, parent[childref]);\n  }\n}\n\nfunction run() {\n  const input = expression.value;\n\n  let json;\n  try {\n    json = JSON.parse(data.value);\n    if (document.getElementById(\"use-fields\").checked) {\n      createFields(null, null, json);\n    }\n  } catch (e) {\n    result.value = e.toString();\n    return;\n  }\n  try {\n    const r = evaluate(json, input, true);\n    if (r instanceof Field) {\n      result.value = r.value;\n    } else if (typeof r === \"object\") {\n      result.value = JSON.stringify(r, null, 2);\n    } else {\n      result.value = r;\n    }\n  } catch (e) {\n    result.value = e.toString();\n  }\n}\n\ndata.addEventListener(\"blur\", run);\nexpression.addEventListener(\"blur\", run);\nrun();\n\nfetch(\"./antlr/JSONFormula.g4\").then(r => {\n  r.text().then((g4 => document.getElementById(\"grammar-out\").innerHTML = g4));\n});\n"],"sourceRoot":""}